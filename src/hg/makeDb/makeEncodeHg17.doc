#!/bin/csh -f
exit

# This is the make doc for the hg17 ENCODE data.
# NOTE: many of these tracks were lifted from hg16 with
# semi-automated processing. The liftOver leftovers were moved
# to the subdirectories "mapped" and "unmapped" of the main\
# work area, /cluster/data/encode/convertHg17

    # create work area
    mkdir /cluster/data/encode/convertHg17
    cd  /cluster/data/encode/convertHg17
    ln -s /cluster/data/hg16/bed/liftOver/hg16ToHg17.over.chain hg16ToHg17.chain

    # Inventory ENCODE tables on hg16 (hgwbeta)

    ssh hgwbeta "echo select tableName from trackDb where tableName like \'encode%\' and settings not like \'%composite%\' order by tableName | hgsql hg16" > tables.txt
    wc -l tables.txt
        #     350 tables.txt

    set encodeBin = /cluster/data/encode/bin/scripts
    csh $encodeBin/listEncodeTables.csh hg16 > tableTypes.txt
    grep bed tableTypes.txt > tables.bed.txt

##########################################################################
# DOWNLOADS

    ssh hgwdev
    cd /usr/local/apache/htdocs/hg17
    mkdir -p encode
    cd encode
    # release terms
    cp ../../hg16/encode/README.txt .
    # annotation database
    # request admin set up automated database dump
    mkdir database
    # auxiliary data files
    mkdir datafiles 
    # sequences
    mkdir regions
    cp ../../hg16/encode/regions/README.txt regions
    # edit README
    cd /cluster/data/encode/convertHg17
    hgsql hg17 -N -e \
      "SELECT name, chrom, chromStart, chromEnd FROM encodeRegions ORDER BY name">regions.txt 

    ssh kolossus
    cd /cluster/data/encode/convertHg17
    mkdir regions
    cd regions
    /cluster/data/encode/bin/scripts/encodeSequences.pl -upper \
        ../regions.txt /iscratch/i/hg17/nib  > hg17.fa
    /cluster/data/encode/bin/scripts/encodeSequences.pl -masked \
        ../regions.txt /iscratch/i/hg17/nib  > hg17.msk.fa
    faSize detailed=on hg17.fa > hg17_count.txt
    gzip *.fa
    md5sum *.fa.gz > md5sum.txt
    # copy regions/README.txt from hg16 and edit

    ssh hgwdev
    cd /usr/local/apache/htdocs/goldenPath/hg17/encode
    ln -s /cluster/data/encode/convertHg17/regions .

    # October MSA freeze
    ssh hgwdev
    cd /usr/local/apache/htdocs/goldenPath/hg17/encode
    mkdir alignments
    ln -s /cluster/data/encode/downloads/msa/SEP-2005 .
    # terms of use
    cp /usr/local/apache/htdocs/goldenPath/hg16/encode/alignments/README.txt .


!##########################################################################
###########################################################################
# Tracks lifted from hg16

##########################################################################
# GIS PET (2005-08-23 kate)
# NOTE: This track will be replaced with a new data submission

    cd  /cluster/data/encode/convertHg17

    # use mysqldump to generate .sql w/ schema, and .txt with data
    set t = encodeGisRnaPetHCT116
    $encodeBin/dumpTable.csh hg16 $t
    wc -l $t.txt
        # 112782 encodeGisRnaPetHCT116.txt

    # create table
    hgsql hg17 < $t.sql

    # convert data coordinates
    ~/bin/i386/liftOver $t.txt -hasBin -bedPlus=12 \
            hg16ToHg17.chain $t.tab $t.unmapped
    wc -l $t.tab $t.unmapped
         # 112701 encodeGisRnaPetHCT116.tab
         #    162 encodeGisRnaPetHCT116.unmapped

    # load into database
    echo "LOAD DATA local INFILE '$t.tab' INTO TABLE $t" | hgsql hg17
    hgsql hg17 -N -s -e "SELECT COUNT(*) FROM $t"
        # 112701
    checkTableCoords hg17 $t

    # Now try scripted version
    csh $encodeBin/convertBedTable.csh hg16 hg17 encodeGisRnaPetMCF7 12
        # encodeGisRnaPetMCF7     hg16 104304   hg17 104187
    csh $encodeBin/convertBedTable.csh hg16 hg17 encodeGisChipPet 12
        # encodeGisChipPet        hg16 65513   hg17 65510

##########################################################################
# KNOWN+PRED RNA (2005-08-29 kate)

    cd  /cluster/data/encode/convertHg17
    grep encodeRna tables.bed.txt
        # encodeRna       encodeGenes     bed 6 +

    $encodeBin/convertBedTable.csh hg16 hg17 encodeRna 6

##########################################################################
# TBA23 Evofold (2005-08-23 kate)

    cd  /cluster/data/encode/convertHg17
    csh $encodeBin/convertBedTable.csh hg16 hg17 encode_tba23EvoFold 6
            # 739 encode_tba23EvoFold.txt
        # Reading liftover chains
        # Mapping coordinates
            # 739 encode_tba23EvoFold.tab
              # 0 encode_tba23EvoFold.unmapped
            # 739 total
        # encode_tba23EvoFold     hg16 739   hg17 739



##########################################################################
# Transcription Levels Group
# BU FIRST EXON
    grep encodeBu tables.bed.txt
        # encodeBuFirstExonCerebrum       encodeTxLevels  bed 12 +
        # encodeBuFirstExonColon  encodeTxLevels  bed 12 +
        # encodeBuFirstExonHeart  encodeTxLevels  bed 12 +
        # encodeBuFirstExonKidney encodeTxLevels  bed 12 +
        # encodeBuFirstExonLiver  encodeTxLevels  bed 12 +
        # encodeBuFirstExonLung   encodeTxLevels  bed 12 +
        # encodeBuFirstExonSkMuscle       encodeTxLevels  bed 12 +
        # encodeBuFirstExonSpleen encodeTxLevels  bed 12 +
        # encodeBuFirstExonStomach        encodeTxLevels  bed 12 +
        # encodeBuFirstExonTestis encodeTxLevels  bed 12 +
    
    set buTables = `echo "SHOW TABLES LIKE 'encodeBuFirstExon%'" | hgsql -N -s hg16`
    foreach t ($buTables)
        csh $encodeBin/convertBedTable.csh hg16 hg17 $t 12
        checkTableCoords hg17 $t
    end


# RIKEN CAGE
    grep encodeRikenCage tables.bed.txt
        # encodeRikenCageMinus    encodeTxLevels  bedGraph 4
        # encodeRikenCagePlus     encodeTxLevels  bedGraph 4

    csh $encodeBin/convertBedTable.csh hg16 hg17 encodeRikenCageMinus 4
        # Creating hg16 encodeRikenCageMinus.sql and encodeRikenCageMinus.txt
           # 6156 encodeRikenCageMinus.txt
        # Reading liftover chains
        # Mapping coordinates
           # 6153 encodeRikenCageMinus.tab
              # 6 encodeRikenCageMinus.unmapped
           # 6159 total
        # encodeRikenCageMinus    hg16 6156   hg17 6153

    csh $encodeBin/convertBedTable.csh hg16 hg17 encodeRikenCagePlus 4
            # csh $encodeBin/convertBedTable.csh hg16 hg17 encodeRikenCagePlus 4
        # Creating hg16 encodeRikenCagePlus.sql and encodeRikenCagePlus.txt
           # 5688 encodeRikenCagePlus.txt
        # Reading liftover chains
        # Mapping coordinates
           # 5639 encodeRikenCagePlus.tab
             # 98 encodeRikenCagePlus.unmapped
           # 5737 total
        # encodeRikenCagePlus     hg16 5688   hg17 5639


##########################################################################
# CHIP/CHIP GROUP
# 
# STANFORD CHIP
# encodeStanfordChip* bedGraph 4 tracks

cat > doStan.csh << 'EOF'
    set stanTables = \
        `echo "SHOW TABLES LIKE 'encodeStanfordChip%'" | hgsql -N -s hg16`
    foreach t ($stanTables)
        csh /cluster/data/encode/bin/scripts/convertBedTable.csh \
                hg16 hg17 $t 4
    end
'EOF'
    csh doStan.csh >&! doStan.log
    grep hg17 doStan.log | wc -l
        # 12 tracks (6 smoothed)
        # encodeStanfordChipHCT116Sp1     hg16 369633   hg17 369465
        # encodeStanfordChipSmoothedHCT116Sp1     hg16 137439   hg17 137361

# UCD Ng
        csh $encodeBin/convertBedTable.csh hg16 hg17 encodeUCDavisE2F1Median 4
        # encodeUCDavisE2F1Median hg16 382884   hg17 382713

# UCSD/LI CHIP
# encodeUcsdChip* bedGraph 4 tracks (total 36)

cat > doUcsd.csh << 'EOF'
    set ucsdTables = \
        `echo "SHOW TABLES LIKE 'encodeUcsdChip%'" | hgsql -N -s hg16`
    foreach t ($ucsdTables)
        csh /cluster/data/encode/bin/scripts/convertBedTable.csh \
                hg16 hg17 $t 4
    end
'EOF'
    csh doUcsd.csh >&! doUcsd.log
    grep hg17 doUcsd.log | wc -l
    # 36 tracks
    # encodeUcsdChipAch3Imr90 hg16 24348   hg17 24339
    # encodeUcsdChipHeLaH3H4tmH3K4_p30        hg16 24537   hg17 24528


##########################################################################
# TRANSCRIPTION LEVELS TRACKS (2005-08-24 kate)

    # grep encodeTxLevels in tables.bed.txt and edit out already
    # completed tracks.  Prefix each table with a call to convertBedTable
    # and suffix with bed field count
    # Tracks are: Stanford RTPCR, Yale TARS

    csh doTx.csh >&! doTx.log
    grep hg17 doTx.log | wc -l
        # 9 tracks

##########################################################################
# CHROMATIN & CHROMOSOMES TRACKS (2005-08-24 kate)

    # Regulome, NHGRI DNase, Stanford Meth, UVA
    csh doChrom.csh >&! doChrom.log
    # 37 tables
    # do Stanford Meth Smoothed tables that weren't converted because
        # hg16 tables had incorrect capitalization wrt trackDb
        # and so weren't being displayed
    csh doChrom2.csh >&! doChrom2.log

##########################################################################
# CHIP/CHIP TRACKS (2005-08-24 kate)
# Sanger, UCSD Nimblegen

    doChip.csh >&! doChip.log

##########################################################################
# VARIATION TRACKS (2005-08-24 kate)
#  HapMap, Reseq, Sanger Gene Expr

    csh doVar.csh >&! doVar.log
    grep hg17 doVar.log
        # encodeReseqRegions      hg16 10   hg17 10
        # encodeSangerGenoExprAssociation hg16 13674   hg17 13674
    csh doHap.csh >&! doHap.log
    grep hg17 doHap.log
        # encodeHapMapAlleleFreqCEU       hg16 20772   hg17 20772
        # encodeHapMapAlleleFreqCHB       hg16 19629   hg17 19629
        # encodeHapMapAlleleFreqJPT       hg16 19629   hg17 19629
        # encodeHapMapAlleleFreqYRI       hg16 19520   hg17 19520
    csh /cluster/data/encode/bin/scripts/convertBedTable.csh \
                hg16 hg17 encodeRecomb         4


##########################################################################
# AFFY CHIP/CHIP TRACKS (2005-08-24 kate)
    csh doAffy.csh >&! doAffy.log
        # 41 doAffy.csh
    grep hg17 doAffy.log | wc -l
        # 41 

    # do tracks missing from RR!
    csh doAffy2.csh >&! doAffy2.log
    wc -l doAffy2.csh
        # 6 doAffy2.csh
    grep hg17 doAffy2.log | wc -l
        # 6

##########################################################################
# WIG TRACKS (2005-08-24 kate)
        doWig.csh > doWig.log
        # 75 tables

##########################################################################
# YALE TRACKS (2005-08-31 kate)
        doYale.csh > doYale.log
        wc -l doYale.csh
            # 54 doYale.csh
        grep hg17 doYale.log | wc -l
            # 50 
            # redo the 4 that failed
        doYale2.csh > doYale2.log
        grep hg17 doYale2.log | wc -l
            # 4 tracks

!##########################################################################
##########################################################################
# Tracks submitted in hg17 coords

##########################################################################
# GENCODE Sanger Havana annotations  (2005-08-18 kate)
    # Used latest (6/7/05) data submission, which was submitted
    #   in hg17 coords and lifted to hg16.  This was described in makeEncodeHg16.doc
    ssh hgwdev
    cd /cluster/data/encode/Gencode
    cd 2005-06-07

    ldHgGene -gtf -genePredExt hg17 encodeGencodeGene gencode.vega.gtf
        # 2888 gene predictions
    checkTableCoords hg17 encodeGencodeGene

    grep intron gencode.gtf | wc -l
        # 15814
    grep -v not_tested gencode.gtf | sed -e 's/-intron/-/g' | \
        ldGencodeIntron hg17 encodeGencodeIntron stdin
            # 469 introns

    # load gene class table 
    hgsql hg17 < ~/kent/src/hg/lib/gencodeGeneClass.sql
    echo "LOAD DATA LOCAL INFILE 'gencodeGeneClass.tab' into table gencodeGeneClass" | hgsql hg17
    wc -l gencodeGeneClass.tab
        #    2888 gencodeGeneClass.tab


##########################################################################
# EGASP Partial (2005-08-18 kate)
# Gene tracks submitted for the EGASP competition were hg17-based
#       by the Gencode group (Roderic Guigo, Julien Legarde, IMIM) 
# These were lifted to hg17, as described in makeEncodeHg16.doc
# NOTE: Problem with encodeEgaspPartAugustusAny table detected
# and fixed on 2006-01-09.  It was somehow loaded with Genemark full data...
    cd /cluster/data/encode
    cd EGASP/Partial
    wc -l lab/*.gtf
       # 1778 lab/ASPic.gtf
       # 4215 lab/AceSCAN.gtf
       # 2692 lab/Augustus_EST-Protein.gtf
       # 2347 lab/Augustus_abinitio.gtf
       # 2736 lab/Augustus_any.gtf
       # 2567 lab/Augustus_dualgenome.gtf
       # 3458 lab/GeneZilla.gtf
       # 2194 lab/SAGA.gtf
    # NOTE: exclude ASPic, which contains only intron records
    # Filenames above, with _CHR_COORDS_hg17.gff appended, are chrom coordinate versions

    # GeneZilla
    ldHgGene hg17 encodeEgaspPartGenezilla lab/GeneZilla.*.gff
        # 656 gene predictions
    genePredCheck -db=hg17 encodeEgaspPartGenezilla

    # SAGA
    # Strip out trailing ## on lines where manual changes were made
    #   (see notes in .gtf file)
    sed -e 's/ ##.*//' lab/SAGA.*.gff | \
        ldHgGene hg17 encodeEgaspPartSaga stdin
        # 378 gene predictions
    genePredCheck -db=hg17 encodeEgaspPartSaga

    # Augustus
   ln -s lab/Augustus_EST-Protein.gtf_CHR_COORDS_hg17.gff augustus.est.gff
   ln -s lab/Augustus_abinitio.gtf_CHR_COORDS_hg17.gff augustus.abinitio.gff
   ln -s lab/Augustus_any.gtf_CHR_COORDS_hg17.gff augustus.any.gff
   ln -s lab/Augustus_dualgenome.gtf_CHR_COORDS_hg17.gff augustus.dual.gff

    foreach f (augustus.*.gff)
        set t = `echo $f | sed -e 's/augustus.\(.*\).gff/encodeEgaspPartAugustus\u\1/'`
        ldHgGene -genePredExt hg17 $t $f
        checkTableCoords hg17 $t
    end
        # augustus.abinitio.gff 418 gene predictions
        # augustus.any.gff      399 gene predictions
        # augustus.dual.gff     413 gene predictions
        # augustus.est.gff      381 gene predictions

    # Reload .est predictions (2006-01-09 kate)
    ldHgGene -genePredExt hg17 encodeEgaspPartAugustusEst augustus.est.gff
        # augustus.est.gff      381 gene predictions
    checkTableCoords hg17 encodeEgaspPartAugustusEst

    # AceSCAN
    # Split into two tracks -- conserved, and other, based on feature
    ldHgGene -predTab hg17 encodeEgaspPartAceCons aceCons.gp
        # 117 gene predictions
    ldHgGene -predTab hg17 encodeEgaspPartAceOther aceOther.gp
        # 727 gene predictions
    genePredCheck -db=hg17 encodeEgaspPartAceCons encodeEgaspPartAceOther

##########################################################################
# EGASP Full (2005-06-27 kate)
# Gene tracks submitted for the EGASP competition were hg17-based
#       by the Gencode group (Roderic Guigo, Julien Legarde, IMIM) 
    cd /cluster/data/encode
    cd EGASP/Full

    # Process "standard" gff files
    # NOTE: must dummy out scores -- float values
cat > doGene.hg17.csh << 'EOF'
ls *.gp | grep -v hg16 > gpList
foreach f (`cat gpList`)
    wc -l $f 
    set b = $f:r
    set t = encodeEgaspFull$b
    ldHgGene -predTab hg17 $t $f
    genePredCheck -db=hg17 $t
end
'EOF'
csh doGene.hg17.csh >&! doGene.hg17.log

    # process special files
    cd custom
cat > doGene.hg17.csh << 'EOF'
foreach f (Jigsaw.gp Ensembl.gp EnsemblPseudo.gp Exonhunter.gp GeneId.gp Sgp2.gp Twinscan.gp)
    set b = $f:r
    set t = encodeEgaspFull$b
    ldHgGene -genePredExt -predTab hg17 $t $b.gp
    genePredCheck -db=hg17 $t
end
'EOF'
# << for emacs
csh doGene.hg17.csh >&! doGene.hg17.log
    # NOTE: OK to have missing exonFrames
# Reading Ensembl.gp
# 735 gene predictions
# Reading EnsemblPseudo.gp
# 34 gene predictions
# Reading Exonhunter.gp
# 1435 gene predictions
# Reading GeneId.gp
# 476 gene predictions
# Reading Sgp2.gp
# 930 gene predictions
# Reading Twinscan.gp
# 954 gene predictions

end
'EOF'
# << for emacs
csh doGene.hg17.csh >&! doGene.hg17.log

    # process others
    set t = "encodeEgaspFullGenemark"
    ldHgGene -predTab hg17 $t Genemark.gp
        # 890 gene predictions
    genePredCheck -db=hg17 $t

    # create genepreds containing just exons flanking U12 introns
    set t = encodeEgaspFullGeneIdU12
    ldHgGene -predTab -genePredExt hg17 $t geneId.introns.gp
        # 24 gene predictions
    genePredCheck -db=hg17 $t
    set t = encodeEgaspFullSgp2U12
    ldHgGene -predTab -genePredExt hg17 $t sgp2.introns.gp
        # 20 gene predictions
    genePredCheck -db=hg17 $t


##########################################################################
# EGASP Update
# Submitted in hg17 coords

    # Jigsaw
    cd /cluster/data/encode
    cd EGASP/Jigsaw/2005-06-01
    ldHgGene -predTab -genePredExt hg17 encodeEgaspUpdJigsaw jigsaw.gp
        # 454 gene predictions
    genePredCheck -db=hg17 encodeEgaspUpdJigsaw

    # Augustus
    cd /cluster/data/encode
    cd EGASP/Augustus/2005-06-22
    foreach f (abinitio.gp any.gp dual.gp est.gp)
        genePredCheck $f
        set t = `echo $f | sed -e 's/\(.*\).gp/encodeEgaspUpdAugustus\u\1/'`
        ldHgGene -predTab -genePredExt hg17 $t $f
        checkTableCoords hg17 $t
    end
        # Reading abinitio.gp
        # 622 gene predictions
        # Reading any.gp
        # 571 gene predictions
        # Reading dual.gp
        # 617 gene predictions
        # Reading est.gp
        # 543 gene predictions

    # Exogean
    cd /cluster/data/encode
    cd EGASP/Exogean/2005-06-23
    ldHgGene -predTab hg17 encodeEgaspUpdExogean exogean.gp
        # 850 gene predictions
    genePredCheck -db=hg17 encodeEgaspUpdExogean

    # GeneIDU12 and SgpU12
    cd /cluster/data/encode
    cd EGASP/GeneIdU12/2005-06-10/
    # create GTF files from submitted GFF's
    awk -F\\t '/^chr/ {printf "%s\t%s\tCDS\t%s\t%s\t.\t%s\t%s\tgene_id \"%s\"; transcript_id \"%s\"; exon_type \"%s\";\n", $1, $2, $4, $5, $7, $8, $9, $9, $3}' < lab/UCSC-hg17-GeneID-U12-track.gff | grep -v intron > geneId.hg17.gtf
    ldHgGene -genePredExt hg17 encodeEgaspUpdGeneId geneId.hg17.gtf
        # 476 gene predictions
    genePredCheck -db=hg17 encodeEgaspUpdGeneId

    awk -F\\t '/^chr/ {printf "%s\t%s\tCDS\t%s\t%s\t.\t%s\t%s\tgene_id \"%s\"; transcript_id \"%s\"; exon_type \"%s\";\n", $1, $2, $4, $5, $7, $8, $9, $9, $3}' < lab/UCSC-hg17-SGP2-U12-track.gff | grep -v intron > sgp2.hg17.gtf
    ldHgGene -genePredExt hg17 encodeEgaspUpdSgp2 sgp2.hg17.gtf
        # 930 gene predictions
    genePredCheck -db=hg17 encodeEgaspUpdSgp2

    # create genepreds containing just exons flanking U12 introns
    # use U12 annotation as gene name, so it appears on details page
    grep U12 geneId.hg17.gtf | perl -wpe \
 's/(^.*gene_id) (\S+) (.*exon_type) (.*)(U12[^-]+)(.*)/$1 "$5"; $3 $4$5$6/' \
        > geneId.introns.hg17.gtf
    ldHgGene -genePredExt hg17 encodeEgaspUpdGeneIdU12 geneId.introns.hg17.gtf
        # 24 gene predictions

    grep U12 sgp2.hg17.gtf | perl -wpe \
 's/(^.*gene_id) (\S+) (.*exon_type) (.*)(U12[^-]+)(.*)/$1 "$5"; $3 $4$5$6/' \
        > sgp2.introns.hg17.gtf
    ldHgGene -genePredExt hg17 encodeEgaspUpdSgp2U12 sgp2.introns.hg17.gtf
        # 20 gene predictions


    # EGASP Yale Pseudogenes
    # Update submitted by Deyou Zheng 8/18/05
    cd /cluster/data/encode
    cd EGASP/yale/latest
    wc -l lab/*.submitted
        #  184 lab/YalePgene-NCBI35.gtf.submitted
        # NOTE: this is fewer than the previous submission -- I confirmed
        # with Deyou that this is correct.

    # munge to create CDS entries to display, and assign pseudogene
    # name as transcript_id, and pseudogene type as gene_id so
    # it displays on details page
    sed -e 's/pseudogene\t/CDS\t/' -e 's/pgene_type/gene_id/'  \
        -e 's/alt_name ENCODE_Yale/transcript_id /' \
                lab/YalePgene-NCBI35.gtf.submitted > yale.hg17.gtf
    ldHgGene -genePredExt hg17 encodeEgaspUpdYalePseudo yale.hg17.gtf
        # 184 gene predictions 
    genePredCheck -db=hg17 encodeEgaspUpdYalePseudo

    # Fgenesh++
    # Update submitted 9/30/05 by Victor Solovyev to Julien Legarde at
    # IMIM, to fix 4 regions (predictions originally on hg16, redone
    # for hg17)
    cd /cluster/data/encode/EGASP
    mkdir -p Fgenesh/2005-09-30/lab
    cd Fgenesh/2005-09-30/lab
    wget ftp://genome.imim.es/pub/projects/gencode/data/egasp05/submitted_predictions/EGASP_Update/FGenesh++_corrected_update.gtf_CHR_COORDS_hg17.gff
    wget ftp://genome.imim.es/pub/projects/gencode/data/egasp05/submitted_predictions/EGASP_partial/FGenesh++_corrected_partial.gtf_CHR_COORDS_hg17.gff
    cd ..
    cat *.gff | ldHgGene hg17 encodeEgaspUpdFgenesh stdin
    genePredCheck -db=hg17 encodeEgaspUpdFgenesh
        # 820 gene predictions
    
##########################################################################
# UCSD/LI Nimblegen Hela
# Data submitted on hg17 for June freeze

    cd /cluster/data/encode/UCSD/nimblegen/2005-06-01
    foreach f (lab/Nim*/*.wig)
        set t =  `echo $f:t:r | sed -e \
         's/rnap/encodeUcsdNgHeLaRnap/; s/tmh3k4/encodeUcsdNgHeLaH3K4me3/;'`
        echo $t
        grep "^chr" $f | hgLoadBed -onServer -bedGraph=4 hg17 $t stdin
        checkTableCoords hg17 $t
    end
        # Produces 4 tables, encodeUcsdNgHeLa{Rnap,H3K4me3}_p{0,30}
        # Loaded 385149 elements of size 4 

##########################################################################
# STANFORD PROMOTERS
    cd /cluster/data/encode/StanfordPromoters
    rm previous
    mv latest previous
    mkdir 2005-08-23
    ln -s 2005-08-23 latest
    mkdir latest/lab
    # copy updated files from Sara Hartman's email.
    # Both hg16 and hg17 versions were included:
    # hg16: StanfordPromoters_<cell>_08.23.txt
    # hg17: StanfordPromoters_hg17_<cell>_08.24.txt
    # Use Angie's processing from hg16, slightly modified
    cd latest
cat > doProm.csh << 'EOF'
    foreach f (lab/StanfordPromoters_hg17*.txt)
      set cellType = `echo $f | perl -wpe 's^lab/StanfordPromoters_hg17_(.*)_.*^$1^'`
      echo $cellType
      if ($cellType == "Average") then
        tail +2 $f \
        | perl -wpe 'chomp; @w = split("\t"); $w[7] =~ s/^\"(.*)\"$/$1/; \
                     $w[3] =~ tr/01/-+/; \
                     $_ = join("\t", \
  $w[2], $w[4], $w[5], $w[0], $w[9], $w[3], $w[4], $w[5], 0, $w[1], $w[7], \
  $w[8]) . "\n";' \
        | makeColoredBed > encodeStanfordPromoters$cellType.hg17.bed
      else
        tail +2 $f \
        | grep -v "Bad Txfn" \
        | perl -wpe 'chomp; @w = split("\t"); $w[7] =~ s/^\"(.*)\"$/$1/; \
                     $w[3] =~ tr/01/-+/; \
                     $_ = join("\t", \
  $w[2], $w[4], $w[5], $w[0], $w[15], $w[3], $w[4], $w[5], 0, $w[1], $w[7], \
  $w[8], $w[9], $w[10], $w[11], $w[12], $w[13], $w[14]) . "\n";' \
        | makeColoredBed > encodeStanfordPromoters$cellType.hg17.bed
      endif
    end
'EOF'
    csh doProm.csh >&! doProm.log

cat > doLoad.csh << 'EOF'
    foreach f (encode*.bed)
      set track = $f:r:r
      if ($track == "encodeStanfordPromotersAverage") then
        hgLoadBed -tab -noBin -sqlTable=$HOME/kent/src/hg/lib/$track.sql \
          hg17 $track $f
      else
        sed -e "s/encodeStanfordPromoters/$track/" \
          $HOME/kent/src/hg/lib/encodeStanfordPromoters.sql > /tmp/esp.sql
        hgLoadBed -tab -noBin -sqlTable=/tmp/esp.sql hg17 $track $f
      endif
    end
'EOF'
    csh doLoad.csh >&! doLoad.log 

    # Put the negative control data spreadsheet out for download.
    ssh kkstore03
    cd /cluster/data/encode/StanfordPromoters/latest/lab
    nice gzip hg17_NegControlDataStanfordPromoters.txt
    ssh hgwdev
    cd /usr/local/apache/htdocs/goldenPath/hg17/encode/datafiles
    mkdir -p stanfordPromoters
    cd stanfordPromoters
    cp -p \
        /cluster/data/encode/StanfordPromoters/latest/lab/hg17_NegControlDataStanfordPromoters.txt.gz \
                NegativeControlDataStanfordPromoters.txt.gz
    # Added a README.txt (edited form Angie's hg16 version)

##########################################################################
# UV Replication -- Segregation, Origins, and Origin Confidence tracks
#       New data for Oct. freeze (but submitted in hg16 coords)
#       All data are bed3
# Contact: Chris Taylor (cmt5n@cs.virginia.edu)

    cd /cluster/data/encode/UVa
    mkdir -p 2005-08-30
    cd 2005-08-30
    mkdir lab

    # Segregation data - 4 subtracks (Early, Mid, Late, Pan-S)
    # 4 custom tracks in a single file -- use Hiram's script to split
    /cluster/data/encode/BU/2005-06-09/splitTracks.pl \
                lab/segchunks.hg16.qced.bed
    # creates t0, t1, t2, t3
    awk < lab/segchunks.hg16.qced.bed '/track/ {print $2}'
#name=early
#name=mid
#name=late
#name=pans
    grep -v "^track" t0 > encodeUvaDnaRepEarly.hg16.bed
    grep -v "^track" t1 > encodeUvaDnaRepMid.hg16.bed
    grep -v "^track" t2 > encodeUvaDnaRepLate.hg16.bed
    grep -v "^track" t3 > encodeUvaDnaRepPanS.hg16.bed
    rm t0 t1 t2 t3
    foreach f (encodeUvaDnaRep*.hg16.bed)
        set d = $f:r:r
        echo $d
        liftOver $f /cluster/data/encode/convertHg17/hg16ToHg17.chain \
                $d.hg17.bed $d.unmapped
        hgLoadBed -noBin -strict hg17 $d $d.hg17.bed
    end

    # Redo with hg17 resubmitted data
    cd /cluster/data/encode/UVa
    cd 2005-10-15
    /cluster/data/encode/bin/scripts/splitTracks.pl lab/segregation.hg17.bed
    grep -v "^track" t0 > encodeUvaDnaRepEarly.bed
    grep -v "^track" t1 > encodeUvaDnaRepMid.bed
    grep -v "^track" t2 > encodeUvaDnaRepLate.bed
    grep -v "^track" t3 > encodeUvaDnaRepPanS.bed
    rm t0 t1 t2 t3
    foreach f (encodeUvaDnaRep*.bed)
        set d = $f:r
        echo $d
        hgLoadBed -noBin -strict hg17 $d $d.bed
    end

    # Origin predictions -- fixed at 200bp
    set t = encodeUvaDnaRepOriginsPred
    ln -s lab/originspred.hg16.qced.bed $t.hg16.bed
    liftOver $t.hg16.bed \
        /cluster/data/encode/convertHg17/hg16ToHg17.chain \
                $t.hg17.bed $t.unmapped
    hgLoadBed -noBin -strict hg17 $t $t.hg17.bed
        # Loaded 289 elements of size 3

    # Origin confidence intervals -- varying length for averaged origins
    set t = encodeUvaDnaRepOriginsConf
    ln -s  lab/originsconf.hg16.qced.bed $t.hg16.bed
    liftOver $t.hg16.bed \
        /cluster/data/encode/convertHg17/hg16ToHg17.chain \
                $t.hg17.bed $t.unmapped
    hgLoadBed -noBin -strict hg17 $t $t.hg17.bed
        # Loaded 270 elements of size 3

    # Smoothed TR50 data
    #  500K 1bp float scores
    # wiggle with span=1
    set table = encodeUvaDnaRepTr50
    grep -v '^track' lab/smoothedtr50.hg17.wig | \
        wigEncode stdin $table.wig $table.wib
            #  upper limit 6.36, lower limit 2.05
    set dir = /gbdb/hg17/encode/UVa/2005-10-15
    mkdir -p $dir
    hgLoadWiggle -pathPrefix=$dir hg17 $table $table.wig
    ln -s `pwd`/$table.wib $dir


##########################################################################
# Indels from Jim Mullikin
# Heather, Sept. 2005

    ssh hgwdev
    cd /cluster/data/encode/NHGRI/mullikin/hg17
    hgsql hg17 < encodeIndels.sql
    split4.pl < hg17.ENCODE.DIPtrack.Q23.bed4+ > split4.out
    # use a modified makeColoredBed
    ./makeColoredBed < split4.out > encodeIndels.bed  
    # don't use -strict because we have lots of simple insertions (where chromStart = chromEnd)
    hgLoadBed hg17 encodeIndels -tab -sqlTable=encodeIndels.sql encodeIndels.bed
    # check reference length
    mysql> select chrom, chromStart, chromEnd, (chromEnd-chromStart) as size, traceName, reference, length(reference) as refsize from encodeIndels where (chromEnd-chromStart) != length(reference) and length(reference) > 1;
    # Empty set (0.07 sec)

##########################################################################
# Boston University ORChID track - (2005-09-18 kate)
#	data developer contact:  Jay Greenbaum jj@bu.edu
    ssh hgwdev
    cd /cluster/data/encode/BU
    mkdir -p orchid/2005-09-08/lab
    cd -p orchid/2005-09-08/lab
    wget --timestamping "http://dna.bu.edu/%7Ejj/cleavage_data_hg17/oh_cleavage_hg17.wig.gz"
    cd ..
    mkdir wib
    # NOTE: continue reluctantly with non-standard table name
    # as in hg16
    wigEncode lab/oh_cleavage_hg17.wig.gz \
        encodeBu_ORChID1.wig wib/encodeBu_ORChID1.wib
                # upper limit 1.58, lower limit -0.56
    # load
    set dir = /gbdb/hg17/encode/Bu/2005-09-08
    mkdir -p $dir
    hgLoadWiggle -pathPrefix=$dir hg17 encodeBu_ORChID1 encodeBu_ORChID1.wig
    mkdir -p $dir/wib
    ln -s `pwd`/wib/encodeBu_ORChID1.wib $dir/wib

##########################################################################
# Genome Institute of Singapore -ChIP/PET of STAT1 TFBS (2005-09-29 kate)
# Submitted 9/19 by Atif Shahab
    cd /cluster/data/encode/GIS
    mkdir chip
    mkdir -p 2005-09-19/lab
    ln -s 2005-09-19 latest
    cd latest
    # copy files from FTP dir to lab subdi4
    # files: 2 bed files (stim and nonstim) and 1 doc file
    # use antiword to convert doc file to txt
    ln -s lab/STAT1+stimulation.bed Gif.bed
    ln -s lab/STAT1+w:o_stimulation.bed NoGif.bed

    # Use cluster-count info, now embedded into the name, to make scored BED:
    # (Angie's methods)
    foreach f (Gif.bed NoGif.bed)
        set d = $f:r
        echo $d
        set table = encodeGisChipPetStat1$d
        perl -wpe 'chomp; @w = split; \
                 if ($w[3] =~ /^\d+-(\d+)$/) { \
                   $w[4] = ($1 >= 4 ? 1000 : ($1 >= 3 ? 800 : 333)); \
                 } else { die "parse"; } \
                 $_ = join("\t", @w) . "\n";' \
               $f > ${table}.tab
       hgLoadBed hg17 $table ${table}.tab
       checkTableCoords hg17 $table
    end
    # Reading encodeGisChipPetStat1Gif.tab
    # Loaded 4007 elements of size 12
    # Reading encodeGisChipPetStat1NoGif.tab
    # Loaded 3180 elements of size 12
    # NOTE: These counts correspond with the doc file they provided
    # Unlike the previous GIS Chip/chip dataset, these are only
    # in the ENCODE regions.  I requested the genome-wide
    # data -- they will provide  this later.


##########################################################################
# Genome Institute of Singapore - PET RNA (2005-10-19 kate)
# Submitted 10/11 by Atif Shahab
#       3 datasets - 5FU treated HCT116 cells, 
#                    MCF7 untreated 
#                    Estrogen-treated MCF7 (new)
# Replace data in existing subtracks, and add new one
    cd /cluster/data/encode/GIS
    mkdir -p rna/2005-10-11/lab
    # copy files from FTP dir
    cd rna/2005-10-11/lab
    ln -s MCF7_estrogen_treated.bed lab/MCF7Estr-hg17.bed

    # use Angie's loading process from hg16
cat > load.csh << 'EOF'
    foreach f (lab/HCT116-hg17.bed lab/MCF7-hg17.bed lab/MCF7Estr-hg17.bed)
      set cellType = `echo $f:t:r | sed -e 's/-hg17//'`
      echo $cellType
      set table = encodeGisRnaPet$cellType
      grep '^chr' $f | \
      perl -wpe \
     'chomp; @w = split; \
      if ($w[3] =~ /\d+-(\d+)-(\d+)/) { \
        ($mc, $ac) = ($1, $2, $3); \
        if ($mc == 1)   { $w[8] = ($ac > 1) ? "35,35,175" : "160,160,188"; } \
        elsif ($mc > 1) { $w[8] = ($ac > 1) ? "180,120,0" : "225,150,0"; } \
        else { die "mc $mc" } \
      } else { die "parse"; } \
      $_ = join(" ", @w) . "\n";'  > $table.bed
      hgLoadBed hg17 $table $table.bed
    end
'EOF'
csh load.csh >&! load.log
    rm *.bed

##########################################################################
# UCSD/Ludwig Institute Nimblegen chip/chip (2005-10-07 KATE)
#   New data submission

    ssh hgwdev
    cd /cluster/data/encode/UCSD/nimblegen
    mkdir 2005-09-29
    cd 2005-09-29
    mkdir lab
    # copy file from FTP dir, unzip and untar, into lab dir
    # 12 data files and README

cat > load.csh << 'EOF'
    foreach f (`ls lab/*.wig`)
        set table = `echo $f:t:r | sed -e 's/\(.*\)/encodeUcsdNgHeLa\u\1/'`
        echo $table
        grep '^chr' $f | hgLoadBed -onServer -bedGraph=4 hg17 $table stdin
        checkTableCoords hg17 $table
    end
'EOF'
    csh load.csh >&! load.log
    # Created hg17 composite track with all 16 datasets
    # The hg16 composite only has the first 4 submitted

##########################################################################
# UT-Austin (Vishy Iyer lab) Chip/chip  (2005-10-10 kate)
    cd /cluster/data/encode
    mkdir UTexas/2005-10-01/lab
    cd UTexas/2005-10-01/lab
    # copy file from FTP dir
    # 8 .wig data files (4 experiments, with raw data, and "peaks"), plus description file

cat > load.csh << 'EOF'
    foreach f (`ls lab/*.wig`)
        set table = `echo $f:t:r | sed -e 's/HeLa/HeLa_NoSerum/;s/NoSerum//;s/Serum4hr/Stim/;s/2091/2091fib/;s/\(.*\)_\(.*\)_\(.*\)_\(.*\)/encodeUtexChip\1\3\2\u\4/'`
        echo $table
        grep '^chr' $f | hgLoadBed -onServer -bedGraph=4 hg17 $table stdin
    checkTableCoords hg17 $table
    end
'EOF'
    csh load.csh >&! load.log
    # Created composite track with 8 subtracks
    
##########################################################################
# Affy Chip/chip and RNA (kate)
# submitted by Hari_Tammana@affymetrix.com (Oct. 3)
#  with clarifications as to display from Phil Kapranov at Affy
# HeLa data update submitted 12/15 by Hari Tamani

    cd /cluster/data/encode/Affy
    mkdir 2005-10-03/lab
    cd 2005-10-03/lab
    # copy file from FTP dir (500M) affy_oct1.tar.gz
    # two data dirs: CHIP, RNA
    # 10 descriptions for CHIP dir, 3 for RNA dir
    # RNA has 2 dirs (bed, wig) with each
    #   having 3 cell lines (GM06990, HeLa, HL60; the HL60
    #   data has 4 timepoints (0, 2, 8, 32)
    #  README's (and discussions with Phil) indicate the 
    #     wig's are replacements for previous RNA Signal
    #     data, and bed's are replacement Transfrags
    # The CHIP .wig files are similar to the previous
    #   Affy Pval data, but analyzed with stricter analysis
    #   criteria.  The .bed files are comparable to the Sites
    #  track.  2 factors are repeats from previous track
    #   (HisH4 TetraAc, Pol2), and 3 are new (H3K9K14DiAc, 
    # p63_ActD (with Actinomycin D treatment), 
    # p63_mActD (without Actinomycin D treatment)
    #  The Pol2, HisH4, and H3* data are at 4 timepoints.
    # These should be loaded in addition to previous tracks
    #  (not replacements).  Later the earlier ("lenient")
    #  analysis will be submitted for the 3 new factors,
    #  and these will be added to the previous Affy Chip/chip tracks
    #  on hg17.

    # Transfrags (6 subtracks)
    cd /cluster/data/encode/Affy/2005-10-03
    tail +2 lab/RNA/bed/GM06990/EC_AS_GM06990_RCyP+_C01vsNULL.sig.gr.bed \
    | hgLoadBed -noBin hg17 encodeAffyRnaGm06990Sites stdin
        # 4377 elements
    tail +2 lab/RNA/bed/HeLa/EC_AS_HeLaS3_RCyP+_C01vsNULL.sig.gr.bed \
    | hgLoadBed -noBin hg17 encodeAffyRnaHeLaSites stdin
        # 2037 elements
cat > loadSites.csh << 'EOF'
    foreach f (lab/RNA/bed/HL60/??/*HL60*.bed)
      set track = `echo $f:t:r:r:r | perl -wpe \
        's/EC_AS_HL60_RWP\+_RA_(\d+)hr_C01vsNULL/encodeAffyRnaHl60SitesHr$1/;'`
      echo $track
      tail +2 $f \
        | hgLoadBed -noBin hg17 $track stdin
    end    
'EOF'
    csh loadSites.csh >&! loadSites.log

    # Update HeLa sites (12/15)
    cd /cluster/data/encode/Affy/2005-11-22
    tail +2 lab//Affy_HeLa/bed/EC_AS_HeLa_RCyP+_C01vsNULL.sig.gr.bed | \
        hgLoadBed -strict -noBin hg17 encodeAffyRnaHeLaSites stdin
            # 7254 elements

    # RNA Signal (6 subtracks)
    set gbdbDir = /gbdb/hg17/encode/Affy/2005-10-03
    mkdir -p $gbdbDir/wib
    mkdir wib wig

    set track = encodeAffyRnaGm06990Signal
    cat lab/RNA/wig/GM06990/EC_AS_GM06990_RCyP+_C01vsNULL.sig.wig \
    | wigEncode stdin wig/$track.wig wib/$track.wib
    ln -s `pwd`/wib/$track.wib $gbdbDir/wib/
    nice hgLoadWiggle hg17 $track wig/$track.wig -pathPrefix=$gbdbDir

    set track = encodeAffyRnaHeLaSignal
    cat lab/RNA/wig/HeLa/EC_AS_HeLa_RCyP+_C01vsNULL.sig.wig \
    | wigEncode stdin wig/$track.wig wib/$track.wib
    ln -s `pwd`/wib/$track.wib $gbdbDir/wib/
    nice hgLoadWiggle hg17 $track wig/$track.wig -pathPrefix=$gbdbDir

cat > loadSig.csh << 'EOF'
    set gbdbDir = /gbdb/hg17/encode/Affy/2005-10-03
    foreach f (lab/RNA/wig/HL60/??/*HL60*C01vsNULL.sig.wig)
      set track = `echo $f:t:r:r:r | perl -wpe \
       's/EC_AS_HL60_RWP\+_RA_(\d+)hr_C01vsNULL/encodeAffyRnaHl60SignalHr$1/;'`
      echo $track
      cat $f \
      | wigEncode stdin wig/$track.wig wib/$track.wib
      ln -s `pwd`/wib/$track.wib $gbdbDir/wib/
      nice hgLoadWiggle hg17 $track wig/$track.wig -pathPrefix=$gbdbDir
    end
'EOF'
    csh loadSig.csh >&! loadSig.log
    # Create a single composite track for RNA and Transfrags

    # Update HeLa signal (2005-12-15 kate)
    cd /cluster/data/encode/Affy/2005-11-22
    mkdir wib wig
    set gbdbDir = /gbdb/hg17/encode/Affy/2005-10-03
    rm $gbdbDir/wib/$track.wib
    set track = encodeAffyRnaHeLaSignal
    cat lab/Affy_HeLa/wig/EC_AS_HeLa_RCyP+_C01vsNULL.sig.wig | \
        wigEncode stdin wig/$track.wig wib/$track.wib
            # Converted stdin, upper limit 1591.50, lower limit -779.75
    ln -s `pwd`/wib/$track.wib $gbdbDir/wib/
    nice hgLoadWiggle hg17 $track wig/$track.wig -pathPrefix=$gbdbDir

    # CHIP/Chip sites (2005-10-24 kate)
    cd /cluster/data/encode/Affy/2005-10-03
    # Load up 12 tables of ChIP/chip sites at (3 factors, 4 timepoints)
    # plus 2 more for ActD at 1 timepoint
cat > loadChipBed.csh << 'EOF'
    foreach f (lab/CHIP/bed/*/??/*.bed)
      set factor = `echo $f:h:h:t | sed 's/Pol2/Rnap/; s/Hish4/H4Kac4/'`
      set hr = $f:h:t
      set table = encodeAffyChIpHl60SitesStrict${factor}Hr$hr
      echo $table
      grep "^chr" $f | hgLoadBed -noBin hg17 $table stdin
    end
    grep "^chr" lab/CHIP/bed/p63_ActD/*.bed | hgLoadBed -noBin hg17 \
                encodeAffyChIpHl60SitesStrictP63_ActD stdin
    grep "^chr" lab/CHIP/bed/p63_mActD/*.bed | hgLoadBed -noBin hg17 \
                encodeAffyChIpHl60SitesStrictP63_mActD stdin
'EOF'
    csh loadChipBed.csh >&! loadChipBed.log

    # Chip/chip signal and pvalue 
cat > loadChipWig.csh << 'EOF'
    set gbdbDir = /gbdb/hg17/encode/Affy/2005-10-03
    foreach d (lab/CHIP/wig/p63_ActD lab/CHIP/wig/p63_mActD)
        set factor = $d:t
        set prefix = encodeAffyChIpHl60;
        set track = ${prefix}SignalStrict$factor
        echo $track
        cat $d/*.sig.median.wig \
            | wigEncode stdin wig/$track.wig wib/$track.wib
        ln -s `pwd`/wib/$track.wib $gbdbDir/wib/
        nice hgLoadWiggle hg17 $track wig/$track.wig -pathPrefix=$gbdbDir
        set track = ${prefix}PvalStrict$factor
        echo $track
        cat $d/*.pval.median.wig \
            | wigEncode stdin wig/$track.wig wib/$track.wib
        ln -s `pwd`/wib/$track.wib $gbdbDir/wib/
        nice hgLoadWiggle hg17 $track wig/$track.wig -pathPrefix=$gbdbDir
    end
    foreach d (lab/CHIP/wig/*/??)
        set hr = $d:t
        set factor = $d:h:t
        set track = ${prefix}SignalStrict${factor}Hr$hr
        echo $track
        cat $d/*.sig.median.wig \
            | wigEncode stdin wig/$track.wig wib/$track.wib
        ln -s `pwd`/wib/$track.wib $gbdbDir/wib/
        nice hgLoadWiggle hg17 $track wig/$track.wig -pathPrefix=$gbdbDir
        set track = ${prefix}PvalStrict${factor}Hr$hr
        echo $track
        cat $d/*.pval.median.wig \
            | wigEncode stdin wig/$track.wig wib/$track.wib
        ln -s `pwd`/wib/$track.wib $gbdbDir/wib/
        nice hgLoadWiggle hg17 $track wig/$track.wig -pathPrefix=$gbdbDir
    end
'EOF'
    csh loadChipWig.csh >&! loadChipWig.log 
    # create 2 composite tracks:
    #  Affy Strict ChIP  (contains Oct freeze Sites and Pval subtracks)
    #  Affy Strict Sig  (contains Oct freeze Signal) 
    # and reformat June freeze tracks (2 composites w/ 10 factors each) as:
    #  Affy Loose ChIP  (contains Jun freeze Sites and Pval subtracks)

##########################################################################
# U North Carolina FAIRE  (2005-10-24 kate)
#       Peaks data updated (2006-04-13 kate)
    # submitted by Paul Giresi, from Jason Lieb's lab
    # later, Paul submitted an "averages" file for the
    # raw data (but doesn't include the "peaks")
    # On 10/24, submitted peaks averages.
    cd /cluster/data/encode
    mkdir UNC/2005-10-10/lab
    cd UNC/2005-10-10/lab
    # copy files from FTP dir
    # 8 .gff data files plus description file
    # NOTE: these are actually .bed and .wig files
    # the .bed files are "peaks", and the .wig are "raw"
    # NOTE: these files are basically replicates,
    # we really want to show just the averages -- 
    # Submitter says OK to just post for download

    mkdir -p download
    # convert to UNIX format
    foreach f (lab/*norm*.gff)
        set t = $f:t:r
        echo $t
        dos2unix -n $f download/$t.bed
    end
    # slightly different format for "peaks" files
    foreach f (lab/*fpr01*.gff)
        set t = $f:t:r
        echo $t
        dos2unix -l -n $f download/$t.bed
    end
    cd download
    gzip *.bed
    md5sum *.bed > md5sum.txt
    # add README file with data terms

    ssh hgwdev
    set dir = /usr/local/apache/htdocs/goldenPath/hg17/encode/datafiles
    mkdir -p $dir
    ln -s /cluster/data/encode/UNC/2005-10-10/download $dir/UncFaire

    # averages 
    sed 's/span=50/span=38/' lab/FAIREavg_data.gff > Signal.wig
    sed 's/span=50/span=38/' lab/FAIREavg_peaks.gff > Peaks.wig
    #_data.gff:  -2.61 to 3.63
    #_peaks.gff:   .47 to 3.63
    # using viewLimits: .2 to 2.6
    # wiggle0 with span=50
    # around 380K records, so load it wiggle, not bedGraph
cat > load.csh << 'EOF'
    foreach f (Signal.wig Peaks.wig)
        set type = $f:r
        set table = encodeUncFaire$type
        wigEncode $f $table.wig $table.wib
        set dir = /gbdb/hg17/encode/UNC/2005-10-10
        mkdir -p $dir
        hgLoadWiggle -pathPrefix=$dir hg17 $table $table.wig
        mkdir -p $dir
        ln -s `pwd`/$table.wib $dir
    end
'EOF'
    csh load.csh >&! load.log 

    # update peaks data (2006-04-13 kate)
    cd /cluster/data/encode
    mkdir UNC/2006-04-13/lab
    cd UNC/2006-04-13/lab

    # trim precision
    awk 'NR !=1 {printf("%s\t%d\t%d\t%.3f\n", $1, $2, $3, $4)}' \
        lab/OfficialChIPOTle_PEAKS.gff > peaks.bedGraph
    # data range: 0 - 3.627
    

##########################################################################
# Gencode Genes (2005-10-10 kate)
#    Files are on Gencode/IMIM web site, our contact for this round is France Denoed
#    France requested 3 subtracks: genes, putatives, and pseudogenes        
# NTOE: reloaded encodeGencodeKnown from updated _genes_ file 10/14 (kate)
    cd /cluster/data/encode
    mkdir -p Gencode/2005-10-07/lab
    cd Gencode/2005-10-07/lab

    wget ftp://genome.imim.es/pub/other/gencode/data/havana-encode/current/44regions/README
    wget ftp://genome.imim.es/pub/other/gencode/data/havana-encode/current/44regions/44regions_genes_CHR_coord.gtf
    wget ftp://genome.imim.es/pub/other/gencode/data/havana-encode/current/44regions/44regions_putative_CHR_coord.gtf
    wget ftp://genome.imim.es/pub/other/gencode/data/havana-encode/current/44regions/44regions_pseudogenes_CHR_coord.gtf

    cd ..
    ldHgGene -gtf -genePredExt hg17 encodeGencodeKnown \
        lab/44regions_genes_CHR_coord.gtf

            # Read 2637 transcripts in 45565 lines in 1 files
            # 2637 groups 21 seqs 13 sources 5 feature types
            # 2608 gene predictions
    genePredCheck -db=hg17 encodeGencodeKnown

    ldHgGene -gtf -genePredExt hg17 encodeGencodePutative lab/44regions_putative_CHR_coord.gtf
            # 156 gene predictions
    genePredCheck -db=hg17 encodeGencodePutative

    ldHgGene -gtf -genePredExt hg17 encodeGencodePseudo lab/44regions_pseudogenes_CHR_coord.gtf
            # 197 gene predictions
    genePredCheck -db=hg17 encodeGencodePutative
    # create composite track: "Gencode Oct Gene" with 3 subtracks

    # Introns track
    grep intron lab/*.gtf | wc -l
        # 25421
    # ignore "not tested" introns
    grep intron lab/*.gtf | grep -v not_tested | wc -l
        # 483
    # NOTE: need verision of loader with new status value added
    cat lab/*.gtf | grep -v not_tested | sed -e 's/-intron/-/g' | \
        ~/bin/i386/ldGencodeIntron hg17 encodeGencodeIntronOct stdin
            # 483 introns in 1 files

    # create gene class table
    sed 's/gencodeGeneClass/gencodeGeneClassOct/' \
        ~/kent/src/hg/lib/gencodeGeneClass.sql | hgsql hg17
    cat lab/*.gtf | grep VEGA | \
        awk '{printf "%s\t%s\n", $10, $2}' | \
        sed -e 's/"//g' -e 's/;//' -e 's/VEGA_//' \
            -e 's/_val/_gencode_conf/' -e 's/Antisense/Novel_transcript/' | \
        sort | uniq > gencodeGeneClassOct.tab
    wc -l gencodeGeneClassOct.tab
        #  2961
    echo "LOAD DATA LOCAL INFILE 'gencodeGeneClassOct.tab' into table gencodeGeneClassOct" | hgsql hg17


##########################################################################
# NHGRI DNaseI HS (2005-10-24 kate)
#       Submitter: Greg Crawford
#       2 datasets:  CD4, GM06690 with different methodology from previous
#       Additional (raw) data for both cell types submitted 12/6

    cd /cluster/data/encode/NHGRI/crawford
    mkdir -p 2005-10-11/lab
    cd 2005-10-11/lab
    # copy 2 data files from FTP site

    # lift to hg17
    ln -s lab/Crawford_DNase_chip_CD4_hg16.txt Cd4.hg16.bed
    awk '{printf "%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$6}' \
        lab/Crawford_DNase_chip_GM06990_hg16.txt > Gm06990.hg16.bed
cat > load.csh << 'EOF'
    foreach f (Cd4.hg16.bed Gm06990.hg16.bed)
        set cell = $f:r:r
        liftOver $cell.hg16.bed \
                 /cluster/data/hg16/bed/liftOver/hg16ToHg17.over.chain \
                        $cell.hg17.bed $cell.unmapped
        hgLoadBed hg17 encodeNhgriDnaseHsChip$cell $cell.hg17.bed
    end
'EOF'
    csh load.csh >&! load.log

    # Add these two tracks to the hg17 NHGRI DNase track
    # Rename 2 data tables lifted from hg16
    hgsql hg17 -e "ALTER TABLE encodeNhgriDnaseHsAct RENAME TO encodeNhgriDnaseHsMpssCd4Act"
    hgsql hg17 -e "ALTER TABLE encodeNhgriDnaseHsNonAct RENAME TO encodeNhgriDnaseHsMpssCd4"

    # Raw data
    ln -s lab/NHGRI_DNase_chip_CD4_na_RAW.bed Cd4.raw.hg16.bed
    ln -s lab/NHGRI_DNase_chip_GM_RAW.bed  Gm06990.raw.hg16.bed
cat > loadRaw.csh << 'EOF'
    foreach f (Cd4.raw.hg16.bed Gm06990.raw.hg16.bed)
        set cell = $f:r:r:r
        liftOver $f \
                 /cluster/data/hg16/bed/liftOver/hg16ToHg17.over.chain \
                        $cell.raw.hg17.bed $cell.raw.unmapped
        hgLoadBed -strict -bedGraph=4 hg17 \
                encodeNhgriDnaseHsChipRaw$cell $cell.raw.hg17.bed
    end
'EOF'
    csh loadRaw.csh >&! loadRaw.log

##########################################################################
# Sanger Chip/chip Hits and Centers (2005-10-24 kate)
    # From Paul Flicek, at EBI 
    # 14 files (3 cells, most with 5 factors), each file having
    # 3 tracks:  chip/chip, HMM regions, HMM centers
    # Christoph says to just display the HMM regions & centers tracks
    # from Paul's files. These were generated from June freeze
    # chip/chip, plus newly submitted HeLa data from Christoph Koch (10/7).
    cd /cluster/data/encode/sanger/chipchip
    mkdir -p 2005-10-18/lab
    cd 2005-10-18/lab

    # HeLa chip/chip
cat > loadHela.csh << 'EOF'
    foreach f (lab/*_HeLa-S3_1.wig.txt)
        set b = `echo $f:t:r:r | sed 's/-S3_1//; s/_//'`
        echo $b
        grep "^chr" $f | sort -k1,1 -k2,2n > chip.$b.wig
        hgLoadBed -bedGraph=4 hg17 encodeSangerChip$b chip.$b.wig 
    end
'EOF'
    csh loadHela.csh >&! loadHela.log &

    # split HMM tracks out of files
cat > load.csh << 'EOF'
    foreach f (lab/*.split.wig.txt)
        set b = `echo $f:t:r:r:r | sed 's/-2//; s/-//g'`
        echo $b
        /cluster/data/encode/bin/scripts/splitTracks.pl $f
        rm t0
        grep '^chr' t1 | sort -k1,1 -k2,2n > $b.wig; rm t1
        hgLoadBed -bedGraph=4 hg17 encodeSangerChipHit$b $b.wig
        checkTableCoords hg17 encodeSangerChipHit$b
        grep '^chr' t2 | sed 's/	1$//' > $b.bed; rm t2
        hgLoadBed -noBin hg17 encodeSangerChipCenter$b $b.bed
        checkTableCoords hg17 encodeSangerChipCenter$b
    end
'EOF'
    csh load.csh >&! load.log 
    
#############################################################################
#  Measuring TARs and TransFrags distances to SINEs and LINEs
#
#
#	Using the table browser on genome.ucsc.edu on Hg17, select the
#	Alu SINEs and L1,L2 LINEs by setting filter at:
#	repClass=LINE or SINE
#	repFamily=L1, L2 or Alu
#	request fields: swScore, genoName, genoStart, genoEnd, repNames
#	save to file L1_LINE_Hg17.txt.gz, L2_LINE_Hg17.txt.gz
#	Alu_SINE_Hg17.txt.gz
##########################################################################
# UW/Regulome DnaseI HS (2005-10-28, 11-17 kate)
# NOTE: trimmed overlaps in baseline files, as per Scott Kuehn

    cd /cluster/data/encode/Regulome
    mkdir -p 2005-11-16
    cd 2005-11-16
cat > load.csh << 'EOF'
    foreach cell (CACO2 CD34 GM HeLa HepG2 Huh7 K562 SKNSH)
        echo $cell
        hgLoadBed -noBin -strict hg17 \
            encodeRegulomeQuality$cell lab/$cell.qc.bed
        hgLoadBed -noBin -strict hg17 \
            encodeRegulomeAmplOdd$cell lab/$cell.oddAmps.bed
        hgLoadBed -noBin -strict hg17 \
            encodeRegulomeAmplEven$cell lab/$cell.evenAmps.bed
        hgLoadBed -noBin -strict -bedGraph=5 hg17 \
            encodeRegulomeProb$cell lab/$cell.hs.bed
        sort -k1,1 -k2,2n lab/$cell.baseline.bed | \
            /cluster/data/encode/bin/scripts/trimOverlap.pl | \
            hgLoadBed -noSort -noBin -strict -bedGraph=5 hg17 \
                encodeRegulomeBase$cell stdin
    end
'EOF'
    csh load.csh >&! load.log &

##########################################################################
# UC Davis Chip/chip (new C-Myc data) (2005-10-29 kate)
# Add as subtrack to existing track

    # convert to bedGraph
    cd /cluster/data/encode/UcDavis/2005-10-12
    set table = encodeUCDavisChipMyc
    awk '{printf "%s\t%s\t%s\t%s\n", $1,$4,$5,$6}' lab/myc_median.gff | \
	sort -k1,1 -k2,2n > $table.bed
    hgLoadBed -strict -bedGraph=4 hg17 $table $table.bed
        # Loaded 385149 elements

##########################################################################
# Yale TAR and TransMap (2005-10-31 kate)
# Submitted: 10/14 by Joel Rozowsky
# 5 bed files (TARs) and 5 wig files (Signal)
# Replacements for June tracks (and drop individual 10 Neu samples)
# Methods changed somewhat -- use new description from Joel's email
# NOTE: adjusted start coord -1 to coorespond to their DART entries --
# verifying with Joel

    cd /cluster/data/encode/yale/rna/2005-10-14
cat > loadBed.csh << 'EOF'
    foreach f (lab/*.bed)
        set table = `echo $f:t:r | sed 's/_//g; s/CTRL/Untr/; s/ncbi35//; s/Placenta/Plac/; s/Neutrophil/Neut/'`
        echo $table
        sed 's/http.*acc=//' $f | \
            awk '{printf "%s\t%d\t%d\t%s\n", $1, $2-1, $3, $4}' | \
                hgLoadBed -strict hg17 $table stdin
    end
'EOF'
    csh loadBed.csh >&! loadBed.log 

# NOTE: trim overlaps in regions resulting from array design
# Joel should have done this for us -- he will verify the files.
# Also, need to adjust coords +1 as per J. Rozowsky
cat > loadSig.csh << 'EOF'
    mkdir -p wig wib
    set gdir = /gbdb/hg17/encode/YaleRna/2005-10-14
    mkdir -p $gdir/wib
    foreach f (lab/*.wig)
        set table = `echo $f:t:r | sed 's/_//g; s/Transcript/Trans/; s/CTRL/Untr/; s/ncbi35//; s/Placenta/Plac/; s/Neutrophil/Neut/'`
        echo $table
        grep "^chr" $f | \
            awk '{printf "%s\t%d\t%d\t%s\n", $1, $2+1, $3+1, $4}' | \
            sort -k1,1 -k2,2n | \
            /cluster/data/encode/bin/scripts/trimOverlap.pl > $table.trim
        wigEncode $table.trim wig/$table.wig wib/$table.wib
        hgLoadWiggle -pathPrefix=$gdir hg17 $table wig/$table.wig
        ln -s `pwd`/wib/$table.wib $gdir/wib
    end
'EOF'
    csh loadSig.csh >&! loadSig.log 
    rm -f *.trim
    
##########################################################################
# Yale Chip/chip (2005-10-31 kate)
# Final submission: 10/26 by Zhengdong Zhang
# signal, pval, and sites for 5 factors (50x38 array)
# Sites file has URL to Gerstein lab as 5th field.
# I'm extracting the accession from it and saving
# as the name field in a BED5.  Score range: .602-3.23
#  Scale *330 produces integer range 200-1000.
# NOTE: >50% of sites are < 1 data value, so use 200 as low score

    cd /cluster/data/encode/yale/chip/2005-10-26
    mkdir -p wig wib
cat > loadSites.csh << 'EOF'
    set pfx = encodeYaleChip
    foreach d (lab/{jun,fos,taf,baf155,baf170})
        set factor = $d:t
        set Factor = `echo $factor | sed 's/\(.*\)/\u\1/'`
        echo $Factor
        set p = $d/Encode_Yale_ChIpChip_${factor}_Hela_Maskless50merevery38bp

        # load sites
        set table = ${pfx}Sites$Factor
        echo $table
        set f = ${p}_Sites.bed
        dos2unix $f
        sed -e "s/bed5FloatScore/$table/" \
            $HOME/kent/src/hg/lib/bed5FloatScore.sql > $table.sql
        sed 's/=/ /' $f | \
          awk '{printf "%s\t%d\t%d\t%s\t%d\t%.3f\n",$1,$2-1,$3,$6,($4 * 330),$4}' |\
            hgLoadBed -strict -sqlTable=$table.sql hg17 $table stdin
        end
'EOF'
    csh loadSites.csh >&! loadSites.log 

cat > loadSig.csh << 'EOF'
    set pfx = encodeYaleChip
    foreach d (lab/{jun,fos,taf,baf155,baf170})
        set factor = $d:t
        set Factor = `echo $factor | sed 's/\(.*\)/\u\1/'`
        echo $Factor
        set p = $d/Encode_Yale_ChIpChip_${factor}_Hela_Maskless50merevery38bp

        # load pval 
        set table = ${pfx}Pval$Factor
        echo $table
        set f = ${p}_Pvalue.wig
        sort -k1,1 -k2,2n $f | \
            /cluster/data/encode/bin/scripts/trimOverlap.pl > $table.trim
        hgLoadBed -strict -bedGraph=4 hg17 $table $table.trim

        # load signal 
        set table = ${pfx}Signal$Factor
        echo $table
        set f = ${p}_Signal.wig
        sort -k1,1 -k2,2n $f | \
            /cluster/data/encode/bin/scripts/trimOverlap.pl > $table.trim
        hgLoadBed -strict -bedGraph=4 hg17 $table $table.trim 
    end
'EOF'
    csh loadSig.csh >&! loadSig.log &
    rm -f *.trim *.sql

    # description files
    # use server with "antiword" available
    foreach d (lab/{jun,fos,taf,baf155,baf170})
        antiword $d/*.doc > ${d:t}.txt
    end

##########################################################################
# UTexas STAGE (2005-10-31, 11-17 kate)
# Submitted 10/15 by Akshay Bhinge <akshayb@mail.utexas.edu>
# Resubmitted 11/17
#  2 files - raw and peaks, for c-Myc in HeLa
# range .001 to 1.0.  Peaks restricted to >.8
# Adjusted data in Tags file:  set score=1 items to 300 so
# they'll be visible with gray-scale tags requested by Akshay.
# (This is why it's loaded as blocked bed)

    #cd /cluster/data/encode/UTexas/stage/2005-10-15
    cd /cluster/data/encode/UTexas/stage/2005-11-17
    grep '^chr' lab/myc.tag.prob.bed | \
        awk '{if ($5 == 1) $5 = 300; \
                printf("%s\t%d\t%d\t%s\t%d\t%s\t%d\t%d\t0\t1\t%d,\t0\n", \
                $1, $2, $3, $4, $5, $6, $2, $3, $3 - $2)}' | \
        hgLoadBed -noBin -strict hg17 encodeUtexStageMycHelaTags stdin
            # 813 elements
    grep '^chr' lab/myc.stage.peaks.bed | \
        hgLoadBed -noBin -strict hg17 \
                encodeUtexStageMycHelaPeaks  stdin
            # 26 elements
    # Created composite track with 2 subtracks
    
##########################################################################
# Univ. Uppsala, Sweden Chip/chip
# Submitted by Claes & Ola
# 4 files with chrom, start, end, integer score
# Sites file in GFF format
# NOTE: this was submitted in hg16, without notifying us.
# I'm reloading after lifting, 2005-12-05

    cd /cluster/data/encode/Uppsala/2005-11-07
    /cluster/data/encode/bin/scripts/splitTracks.pl lab/chip.wig
    mv t0 Usf1.wig
    mv t1 Hnf3b.wig
    mv t2 Hnf4a.wig
    mv t3 Ach3.wig
    mv t4 Sites.gff

    # load data for individual factors
    # NOTE: rounded overly long float scores
cat > load.csh << 'EOF'
    foreach factor (Usf1 Hnf3b Hnf4a Ach3)
      awk '/^chr/ {printf("%s\t%s\t%s\t%.3f\n", $1, $2, $3, $4)}' $factor.wig |\
        liftOver stdin /cluster/data/encode/convertHg17/hg16ToHg17.chain \
                $factor.hg17.bed $factor.unmapped
        hgLoadBed -strict -bedGraph=4 hg17 encodeUppsalaChip$factor $factor.hg17.bed
    end
'EOF'
    csh load.csh >&! load.log &
    
    # sites (they refer to as Tentative Binding Sites)
    # NOTE: I added an item name, of the form "uutbs.#"
    grep -v track Sites.gff | sort -k1,1 -k2,2n | \
        awk '{printf ("%s\t%d\t%d\tuutbs.%d\t%d\n", $1, $4, $5, NR, $6)}' | \
            liftOver stdin /cluster/data/encode/convertHg17/hg16ToHg17.chain \
                sites.hg17.bed sites.unmapped
            hgLoadBed -noSort -noBin -strict hg17 encodeUppsalaChipSites sites.hg17.bed
                # Loaded 327 elements of size 5

##########################################################################
# MSA tracks from Sept. 2005 freeze
# Use links from Wiki for data submission (as per Elliott Margulies)
# NOTE: mapping of sequence name to assembly is in column 7 of
# metadata.txt file in Elliott's MSA release
# Assemblies in this freeze are: canFam1 danRer2 fr1 galGal2 mm6
#       monDom1 panTro1 rheMac1 rn3 tetNig1

    # TBA alignments
    cd /cluster/data/encode/TBA
    mkdir -p SEP-05/lab
    cd SEP-05/lab
    wget ftp://kronos.nhgri.nih.gov/pub/outgoing/elliott/msa/SEP-2005/tba.v2.maf.tar

    cd ..
    foreach f (lab/*/*.maf.gz)
        echo $f
        gunzip -c $f | \
            sed 's/^s human\./s hg17./;          s/^s dog\./s canFam1./; \
                 s/^s zebrafish\./s danRer2./;   s/^s fugu\./s fr1./; \
                 s/^s chicken\./s galGal2./;     s/^s mouse\./s mm6./; \
                 s/^s monodelphis\./s monDom1./; s/^s chimp\./s panTro1./; \
                 s/^s macaque\./s rheMac1./;     s/^s rat\./s rn3./; \
                 s/^s tetraodon\./s tetNig1./;' \
                        > $f:t:r:r:e.maf
    end
    set gdir = /gbdb/hg17/encode/TBA/maf
    mkdir -p $gdir
    rm -f $gdir/*.maf
    ln -s /cluster/data/encode/TBA/SEP-05/*.maf $gdir
    hgLoadMaf -pathPrefix=$gdir -WARN hg17 encodeTbaAlign >&! load.log
    # lots of "score too small" messages -- these are OK.
    cat *.maf | hgLoadMafSummary hg17 encodeTbaSummary stdin

    #  MLAGAN alignments
    cd /cluster/data/encode/MLAGAN
    mkdir -p SEP-05/lab
    cd SEP-05/lab
    wget http://ai.stanford.edu/~asimenos/ENCODE_Oct-2005_maf.tgz
    cd ..
cat > project.csh << 'EOF'
    mkdir -p tmp
    set tmpDir = tmp
    foreach d (lab/EN[mr]*)
        set r = $d:t
        echo $r
        set c = `echo "SELECT chrom from encodeRegions WHERE name='$r'" | \
                        hgsql -N hg17`
        set start =  \
                `echo "SELECT chromStart from encodeRegions WHERE name='$r'" | \
                        hgsql -N hg17`
        set size = \
                `echo "SELECT size from chromInfo WHERE chrom='$c'" | \
                        hgsql -N hg17`
        /cluster/data/encode/MLAGAN/mafCoord.pl < $d/$r.maf \
                human.1 hg17.$c $start $size | \
            sed 's/^a$/a score=0.0/' > $tmpDir/$r.db.maf
        echo "projecting $r"
        /cluster/bin/penn/maf_project $tmpDir/$r.db.maf hg17.$c > $r.maf
        echo "finished $r"
    end
'EOF'
    set gdir = /gbdb/hg17/encode/MLAGAN/SEP-05/maf
    mkdir -p $gdir
    rm -f $gdir/*.maf
    ln -s /cluster/data/encode/MLAGAN/SEP-05/*.maf $gdir
    hgLoadMaf -pathPrefix=$gdir -WARN hg17 encodeMlaganAlign >&! load.log
    # lots of "score too small" messages -- these are OK.
    cat *.maf | hgLoadMafSummary hg17 encodeMlaganSummary stdin

    # MAVID alignments
    cd /cluster/data/encode/MAVID
    mkdir -p SEP-05/lab
    cd SEP-05/lab
    wget http://hanuman.math.berkeley.edu/~cdewey/encode/alignments/ENCODE_SEP-2005_MAVID_MAF_ABS.tar.gz
    cd ..
cat > project.csh << 'EOF'
    set tmpDir = tmp
    mkdir $tmpDir
    foreach f (lab/ABS/*.maf)
        set r = $f:t:r
        echo $r
        set c = `echo "SELECT chrom from encodeRegions WHERE name='$r'" | \
                        hgsql -N hg17`
        sed 's/^a$/a score=0.0/; s/^s  *human/s hg17/' $f > $tmpDir/$r.maf
        echo "projecting $r"
        /cluster/bin/penn/maf_project $tmpDir/$r.maf hg17.$c > $r.maf
        echo "finished $r"
    end
'EOF'
    set gdir = /gbdb/hg17/encode/MAVID/SEP-05/maf
    mkdir -p $gdir
    rm -f $gdir/*.maf
    ln -s /cluster/data/encode/MAVID/SEP-05/*.maf $gdir
    hgLoadMaf -pathPrefix=$gdir -WARN hg17 encodeMavidAlign >&! load.log
    cat *.maf | hgLoadMafSummary hg17 encodeMavidSummary stdin

    # conserved elements
    # Scores:  binCons are all 1000, gerp range is 6.75 - 4813.26
    #          phastCons is 10-18088
    # Force gerp to integer for consistent table format, but don't
    # bother scaling at this point (and don't use to score on display)
    # For some reason, phastCons has + strand -- strip this out
    # NOTE: coords are ENCODE-region based, so need to adjust
    # by start of region (Elliott used custom tracks offset= to do this).

    # NOTE: Updated GERP elements 2/1/06, with new data from Greg Cooper
    # overwriting Elliott's elements.  This is doc'ed in the GERP section.
    cd /cluster/data/encode/MSA
    mkdir -p SEP-05/elements/lab
    cd SEP-05/elements/lab
    wget ftp://kronos.nhgri.nih.gov/pub/outgoing/elliott/msa/SEP-2005/cons/target.align.conservation.v1.tar.gz
    cd ..
cat > load.csh << 'EOF'
    foreach d (lab/{tba,mlagan,mavid})
        set align = `echo $d:t | sed 's/\(.*\)/\u\1/'`
        set bTable = encode${align}BinConsEl
        set pTable = encode${align}PhastConsEl
        set gTable = encode${align}GerpEl
        rm -f $bTable.bed $pTable.bed $gTable.bed
        foreach rd ($d/*)
            set region = $rd:t
            set offset = `sed -n 's/.*offset=\([0-9][0-9]*\)$/\1/p' \
                        $rd/human.$region.gerp.bed`
            echo "$align $region"
            awk -v OFFSET=$offset \
                '/^chr/ {printf("%s\t%d\t%d\t%s\t%d\n", \
                $1,$2+OFFSET,$3+OFFSET,$4,$5)}' \
                        $rd/human.$region.binCons.bed >> $bTable.bed
            awk -v OFFSET=$offset \
                '/^chr/ {printf("%s\t%d\t%d\t%s\t%d\n", \
                $1,$2+OFFSET,$3+OFFSET,$4,$5)}' \
                        $rd/human.$region.phastCons.bed >> $pTable.bed
            awk -v OFFSET=$offset \
                '/^chr/ {printf("%s\t%d\t%d\t%s\t%.0f\n", \
                $1,$2+OFFSET,$3+OFFSET,$4,$5)}' \
                        $rd/human.$region.gerp.bed >> $gTable.bed
        end
        hgLoadBed -strict hg17 $bTable $bTable.bed
        hgLoadBed -strict hg17 $pTable $pTable.bed
        hgLoadBed -strict hg17 $gTable $gTable.bed
    end
'EOF'
    csh load.csh >&! load.log &

    # consensus elements
    cd /cluster/data/encode/MSA
    mkdir -p SEP-05/consensus/lab
    cd SEP-05/consensus/lab
    wget ftp://kronos.nhgri.nih.gov/pub/outgoing/elliott/msa/SEP-2005/cons/consensus.conservation.v1.tar.gz
    cd ..
    ln -s lab/or.or.bed MsaElUnion.bed
    ln -s lab/and.and.bed MsaElIntersect.bed
    ln -s lab/two.two.bed MsaElModerate.bed
cat > load.csh << 'EOF'
    foreach f (MsaEl*.bed)
        echo $f
        set b = $f:r
        set t = encode$b
        hgLoadBed -strict -noBin hg17 $t $f
    end
'EOF'
    csh load.csh >&! load.log
        #Reading MsaElIntersect.bed
        #Loaded 30645 elements of size 4
        #Reading MsaElModerate.bed
        #Loaded 36793 elements of size 4

    # conservation
    cd /cluster/data/encode/MSA
    mkdir -p SEP-05/conservation/lab
    cd SEP-05/conservation/lab
    wget ftp://kronos.nhgri.nih.gov/pub/outgoing/elliott/msa/SEP-2005/cons/phastCons.wig.tar.gz
    cd ..
cat > load.csh << 'EOF'
    # TBA
    gunzip -c lab/tba/*/phast/human.ENm*.gz | \
        wigEncode stdin tbaPhastCons.wig tbaPhastCons.wib
    set d = /gbdb/hg17/encode/TBA/SEP-05
    ln -s `pwd`/tbaPhastCons.wib $d
    hgLoadWiggle -pathPrefix=$d hg17 encodeTbaPhastCons tbaPhastCons.wig

    # MLAGAN
    gunzip -c lab/mlagan/*/phast/human.ENm*.gz | \
        wigEncode stdin mlaganPhastCons.wig mlaganPhastCons.wib
    set d = /gbdb/hg17/encode/MLAGAN/SEP-05
    ln -s `pwd`/mlaganPhastCons.wib $d
    hgLoadWiggle -pathPrefix=$d hg17 encodeMlaganPhastCons mlaganPhastCons.wig

    # MAVID
    gunzip -c lab/mavid/*/phast/human.ENm*.gz | \
        wigEncode stdin mavidPhastCons.wig mavidPhastCons.wib
    set d = /gbdb/hg17/encode/MAVID/SEP-05
    ln -s `pwd`/mavidPhastCons.wib $d
    hgLoadWiggle -pathPrefix=$d hg17 encodeMavidPhastCons mavidPhastCons.wig

'EOF'
    csh load.csh >&! load.log

##########################################################################
# MSA GERP Conservation (2005-02-06 kate)
#  Submitted 2/1/06 by Greg Coooper

    cd /cluster/data/encode/MSA/Gerp
    mkdir -p 2006-02-01/lab
    cd 2006-02-01/lab
    wget http://baumbox.stanford.edu/~coopergm/ENCODE/GERP_Cons_SepFreeze_Jan.zip 
    unzip GERP_Cons_SepFreeze_Jan.zip 
    cd ..

    # TBA
    cat lab/chr*_GERP_TBA_scores.wig | \
        wigEncode stdin tbaGerpCons.wig tbaGerpCons.wib
        #  upper limit 4.48, lower limit -29.86
    set d = /gbdb/hg17/encode/TBA/SEP-05
    ln -s /cluster/data/encode/MSA/Gerp/2006-02-01/tbaGerpCons.wib $d
    hgLoadWiggle -pathPrefix=$d hg17 encodeTbaGerpCons tbaGerpCons.wig

    # MLAGAN 
    cat lab/chr*_GERP_MLAGAN_scores.wig | \
        wigEncode stdin mlaganGerpCons.wig mlaganGerpCons.wib
        #  upper limit 4.48, lower limit -25.74
    set d = /gbdb/hg17/encode/MLAGAN/SEP-05
    ln -s /cluster/data/encode/MSA/Gerp/2006-02-01/mlaganGerpCons.wib $d
    hgLoadWiggle -pathPrefix=$d hg17 encodeMlaganGerpCons mlaganGerpCons.wig

    # MAVID
    cat lab/chr*_GERP_MAVID_scores.wig | \
        wigEncode stdin mavidGerpCons.wig mavidGerpCons.wib
        # upper limit 4.48, lower limit -22.58
    set d = /gbdb/hg17/encode/MAVID/SEP-05
    ln -s /cluster/data/encode/MSA/Gerp/2006-02-01/mavidGerpCons.wib $d
    hgLoadWiggle -pathPrefix=$d hg17 encodeMavidGerpCons mavidGerpCons.wig

    # Elements.  Note: scores from 307-1000.  This data also
        # upper limit 4.48, lower limit -22.58
    # includes a 6th field with an unscaled float score, which
    # will be included in the table, but not used for display
    # with unscaled scores.

    # Adding item names (<region>.#) for consistency with other MSA elements
    # subtracks

    lab/GERP_TBA_Cons.bed


##########################################################################
# MSA SCONE Conservation (2005-12-12 kate)
# From Harvard Med School, Saurabh Asthana <faplap@gmail.com>
# Reusbmitted 12/21/05

    cd /cluster/data/encode/MSA
    mkdir -p SconeCons/2005-12-21/lab
    ln -s SconeCons/2005-12-21 latest
    cd latest/lab
    mkdir bed; cd bed
    wget http://genetics.bwh.harvard.edu/graft/bed/sconeRegions.NOV-2005.bed.tar.bz2
    bunzip2 sconeRegions.NOV-2005.bed.tar.bz2
    tar xvf sconeRegions.NOV-2005.bed.tar
    cd ..

    cd ..; mkdir wig; cd wig
    wget http://ika.bwh.harvard.edu/graft/wig/scone.NOV-2005.wig.tar.bz2
    bunzip2 scone.NOV-2005.wig.tar.bz2
    tar xvf scone.NOV-2005.wig.tar
    cd ../..

    # elements
cat > load.csh << 'EOF'
    set out = sconeRegions.bed
    rm -f $out
    foreach f (lab/bed/*.bed)
        set r = $f:t:r
        echo $r
        grep '^chr' $f | \
            awk '{printf("%s\t%d\t%d\t%s\t1000\n", \
                        $1,$2,$3,$4)}' >> $out
    end
    hgLoadBed -strict hg17 encodeTbaSconeEl $out
'EOF'
    csh load.csh >&! load.log &
        # Loaded 18817 elements 
    featureBits -enrichment hg17 encodeRegions encodeTbaSconeEl
        # encodeRegions 1.047%, encodeTbaSconeEl 0.083%, both 0.083%, cover 7.92%, enrich 95.55x
    featureBits -enrichment hg17 encodeRegions encodeTbaPhastConsEl
       # encodeRegions 1.047%, encodeTbaPhastConsEl 0.063%, both 0.063%, cover 6.04%, enrich 95.55x
    featureBits -enrichment hg17 encodeRegions encodeTbaGerpEl
       # encodeRegions 1.047%, encodeTbaGerpEl 0.057%, both 0.057%, cover 5.47%, enrich 95.55x
    featureBits -enrichment hg17 encodeRegions encodeTbaBinConsEl
        # encodeRegions 1.047%, encodeTbaBinConsEl 0.060%, both 0.060%, cover 5.71%, enrich 95.55x

    # conservation
    cat lab/wig/*.wig | \
        wigEncode stdin tbaScone.wig tbaScone.wib
    set d = /gbdb/hg17/encode/TBA/SEP-05
    ln -s `pwd`/tbaScone.wib $d
    hgLoadWiggle -pathPrefix=$d hg17 encodeTbaSconeCons tbaScone.wig 

##########################################################################
# MSA Conservation  (2005-12-07 kate)
# Just phastCons and GERP for this freeze  (x3 aligners)

    cd /cluster/data/encode/MSA/SEP-05
    mkdir -p conservation/lab
    cd conservation/lab
    wget ftp://kronos.nhgri.nih.gov/pub/outgoing/elliott/msa/SEP-2005/cons/phastCons.wig.tar.gz
    tar xvfz phastCons.wig.tar.gz
    cd ..

cat > load.csh << 'EOF'
    # TBA
    gunzip -c lab/tba/*/phast/human.ENm*.gz | \
        wigEncode stdin tbaPhastCons.wig tbaPhastCons.wib
    set d = /gbdb/hg17/encode/TBA/SEP-05
    ln -s `pwd`/tbaPhastCons.wib $d
    hgLoadWiggle -pathPrefix=$d hg17 encodeTbaPhastCons tbaPhastCons.wig 

    # MLAGAN
    gunzip -c lab/mlagan/*/phast/human.ENm*.gz | \
        wigEncode stdin mlaganPhastCons.wig mlaganPhastCons.wib
    set d = /gbdb/hg17/encode/MLAGAN/SEP-05
    ln -s `pwd`/mlaganPhastCons.wib $d
    hgLoadWiggle -pathPrefix=$d hg17 encodeMlaganPhastCons mlaganPhastCons.wig 

    # MAVID
    gunzip -c lab/mavid/*/phast/human.ENm*.gz | \
        wigEncode stdin mavidPhastCons.wig mavidPhastCons.wib
    set d = /gbdb/hg17/encode/MAVID/SEP-05
    ln -s `pwd`/mavidPhastCons.wib $d
    hgLoadWiggle -pathPrefix=$d hg17 encodeMavidPhastCons mavidPhastCons.wig 
'EOF'
    csh load.csh >&! load.log

          
##########################################################################
# MSA alignment agreement
#  From Ariel Schwartz, UC Berkeley

    cd /cluster/data/encode/MSA
    mkdir alignAgreement/2005-11-16/lab
    cd alignAgreement/2005-11-16/lab
    touch Mean.wig MavidMlagan.wig MavidTba.wig MlaganTba.wig 
    touch MavidUngapped.wig MlaganUngapped.wig TbaUngapped.wig
cat > split.csh << 'EOF'
    foreach f (lab/*.wig.gz)
        echo $f
        gunzip $f
        /cluster/data/encode/bin/scripts/splitTracks.pl $f:r
        cat t0 >> Mean.wig
        cat t1 >> MavidMlagan.wig
        cat t2 >> MavidTba.wig
        cat t3 >> MlaganTba.wig
        cat t4 >> MavidUngapped.wig
        cat t5 >> MlaganUngapped.wig
        cat t6 >> TbaUngapped.wig
        rm t?
        gzip $f:r
    end
'EOF'
    csh split.csh >&! split.log &
    mkdir wig wib
cat > load.csh << 'EOF'
    set dir = /gbdb/hg17/encode/MSA/alignAgree/2005-11-16
    mkdir -p $dir
    foreach f (*.wig)
        set table = encodeMsaAlign$f:r
        echo $table
        egrep -v "browser|track" $f | \
            wigEncode stdin wig/$table.wig wib/$table.wib
        hgLoadWiggle -pathPrefix=$dir hg17 $table wig/$table.wig
        ln -s `pwd`/wib/$table.wib $dir
    end
'EOF'
    csh load.csh >&! load.log &

##########################################################################
# Harvard TBA Conservation (2005-12-12 kate)
#  From <faplap@gmail.com> Saurabh Asthana
# Dept. of Medicine, Brigham & Women's Hospital, Harvard Medical School

    cd /cluster/data/encode/MSA/SconeCons
    mkdir -p 2005-12-01/lab
    cd 2005-12-01/lab
    wget http://ika.bwh.harvard.edu/graft/wig/scone.NOV-2005.wig.tar.bz2
    wget http://genetics.bwh.harvard.edu/graft/bed/sconeRegions.NOV-2005.bed.tar.bz2
    mkdir -p bed wig
    # NOTE: files are actually gzipped
    mv scone.NOV-2005.wig.tar.bz2 wig/scone.wig.tar.gz
    mv sconeRegions.NOV-2005.bed.tar.bz2 bed/sconeRegions.bed.tar.gz
    cd ..

    # Conservation scores
    cat lab/wig/*.wig | grep -v track | \
        wigEncode 
    # Conserved Elements
    # Add these to the TBA Elements track as a subtrack
    # For table consistency, assign item names of the form <region>.#,
    # and a score=1000
    set bed = sconeRegions.bed
    rm $out
    foreach f (lab/bed/*.bed)
        set r = $f:t:r
        echo $r
        grep '^chr' $f | \
            awk -v REGION=$r '{printf("%s\t%d\t%d\t%s.%d\t%d\n", \
                $1,$2,$3,REGION, NR,1000)}' >> $bed
    end
    hgLoadBed -strict hg17 encodeTbaSconeEl $bed
        # Loaded 18784 elements of size 5

    
##########################################################################
# UW/Regulome Chromatin Accessibility Profiling (CAP)
#  Submitted 2006-1-17 by Scott Kuehn

    cd /cluster/data/encode/Regulome
    mkdir -p 2006-01-17/lab
    cd 2006-01-17/lab
    awk '{printf("%s\t%s\t%s\t%.3f\n", $1, $2, $3, $5)}' \
                lab/Encode.hs-baseline.hg17.bed | \
        sort -k1,1 -k2,2n  | \
        /cluster/data/encode/bin/scripts/trimOverlap.pl > sens.bed
    hgLoadBed -strict -bedGraph=4 hg17 encodeRegulomeCapSensGM06990 sens.bed

    sort -k1,1 -k2,2n lab/Encode.dhs.hg17.bed | \
        hgLoadBed -strict hg17 encodeRegulomeCapSitesGM06990 stdin
    
    
##########################################################################
# SANGER CHIP/CHIP  (2006-03-16 kate)
#  5 histone mods in HFL cells, to be added to existing track
#  Submitted by Rob Andrews

    ssh hgwdev
    cd /cluster/data/encode/sanger/chipchip
    mkdir -p 2006-03-16/lab
    cd 2006-03-16
    cp /var/ftp/encode/*.wig.txt lab

    grep "^chr" lab/H3K4me1_HFL-1_1.wig.txt | sort -k1,1 -k2,2n > \
	H3K4me1HFL1.bed
    grep "^chr" lab/H3K4me2_HFL-1_1.wig.txt | sort -k1,1 -k2,2n > \
	H3K4me2HFL1.bed
    grep "^chr" lab/H3K4me3_HFL-1_1.wig.txt | sort -k1,1 -k2,2n > \
	H3K4me3HFL1.bed
    grep "^chr" lab/H3ac_HFL-1_1.wig.txt | sort -k1,1 -k2,2n > \
	H3acHFL1.bed
    grep "^chr" lab/H4ac_HFL-1_1.wig.txt | sort -k1,1 -k2,2n > \
	H4acHFL1.bed
cat > load.csh << 'EOF'
    foreach f (*.bed)
        set t = $f:r
        echo $t
	hgLoadBed -bedGraph=4 hg17 encodeSangerChip$t $t.bed
    end
'EOF'
    csh load.csh >&! load.log &
    # loaded 23996 elements for 5 tables

# ENCODE PSEUDOGENE TRACK (in progress, hartera)
    # Yontao reloaded the encodePseudogeneUcsc2 table with shorter 
    # names for the pseudogenes as they were cut off in the browser so now
    # NM_001017421|chr2|+|1 would be NM_001017421|1
    # The class table needs to be reloaded. Yontao provided a file:
    # encodePseudogeneUcsc2-forload.class
    # get a dump of the current table without the ucsc2 entries.
    ssh hgwdev
    cd /cluster/data/encode/pseudogene/class
    hgsql -N -e 'select * from encodePseudogeneClass where owner != "ucsc2";' \
          hg17 > encodePseudogeneClassNoUcsc2.txt
    cat encodePseudogeneClassNoUcsc2.txt encodePseudogeneUcsc2-forload.class \
        > allPseudogenesClass.txt
    sort -k3,3 allPseudogenesClass.txt > encodePseudogeneClass2.txt 
    # the consensus sequences have different names in the Class table, the
    # names had been changed to Vega gene names. Get the Class from the gtf in
    # /cluster/data/encode/pseudogene/consensus
    awk 'BEGIN {OFS="\t"} {print $10, $2}' \
         ../consensus/consensus.jan6.hg17.gtf | sort | uniq \
         > pgConsensus.class
    sed -e 's/VEGA_//' pgConsensus.class | sed -e 's/"//g' \
           | sed -e 's/;//' > pgConsensusClass.txt
    wc -l pgConsensusClass.txt
    # 201 pgConsensusClass.txt
    awk 'BEGIN {OFS="\t"}{print $0,"consensus"}' pgConsensusClass.txt | sort \
        > pgConsensusClassSorted.txt
    # reload the encodePseudogeneClass table
    hgsql -N -e 'select * from encodePseudogeneClass where owner != "ucsc2" and owner != "consensus";' \
          hg17 > pseudoClassNoUcsc2OrConsensus.txt
    cat pseudoClassNoUcsc2OrConsensus.txt encodePseudogeneUcsc2-forload.class \
        pgConsensusClassSorted.txt > allPseudogenesClass.txt
    sort -k3,3 allPseudogenesClass.txt > encodePseudogeneClass2.txt 
    wc -l encodePseudogeneClass2.txt
    # 995 encodePseudogeneClass2.txt
    # only 830 load as there are dupicate names - 165 names are shared
    # between the consensus and havana subtracks. These names
    # need to be unique as they are the primary key. Checked that the 
    # class is the same for havana and consensus subtracks where the 
    # name is the same so reload table with one entry for these genes.
    # remove havana and consensus pseudogenes
    grep -v havana allPseudogenesClass.txt | grep -v consensus \
         > pseudoNoHavananNoCons.txt
    wc -l pseudoNoHavananNoCons.txt
    # 616 pseudoNoHavananNoCons.txt
    # prepare consensus set not in havana
    awk 'BEGIN {OFS="\t"}{print $0,"consensus"}' consOnly > consOnlyWithOwner
    # prepare havana set not in consensus
    awk 'BEGIN {OFS="\t"}{print $0,"havana"}' havanaOnly2 > havanaOnlyWithOwner
    # prepare set common to consensus and havana
    awk 'BEGIN {OFS="\t"}{print $0,"havana or consensus"}' \
        nameAndClass.ConsAndHavana > havanaAndConsWithOwner
    wc -l *Owner
    # 36 consOnlyWithOwner
    # 165 havanaAndConsWithOwner
    # 2 havanaOnlyWithOwner
    cat pseudoNoHavananNoCons.txt consOnlyWithOwner havanaAndConsWithOwner \
        havanaOnlyWithOwner > allPseudogenesClass2.txt
    sort -k3,3 allPseudogenesClass2.txt > encodePseudogeneClass2.txt 
    wc -l encodePseudogeneClass2.txt
    # 819 encodePseudogeneClass2.txt
    # reload table
    hgsql -e 'drop table encodePseudogeneClass;' hg17
    hgsql hg17 < encodePseudogeneClass.sql
    echo "load data local infile 'encodePseudogeneClass2.txt' into \
         table encodePseudogeneClass" | hgsql hg17

