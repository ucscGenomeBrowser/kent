# These are instructions for building the
# neighborhood browser.  Don't start these until
# there is a knownGene track, or a track with the 
# usual genePred fields followed by a proteinID field 
# with SwissProt IDs.

# Set up db variable (you'll actually need to redo this
# after each ssh until we work out a better system.)
ssh hgwdev
set db = hg16

# Cluster together various alt-splicing isoforms.
hgClusterGenes $db knownGene knownIsoforms knownCanonical

# Extract peptides from knownGenes into fasta file
# and create a blast database out of them.
mkdir -p /cluster/data/$db/bed/blastp
cd /cluster/data/$db/bed/blastp
pepPredToFa $db knownGenePep known.faa
formatdb -i known.faa -t known -n known
cd ..

# Copy over database to iscratch/i
ssh kkr1u00
if (-e /iscratch/i/$db/blastp) then
   rm -r /iscratch/i/$db/blastp
endif
mkdir -p /iscratch/i/$db/blastp
if (-e /iscratch/i/$db/blastp) then
   rm -r /iscratch/i/$db/blastp
endif
mkdir -p /iscratch/i/$db/blastp
cp /cluster/data/$db/bed/blastp/known.* /iscratch/i/$db/blastp

# Load up iscratch/i with blastp and related files
# if necessary
if (! -e /iscratch/i/blast/blastall) then
    mkdir -p /iscratch/i/blast
    cp /projects/compbio/bin/i686/blastall /iscratch/i/blast
    mkdir -p /iscratch/i/blast/data
    cp /projects/compbio/bin/i686/data/* /iscratch/i/blast/data
endif
iSync

# Split up fasta file into bite sized chunks for cluster
cd /cluster/data/$db/bed/blastp
mkdir split
faSplit sequence known.faa 6000 split/kg

# Make parasol run directory 
ssh kk
mkdir -p /cluster/data/$db/bed/blastp/self
cd /cluster/data/$db/bed/blastp/self
mkdir run
cd run
mkdir out

# Make blast script
cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/$db/blastp/known -i \$1 -o \$2 -e 0.01 -m 8 -b 1000
end
chmod a+x blastSome

# Make gensub2 file
cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub spec
para create spec
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push
# This should finish in 5-10 minutes if the cluster is free.

#Completed: 5815 of 5815 jobs
#CPU time in finished jobs:     125571s    2092.84m    34.88h    1.45d  0.004 y
#IO & Wait Time:                 24734s     412.24m     6.87h    0.29d  0.001 y
#Average job time:                  26s       0.43m     0.01h    0.00d
#Longest job:                      259s       4.32m     0.07h    0.00d
#Submission to last job:           438s       7.30m     0.12h    0.01d

# Load into database.  This takes about an hour.
ssh hgwdev
cd /cluster/data/$db/bed/blastp/self/run/out
hgLoadBlastTab $db knownBlastTab *.tab

# Create table that maps between known genes and RefSeq
hgMapToGene $db refGene knownGene knownToRefSeq

# Create table that maps between known genes and LocusLink
echo "select mrnaAcc,locusLinkId from refLink" | hgsql -N $db > refToLl.txt
hgMapToGene $db refGene knownGene knownToLocusLink -lookup=refToLl.txt

# Create table that maps between known genes and Pfam domains
hgMapViaSwissProt $db knownGene name proteinID Pfam knownToPfam

# Create a table that maps between known genes and 
# the nice affyUcla expression data.
hgMapToGene "-type=bed 12" $db affyUcla knownGene knownToU133

# Create expression distance table.  This will take about an hour.
cd ~/src/hg/near/hgExpDistance
hgExpDistance $db affyUcla affyUclaExp knownExpDistance -weights=affyUcla.weight -lookup=knownToU133

# Format and load the GNF data
cd /cluster/data/$db/bed
mkdir affyGnf95
cd affyGnf95
affyPslAndAtlasToBed -newType ../affyU95.psl /projects/compbio/data/microarray/affyGnfHuman/data_public_U95 affyGnfU95.tab affyGnfU95Exps.tab -shortOut
hgsql $db < ~/src/hg/affyGnf/affyGnfU95.sql

# Create table that maps between known genes and 
# the GNF data.
hgMapToGene $db affyU95 knownGene knownToU95
cd ~/src/hg/near/hgExpDistance
#hgExpDistance $db affyGnfU95 affyGnfU95Exps knownGnfDistance -lookup=knownToU95
hgExpDistance $db hgFixed.gnfHumanU95MedianRatio hgFixed.gnfHumanU95MedianExps gnfU95Distance -lookup=knownToU95

#For worm did instead
#hgExpDistance ce1 kimLifeCycleMedian kimWormLifeCycleMedian kimExpDistance
hgExpDistance ce1 hgFixed.kimWormLifeMedianRatio hgFixed.kimWormLifeMedianExps kimExpDistance

#For mouse did instead
hgExpDistance mm3 affyGnfU74A affyGnfU74AExps affyGnfU74ADistance -lookup=knownToU74
hgExpDistance mm3 affyGnfU74B affyGnfU74BExps affyGnfU74BDistance -lookup=knownToU74
hgExpDistance mm3 affyGnfU74C affyGnfU74CExps affyGnfU74CDistance -lookup=knownToU74

# Make sure that GO database is up to date.
See README in /cluster/store1/geneOntology.

# Create knownToEnsembl column
hgMapToGene $db ensGene knownGene knownToEnsembl

# Make knownToCdsSnp column.  This is a little complicated by
# having to merge data form the snpTsc and the snpNih tracks.
hgMapToGene $db snpTsc knownGene knownToCdsSnp -createOnly -all -cds
hgMapToGene $db snpTsc knownGene snp1 -noLoad -all -cds
hgMapToGene $db snpNih knownGene snp2 -noLoad -all -cds
sort snp1.tab snp2.tab > knownToCdsSnp.tab
rm snp1.tab snp2.tab
hgsql $db <<end
load data local infile 'knownToCdsSnp.tab' into table knownToCdsSnp;
end


# Make C. elegans ortholog column using blastp on wormpep.
# First make C. elegans protein database and copy it to iscratch/i
# if it doesn't exist already
cd /cluster/data/ce1/bed
mkdir blastp
cd blastp
wget ftp://ftp.sanger.ac.uk/pub/databases/wormpep/wormpep
mv wormpep wormPep.faa
formatdb -i wormPep.faa -t wormPep -n wormPep
ssh kkr1u00
if (-e /iscratch/i/ce1/blastp) then
   rm -r /iscratch/i/ce1/blastp
endif
mkdir -p /iscratch/i/ce1/blastp
cp /cluster/data/ce1/bed/blastp/wormPep.p?? /iscratch/i/ce1/blastp
iSync

# Make parasol run directory 
ssh kk
mkdir -p /cluster/data/$db/bed/blastp/ce1
cd /cluster/data/$db/bed/blastp/ce1
mkdir run
cd run
mkdir out

# Make blast script
cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/ce1/blastp/wormPep -i \$1 -o \$2 -e 0.01 -m 8 -b 1
end
chmod a+x blastSome

# Make gensub2 file
cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub spec
para create spec
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push

# This should finish in 5-10 minutes if the cluster is free.
# Here's the para time results
Completed: 4851 of 4851 jobs
CPU time in finished jobs:      94530s    1575.50m    26.26h    1.09d  0.003 y
IO & Wait Time:                 22449s     374.15m     6.24h    0.26d  0.001 y
Average job time:                  24s       0.40m     0.01h    0.00d
Longest job:                      148s       2.47m     0.04h    0.00d
Submission to last job:           561s       9.35m     0.16h    0.01d

# Load into database.  
ssh hgwdev
cd /cluster/data/$db/bed/blastp/ce1/run/out
hgLoadBlastTab $db ceBlastTab -maxPer=1 *.tab

# Make mouse ortholog column using blastp on mouse known genes.
# First make mouse protein database and copy it to iscratch/i
# if it doesn't exist already
cd /cluster/data/mm3/bed
mkdir blastp
cd blastp
pepPredToFa mm3 knownGenePep known.faa
formatdb -i known.faa -t known -n known
ssh kkr1u00
if (-e /iscratch/i/mm3/blastp) then
   rm -r /iscratch/i/mm3/blastp
endif
mkdir -p /iscratch/i/mm3/blastp
cp /cluster/data/mm3/bed/blastp/known.p?? /iscratch/i/mm3/blastp
iSync

# Make parasol run directory 
ssh kk
mkdir -p /cluster/data/$db/bed/blastp/mm3
cd /cluster/data/$db/bed/blastp/mm3
mkdir run
cd run
mkdir out

# Make blast script
cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/mm3/blastp/known -i \$1 -o \$2 -e 0.001 -m 8 -b 1
end
chmod a+x blastSome

# Make gensub2 file
cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub spec
para create spec
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push

# Load into database.  
ssh hgwdev
cd /cluster/data/$db/bed/blastp/mm3/run/out
hgLoadBlastTab $db mmBlastTab -maxPer=1 *.tab

# Make Danio rerio (zebrafish) ortholog column using blastp on Ensembl.
# First make protein database and copy it to iscratch/i
# if it doesn't exist already
cd /cluster/data/dm1/bed
mkdir blastp
cd blastp
wget ftp://ftp.ensembl.org/pub/current_zebrafish/data/fasta/pep/Danio_rerio.ZFISH2.pep.fa.gz 
zcat Dan*.pep.fa.gz > ensembl.faa
echo "Translation:" > subs.in
subs -e ensembl.faa > /dev/null
formatdb -i ensembl.faa -t ensembl -n ensembl
ssh kkr1u00
if (-e /iscratch/i/dr1/blastp) then
   rm -r /iscratch/i/dr1/blastp
endif
mkdir -p /iscratch/i/dr1/blastp
cp /cluster/data/dr1/bed/blastp/ensembl.p?? /iscratch/i/dr1/blastp
iSync

# Make parasol run directory 
ssh kk
mkdir -p /cluster/data/$db/bed/blastp/dr1
cd /cluster/data/$db/bed/blastp/dr1
mkdir run
cd run
mkdir out

# Make blast script
cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/dr1/blastp/ensembl -i \$1 -o \$2 -e 0.005 -m 8 -b 1
end
chmod a+x blastSome

# Make gensub2 file
cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub spec
para create spec
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push

# Load into database.  
ssh hgwdev
cd /cluster/data/$db/bed/blastp/dr1/run/out
hgLoadBlastTab $db drBlastTab -maxPer=1 *.tab

# Make Saccharomyces cerevisiae (yeast) ortholog column using blastp on RefSeq.
# First make protein database and copy it to iscratch/i
# if it doesn't exist already
cd /cluster/data/sc1/bed
mkdir blastp
cd blastp
wget ftp://genome-ftp.stanford.edu/pub/yeast/data_download/sequence/genomic_sequence/orf_protein/orf_trans.fasta.gz
zcat orf_trans.fasta.gz > sgd.faa
echo "ORFP:|" > subs.in
subs -e sgd.faa > /dev/null
formatdb -i sgd.faa -t sgd -n sgd
ssh kkr1u00
if (-e /iscratch/i/sc1/blastp) then
   rm -r /iscratch/i/sc1/blastp
endif
mkdir -p /iscratch/i/sc1/blastp
cp /cluster/data/sc1/bed/blastp/sgd.p?? /iscratch/i/sc1/blastp
iSync

# Make parasol run directory 
ssh kk
mkdir -p /cluster/data/$db/bed/blastp/sc1
cd /cluster/data/$db/bed/blastp/sc1
mkdir run
cd run
mkdir out

# Make blast script
cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/sc1/blastp/sgd -i \$1 -o \$2 -e 0.01 -m 8 -b 1
end
chmod a+x blastSome

# Make gensub2 file
cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub spec
para create spec
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push

# Load into database.  
ssh hgwdev
cd /cluster/data/$db/bed/blastp/sc1/run/out
hgLoadBlastTab $db scBlastTab -maxPer=1 *.tab

# Make Drosophila melanagaster ortholog column using blastp on FlyBase.
# First make SwissProt protein database and copy it to iscratch/i
# if it doesn't exist already
cd /cluster/data/dm1/bed
mkdir blastp
cd blastp
wget ftp://ftp.fruitfly.org/pub/download/dmel_RELEASE3-1/FASTA/whole_genome_translation_dmel_RELEASE3-1.FASTA.gz
zcat whole_ge*.gz | faFlyBaseToUcsc stdin flyBase.faa
formatdb -i flyBase.faa -t flyBase -n flyBase
ssh kkr1u00
if (-e /iscratch/i/dm1/blastp) then
   rm -r /iscratch/i/dm1/blastp
endif
mkdir -p /iscratch/i/dm1/blastp
cp /cluster/data/dm1/bed/blastp/flyBase.p?? /iscratch/i/dm1/blastp
iSync

# Make parasol run directory 
ssh kk
mkdir -p /cluster/data/$db/bed/blastp/dm1
cd /cluster/data/$db/bed/blastp/dm1
mkdir run
cd run
mkdir out

# Make blast script
cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/dm1/blastp/flyBase -i \$1 -o \$2 -e 0.01 -m 8 -b 1
end
chmod a+x blastSome

# Make gensub2 file
cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end

# Create parasol batch
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub spec
para create spec
para try

# Wait a couple of minutes, and do a para check,  if all is good
# then do a
para push

#Results of this:
#Completed: 5814 of 5814 jobs
#CPU time in finished jobs:      62285s    1038.09m    17.30h    0.72d  0.002 y
#IO & Wait Time:                 23056s     384.26m     6.40h    0.27d  0.001 y
#Average job time:                  15s       0.24m     0.00h    0.00d
#Longest job:                      152s       2.53m     0.04h    0.00d
#Submission to last job:           290s       4.83m     0.08h    0.00d


# Load into database.  
ssh hgwdev
cd /cluster/data/$db/bed/blastp/dm1/run/out
hgLoadBlastTab $db dmBlastTab -maxPer=1 *.tab

#---------

## (markd did this when??)
# create Rankprop homology score and PSI-BLAST tables.
# requires rankprop code from Bill Noble <noble@gs.washington.edu>
# which includes scripts to build these tables on the cluster.

    # run psiblast

      ssh hgwdev
      mkdir /cluster/bluearc/markd/rankprop
      cd  /cluster/bluearc/markd/rankprop
     
      # link rankprop to work directory:
      ln -s /cluster/store7/markd/rankprop/rankprop/bin .

      mkdir -p blastRun
      cd blastRun

      # hs.sw+tr is human swissprot+trembl (on hgwdev)
      ../bin/cluster-blast-setup hs.sw+tr

      ssh kk
      cd /cluster/bluearc/markd/rankprop/blastRun/hs.sw+tr
      para create jobs.para
      para try ,...
      # one job crashed on Query=P01722, no idea why; remove it from database
      # and rerun

      # finish up run
      cd ..
      ../bin/cluster-blast-finishup hs.sw+tr

  # run rankprop

      # rankprop run, on rack9 due to memory sies of kk9
      ssh kk9  
      cd /cluster/bluearc/markd/rankprop/rankpRun/
      ../bin/cluster-rankprop-setup -maxHits 1000 hs.sw+tr/max1k 10
      cd hs.sw+tr
      para create jobs.para
      para try, push, blah
      cd ..
      ../bin/cluster-rankprop-finishup  hs.sw+tr/max1k


      # load database
      cd /cluster/bluearc/markd/rankprop/results
      spLoadRankProp -noKgIdFile=hs.sw+tr/max1k.hg17.nokg.spids hg17 rankProp hs.sw+tr/max1k.rankp.gz >&hs.sw+tr/max1k.hg17.log
      spLoadPsiBlast hg17 spPsiBlast hs.sw+tr.eval.gz

#---------

## (aamp andy pohl did this when??)
# Human data from Shyamsundar R, et al. (2005) Genome Biol 6(3):R22
hgExpDistance hg17 hgFixed.humanNormalRatio hgFixed.humanNormalExps humanNormalDistance -lookup=knownToLocusLink

# Mouse landscape data.
hgExpDistance mm6 hgFixed.mouseLandscape hgFixed.mouseLandscapeExps mouseLandscapeDistance -lookup=knownToXM

# Remaking some distance tables after the knownGene updates (DONE 01/24/2006 Andy)
# (current working directory irrelevant... it's all database)
hgExpDistance mm6 hgFixed.mouseLandscape hgFixed.mouseLandscapeExps mouseLandscapeDistance -lookup=knownToXM
hgExpDistance hg17 hgFixed.gladHumES hgFixed.gladHumESExps gladHumESDistance -lookup=knownToGnfAtlas2

#----------------------------------------------------------

## (galt 2005-06-03)
# p2p Protein-to-protein network - P2P column and sort order
# I wrote the hgNetDist program to calculate network-distances for all gene pairs from gene-to-gene edges in input data .tab,
# using the Floyd-Warshall dynamic programming algorithm.
# These .tab files are from Josh Stuart /cluster/home/jstuart/Data/Interaction/P2P/{Worm,Fly,Yeast}/Compendium/data.tab
# I have also deposited copies of the .tab files used in /cluster/data/$db/p2p/
# added entries to hgNearData/$species/{orderDb,columbDb}.ra
# added hgNearData/$species/p2p.html
# added hgNearData/p2p.html
#  
#yeast: (1.5 hours for about 5000 genes, 24452 edges)
hgNetDist yeastP2P.tab sacCer1 yeastP2P -threshold=3
 
#fly: (3 hours for about 6500 genes, 19993 edges)
# The temporary table bdgpGeneFb2Bdgp was constructed just for fly from this sql command:
# create table bdgpGeneFb2Bdgp as
# select flyBaseId, name bdgpName from bdgpGene a, bdgpGeneInfo b
# where SUBSTRING_INDEX(name, "-R", 1) = bdgpName order by flyBaseId, bdgpName;
#
hgNetDist flytest.tab dm1 flyP2P -threshold=2 -sqlRemap="select flyBaseId, bdgpName from bdgpGeneFb2Bdgp"
 
#worm: (15 minutes for about 2514 genes, 3871 edges - interaction data available is small)
hgNetDist wormP2P.tab ce2 wormP2P -threshold=2
 

#----------------------------------------------------------

## (galt 2006-07-31)
# Human p2p Protein-to-protein network - P2P column and sort order
# I used the hgNetDist program to calculate network-distances for all gene pairs from gene-to-gene edges in input data,
# I have also deposited copies of the .tab files used in /cluster/data/$db/p2p/{vidal,wanker}
# added entries to hgNearData/Human/{orderDb,columbDb}.ra
# added hgNearData/Human/{vidal,wanker}P2p.html
#  
#vidal 
 
cat nature04209-s17.xls | gawk '{print $1 "\t" $3 "\t" "1.0"}' > humanVidal.p2p

hgNetDist humanVidal.p2p hg18 humanVidalP2P -threshold=2 -sqlRemap="select distinct locusLinkID, kgID from refLink, kgXref where refLink.mrnaAcc = kgXref.mRNA"

#Added to hgNearData/Human/hg18/columbDb.ra
#-------------
name vidalP2p
type distance humanVidalP2P query target distance
visibility off
shortLabel Vidal P2P
longLabel Human Protein-Protein Interaction Network from Marc Vidal
priority 12


#Added to hgNearData/Human/hg18/orderDb.ra
#-----------
name vidalP2p
shortLabel Vidal Protein-to-Protein
longLabel P2P Network Distance to Selected Gene from Marc Vidal data
type pair humanVidalP2P query target distance 1
priority 9


#wanker
cat table_S3.txt | gawk '{print $4 "\t" $7 "\t" "1.0"}' > humanWanker.p2p

hgNetDist wanker/humanWanker.p2p hg18 humanWankerP2P -threshold=2 -sqlRemap="select distinct locusLinkID, kgID from refLink, kgXref where refLink.mrnaAcc = kgXref.mRNA"

#Did exactly the same for hg17 also.

#Did the same thing to the .ra files all over again for name wankerP2p.

---

# show amount of overlap between Vidal and Wanker data sets
#These following queries joining both P2P data were 
#glacial until I added these better indexes:

create index ninny on humanVidalP2P(query(9),target(9));
create index ninny on humanWankerP2P(query(9),target(9));

select count(*) from humanVidalP2P v, humanWankerP2P w where v.query=w.query and v.target=w.target; 
#+----------+
#| count(*) |
#+----------+
#|     1661 |
#+----------+


