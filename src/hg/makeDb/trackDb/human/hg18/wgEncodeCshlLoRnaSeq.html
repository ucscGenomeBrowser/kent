<H2>Description</H2>

<P> This track depicts high throughput sequencing of long RNAs (&gt;200 nt) 
from 
<A TARGET=_BLANK HREF="/cgi-bin/hgEncodeVocab?type=rnaExtract">
RNA samples</A> from 
<A TARGET=_BLANK HREF="/cgi-bin/hgEncodeVocab?type=localization">
tissues or subcellular compartments</A> from 
<A TARGET=_BLANK HREF="/cgi-bin/hgEncodeVocab?type=cellType">ENCODE cell
lines</A>. 
The overall goal of the ENCODE project is to identify and characterize all
functional elements in the sequence of the human genome.
</P>

<H2>Display Conventions and Configuration</H2>
This track is a multi-view composite track that contains the following
<EM>views</EM>:
<DL>
<DT><i>Alignments</i>
<DD>The Alignments view shows reads mapped to the genome.
<DT><i>Raw Signal</i>
<DD>The Raw Signal views show the density of aligned tags on the plus and minus strand.
</DL>

<H2>Methods</H2>

Cells were grown according to the approved 
<A HREF="../../ENCODE/protocols/cell" TARGET=_BLANK>ENCODE cell culture protocols</A>.
<P>
Oligo-dT selected poly-A+ RNA was RiboMinus-treated according to the
manufacturer's protocol (Invitrogen). The RNA was treated with tobacco alkaline
pyrophosphatase to eliminate any 5&prime; cap structures and hydrolyzed to ~200
bases via alkaline hydrolysis.  The 3&prime; end was repaired using calf
intestinal alkaline phosphatase, and poly-A polymerase was used to catalyze the
addition of Cs to the 3&prime; end.   The 5&prime; end was phosphorylated using T4
PNK, and an RNA linker was ligated onto the 5&prime; end.  Reverse transcription
was carried out using a poly-G oligo with a defined 5&prime; extension.  The
inserts were then amplified using oligos targeting the 5&prime; linker and
poly-G extension.  This cloning protocol generated stranded reads that were read
from the 5&prime; ends of the inserts.  The library was sequenced on a Solexa
platform for a total of 36 cycles; however, the reads underwent post-processing,
resulting in trimming of their 3&prime; ends. Consequently, the mapped read
lengths are variable. 
</P>

<H2>Analysis</H2>
<P>
The reads were mapped to the human (hg18, March 2006) assembly using Timo
Lassmann's Nexalign program as follows:
<P>
Only uniquely (one loci), exactly (no mis-matches) aligned reads are reported in
the processed files.

<OL>
<LI>Collect the read sequences from Illumina non-filtered output files.
</LI>
<LI>Filter out all reads that contain undefined nucleotides ('N')
</LI>
<LI>Perform iterative alignment/C-tail chopping algorithm (below). On each
alignment step, the reads are aligned to the genome with 100% identity. 
All reads that align to a single locus are withdrawn from the alignment pool and
only the reads that could not be aligned continue to the next step.
  <OL type="a">
  <LI>Align to the hg18 genome using Nexalign 1.3.3 (&copy; Timo Lassmann) without
  chopping off any nucleotides
  </LI>
  <LI>Chop off any C-blocks (until the first non-C) at the ends of the reads
  </LI>
  <LI>Align to the genome -&gt; remove and save those that align
  </LI>
  <LI>Chop off any non-Cs until the next C
  </LI>
  <LI>Chop off C-block until the next non-C
  </LI>
  <LI>Align to the genome -&gt; remove and save those that align
  </LI>
  <LI>Repeat steps d, e, and f until the reads align to the genome, or chopping 
  results in the reduction of the reads' lengths to below 16 (default), or
  there are no non-Cs left.
  </LI>
  </OL>
</LI>
</OL>
</P>

<H2>Verification</H2>

<P>Verification was done by comparison of referential data generated from 8
individual sequencing lanes (Illumina technology). 
</P>

<H2>Credits</H2>

<P>These data were generated and analyzed by the transcriptome group at
Cold Spring Harbor Laboratories, and the Center for Genomic
Regulation (Barcelona), who are participants in the ENCODE Transcriptome Group.
</P>

<P>
Contacts: 
<A HREF="mailto:&#100;a&#118;&#105;s&#99;&#64;&#99;sh&#108;.&#101;&#100;&#117;">Carrie Davis</A>
<!-- above address is davisc at cshl.edu -->
 and Tom Gingeras (CSHL).
</P>

<H2> Data Release Policy </H2>

<P>Data users may freely use ENCODE data, but may not, without prior 
consent, submit publications that use an unpublished ENCODE dataset until 
nine months following the release of the dataset.  This date is listed in 
the <EM>Restricted Until</EM> column, above.  The full data release policy 
for ENCODE is available 
<A HREF="../ENCODE/terms.html" TARGET=_BLANK>here</A>.</P> 
