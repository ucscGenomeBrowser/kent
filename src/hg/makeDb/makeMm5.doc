# This file describes how we made the browser database on the mouse
# genome, June 2004 build. - Mm5
#
#
#	NOTE:  There is a new chrMT sequence in the build 32
#	>gi|34538597|ref|NC_005089.1| Mus musculus mitochondrion
#
#   Will have to beware of this NC_ contig in the processing since
#	all previous builds had only NT_ contigs
#
# NOTE: The README_PREBUILD file for this assembly mentions several
# differences from the previous release (build 30):
# 1. seq_contig.md - new first line is a comment containing column name
#       Also, last two columns (group label and weight, have been swapped)
#       Also, some lines have id with CONTIG: prepended, and upper-case
#               feature type (CONTIG)
# 2. contig.idmap - has an additional column "contig label"
# This required changing the jkStuff ncbi* utilities (7/1/03 KRR)
#
# DOWNLOAD THE MOUSE SEQUENCE FROM NCBI (DONE - 2004-06-27 - Fan)
    ssh kksilo
    mkdir -p /cluster/store6/mm5/ncbi
    ln -s /cluster/store6/mm5 /cluster/data
    cd /cluster/data/mm5/ncbi
    mkdir chrfasta contigfasta
    ftp ftp.ncbi.nih.gov
      # user hgpguest, password from /cse/faculty/kent/buildHg6.doc
      cd mouse_33
      prompt
      bin
      mget *
      quit
    gunzip *.agp.gz

# compress chrY.fa (at NCBI site, this one file some how was not compressed)
	cd chrfasta
gzip chrY.fa
cd ..

#use chrMT.fa.gz from mm4 instead because its first line format is correct
 
	cp -p /cluster/store6/mm4/ncbi/chrfasta/chrMT.fa.gz chrfasta
cp -p /cluster/store6/mm4/ncbi/contigfasta/chrMT.fa.gz contigfasta

# Fix the troubles caused by chrMT released later separately

# Fixed allcontig.agp
# add the last line of .../mm4/ncbi/allcontig.agp to allcontig.agp

# Fixed allrefcontig.chr.agp
# add the last line of .../mm4/ncbi/allrefcontig.chr.agp to allrefcontig.chr.agp

# Fix contig.idmap
    cat contig.idmap chrMT/contig.idmap >new.idmap
    mv new.idmap contig.idmap

# Fix seq_contig.md
# Edit seq_contig.md to add 3 lines (from mm4) in its middle before  Un|...
10090   MT      0       0       +       start   -1      CONTIG  C57BL/6J        
1010090   MT      1       16299   +       NC_005089       GI:34538597     CONTIG  
C57BL/6J        na10090   MT      16299   16299   +       end     -2      CONTIG  C57BL/6J        
10

# ctg_coords, contig_overlaps.agp and sequence.inf not fixed.

# Check chromosome files  (DONE - 2004-06-27 - Fan)
cd chrfasta

foreach f (*.fa.gz)
echo $f:r >> faSize.out
gunzip $f
/cluster/bin/i386/faSize $f:r >> faSize.out
echo $f:r done
end

/cluster/bin/i386/faSize *.fa >> faSize.out
grep "^>" *.fa > ../chrfasta.all.fa.headers

gzip *.fa

cd ../contigfasta
gunzip *.fa.gz
grep "^>" *.fa > ../contigfasta.all.fa.headers
gzip *.fa

# BREAK UP SEQUENCE INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS
#					(DONE - 2004-06-27 - Fan)

    ssh kksilo
    cd /cluster/data/mm5
    gunzip ncbi/allrefcontig.chr.agp.gz
    # splitFaIntoContigs doesn't do right with agp lines arriving in a
    # different order than fasta chrom sequences.  so split up the agp
    # into one per chrom.
    foreach c ( 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 X Y MT Un)
      mkdir $c
      perl -we "while(<>){if (/^chr$c\t/) {print;}}" \
        ./ncbi/allrefcontig.chr.agp \
        > $c/chr$c.agp
      gunzip -c ./ncbi/chrfasta/chr$c.fa.gz \
        | perl -wpe 's/^>lcl\|(chr\w+)\.fa.*/>$1/' \
        | splitFaIntoContigs $c/chr$c.agp \
          stdin /cluster/data/mm5 -nSize=5000000
    end

#    gzip ncbi/chrfasta/chr*.fa

# CREATE CHROM-LEVEL AGP AND FASTA FOR _RANDOMS (DONE 2004-06-27 - Fan)
    ssh kksilo
    cd /cluster/data/mm5/ncbi

    gunzip seq_contig.md.gz

    # reorder random contigs in allrefcontig agp file to match seq_contig.md
    # this is required by the ncbiToRandomAgps scripts
    # had to fixup ncbiToRandomAgps from previous use to match the
    #	lines better, and to do the MT/NC_ mitochondrion thing

    mkdir /cluster/store6/mm5/jkStuff

# copy scripts used from previous trial mm5 build
    cd /cluster/data/mm5
    cp -p ~/mm50/jkStuff/* jkStuff
    cd /cluster/data/mm5/ncbi
    ../jkStuff/ncbiFixAgp allrefcontig.chr.agp > \
                        allrefcontig.chr.ordered.agp

#Edit MANUALLY ../jkStuff/ncbiToRandomAgps, to change build 32 to build 33.

    ../jkStuff/ncbiToRandomAgps seq_contig.md allrefcontig.chr.ordered.agp \
                        contig.idmap ..
        # creating ../mm5/1/chr1_random.agp...
        # ... creating ../mm5/Un/chrUn_random.agp...
    #  The chrUn_random.agp created by this is too large with the 5000
    #  gaps.  it will work with 1000 gaps, so fixup the chrUn_random agp:
    ../jkStuff/ncbiToRandomAgps -gapLen 1000 -chrom Un \
      seq_contig.md allrefcontig.chr.ordered.agp contig.idmap ..

    ssh kksilo
    cd /cluster/data/mm5
    foreach c (?{,?})
      if (-e $c/chr${c}_random.ctg.agp) then
        echo building $c/chr${c}_random.fa
        gunzip -c ./ncbi/contigfasta/chr$c.fa.gz \
          | perl -wpe 's/^>lcl\|(Mm\w+)\s+.*$/>$1/' \
          > ./tmp.fa
        agpToFa -simpleMulti $c/chr${c}_random.ctg.agp chr${c}_random \
          $c/chr${c}_random.fa ./tmp.fa
        rm tmp.fa
      endif
    end
    # building 1/chr1_random.fa
    # ... etc ...
    # building Un/chrUn_random.fa
    # Writing 102265694 bases to Un/chrUn_random.fa

    # Clean these up to avoid confusion later... they're easily rebuilt
    #	with the ncbiToRandomAgps script above
    rm ?/*.ctg.agp ??/*.ctg.agp

# BREAK UP _RANDOMS INTO 5 MB CHUNKS AT NON-BRIDGED CONTIGS (DONE 2004-06-27 - Fan)
    ssh kksilo
    cd /cluster/data/mm5
    foreach c (?{,?})
      if (-e $c/chr${c}_random.agp) then
        splitFaIntoContigs $c/chr${c}_random.agp $c/chr${c}_random.fa . \
          -nSize=5000000
        mkdir -p $c/lift
        mv ${c}_random/lift/oOut.lst $c/lift/rOut.lst
        mv ${c}_random/lift/ordered.lft $c/lift/random.lft
        mv ${c}_random/lift/ordered.lst $c/lift/random.lst
        rmdir ${c}_random/lift
        rm ${c}_random/chr${c}_random.{agp,fa}
        mv ${c}_random/* $c
        rmdir ${c}_random
      endif
    end
    #  This has a lot of output.  It is difficult to see if anything
    #   goes wrong.

#  Fixup chrMT name to be chrM (DONE - 2004-06-27 - Fan)

    ssh kksilo
    cd /cluster/data/mm5
    mv MT MT.ncbi
    mkdir M
    mkdir M/chrM_1
    mkdir M/lift
    cd MT.ncbi

    bash
    find . -type f | while read FN
    do
	NF=`echo $FN | sed -e "s/MT/M/g"`
	sed -e "s/chrMT/chrM/g" $FN > ../M/$NF
    done

# MAKE LIFTALL.LFT (DONE - 2003-06-27 - Fan)

    cd /cluster/data/mm5
    cat ?{,?}/lift/{ordered,random}.lft > jkStuff/liftAll.lft

# 7:40 PM 6/27/04, used dark blue color above.
# Now changed to use dark pink color for things done. 

# CREATING DATABASE (DONE 2004-06-27 - Fan)

# First, clean out mm5 tables built by previous trail build.
# Rename all mm5.* tables to mm5_old4.*,
# then drop database mm5

o - Create the database.
    ssh hgwdev
    hgsql -e 'create database mm5;' ''
    # if you need to delete this database:  !!! WILL DELETE EVERYTHING !!!
    #	hgsql -e "drop database mm5;" mm5
o - Use df to make sure there is at least 5 gig free on hgwdev:/var/lib/mysql
    df -h /var/lib/mysql
    Filesystem            Size  Used Avail Use% Mounted on
    /dev/sdc1             1.8T  383G  1.3T  24% /var/lib/mysql

# CREATING GRP TABLE FOR TRACK GROUPING (DONE - 2004-06-27 - Fan)
    #	Use any of the newest databases to ensure that the organization
    #	of the grp table is up to date
    ssh hgwdev
    hgsql -e "create table grp (PRIMARY KEY(NAME)) select * from hg16.grp" mm5

# STORING O+O SEQUENCE AND ASSEMBLY INFORMATION  (DONE - 2004-06-27 - Fan)
    # Create (unmasked) nib files
    ssh kksilo
    cd /cluster/data/mm5
    mkdir -p unmaskedNib
    foreach f (?{,?}/chr?{,?}{,_random}.fa)
      echo $f:t:r
      faToNib $f unmaskedNib/$f:t:r.nib
    end
    # Create symbolic links from /gbdb/mm5/nib to real nib files
    #	These unmasked Nib files are temporary just to get the browser
    #	up an running immediately.  After the masking is done and masked
    #	sequence is created, these nibs will be replaced with the masked
    #	nibs
    ssh hgwdev
    mkdir -p /gbdb/mm5/nib
    cd /gbdb/mm5/nib
    ln -s /cluster/data/mm5/unmaskedNib/chr*.nib .

    # Load /gbdb nib paths into database and save size info.
    ssh hgwdev
    cd /cluster/data/mm5
    hgsql mm5  < ~/kent/src/hg/lib/chromInfo.sql
    hgNibSeq -preMadeNib mm5 /gbdb/mm5/nib ?{,?}/chr?{,?}{,_random}.fa
    # 3164952073 total bases
    # NOTE: mm4 was 2952612207, an increase of 212 Mb (~7.2%)
    hgsql -N -e "select chrom,size from chromInfo;" mm5 > chrom.sizes
    # check the resulting file chrom.sizes

    # Store o+o info in database.
    cd /cluster/data/mm5/ncbi
    gunzip sequence.inf
    cd /cluster/data/mm5
    ln -s ncbi ffa
    # remove so as not to confuse hgGoldGap -- they are easily regenerated
    rm */chr*.ctg.agp
    # to undo/redo:
    #     jkStuff/dropSplitTable.csh gap
    #     jkStuff/dropSplitTable.csh gold
    /cluster/bin/i386/hgGoldGapGl mm5 /cluster/data/mm5 .
    featureBits mm5 gold
    # 2615483787 bases of 2615483787 (100.000%) in intersection
    featureBits mm4 gold
    # 2627444668 bases of 2627444668 (100.000%) in intersection

    featureBits mm5 gap
    # 549468286 bases of 2615483787 (21.008%) in intersection
    featureBits mm4 gap
    # 325167539 bases of 2627444668 (12.376%) in intersection
    featureBits mm3 gap
    # 202319873 bases of 2505900260 (8.074%) in intersection


# Make and load GC percent table	(DONE - 2004-06-27 - Fan)
#	NOT REQUIRED, been replaced by gc5Base procedure below
     ssh hgwdev
     mkdir -p /cluster/data/mm5/bed/gcPercent
     cd /cluster/data/mm5/bed/gcPercent
     hgsql mm5  < ~/kent/src/hg/lib/gcPercent.sql
     hgGcPercent mm5 ../../unmaskedNib


# MAKE HGCENTRALTEST ENTRY AND TRACKDB TABLE FOR MM5 (DONE - 2004-06-27 - Fan)
    #	using the Mm3 position blatted onto Mm5:
    # Enter mm5 into hgcentraltest.dbDb so test browser knows about it:
    hgsql -e 'INSERT INTO dbDb \
        (name, description, nibPath, organism, defaultPos, \
         active, orderKey, genome, scientificName, htmlPath, \
         hgNearOk, hgPbOk, sourceName) \
      VALUES("mm5", "May 2004", "/gbdb/mm5/nib", "Mouse", \
	"chr6:121658238-121674165", \
         1, 20, "Mouse", "Mus musculus", "/gbdb/mm5/html/description.html",\
	0, 0, "NCBI Build 33");' \
	-h genome-testdb hgcentraltest
    #	If you need to delete that entry:
    hgsql -e 'delete from dbDb where name="mm5";' -h genome-testdb hgcentraltest

    # Make trackDb table so browser knows what tracks to expect:
    ssh hgwdev
    cd ~kent/src/hg/makeDb/trackDb
    cvs up -d -P
    # Edit that makefile to add mm5 in all the right places and do
    make update
    make alpha
    cvs commit makefile

# MAKE HGCENTRALTEST BLATSERVERS ENTRY FOR MM5 (DONE - 2004-07-14 Fan)
    ssh hgwdev

    # Make one big 2bit file as well, and make a link to it in
    # /gbdb/mm5/nib because hgBlat looks there:
    cd /cluster/data/mm5
    faToTwoBit */chr*.fa mm5.2bit
    ln -s /cluster/data/mm5/mm5.2bit /gbdb/mm5/nib/

    hgsql -e 'INSERT INTO blatServers (db, host, port, isTrans, canPcr) \
    VALUES ("mm5", "snort", "17778", "1", "0"); \
    INSERT INTO blatServers (db, host, port, isTrans, canPcr) \
    VALUES ("mm5", "snort", "17779", "0", "1");' \
    -h genome-testdb hgcentraltest

# REPEAT MASKING (Working on 2004-06-27 Fan)
    #	TRF simpleRepeat below can be run at the same time
    # Split contigs, run RepeatMasker, lift results
    # * Contigs (*/chr*_*/chr*_*.fa) are split into 500kb chunks to make
    #   RepeatMasker runs manageable on the cluster ==> results need lifting.
    # * For the NCBI assembly we repeat mask on the sensitive mode setting
    #  (RepeatMasker -m -s -ali)

    #- Split contigs into 500kb chunks:
    ssh kksilo
    cd /cluster/data/mm5
    foreach d ( */chr?{,?}{,_random}_?{,?} )
	cd $d
	set contig = $d:t
	faSplit size $contig.fa 500000 ${contig}_ -lift=$contig.lft \
	    -maxN=500000
	cd ../..
    end
    #	...
    #	11 pieces of 11 written
    #	1 pieces of 1 written
    #	...

    #- Make the run directory and job list:

    cd /cluster/data/mm5
    cat << '_EOF_' > jkStuff/RMMouse
#!/bin/csh -fe

cd $1
pushd .
/bin/mkdir -p /tmp/mm5/$2
/bin/cp $2 /tmp/mm5/$2
cd /tmp/mm5/$2
/cluster/bluearc/RepeatMasker/RepeatMasker -ali -s -species mus $2
popd
/bin/cp /tmp/mm5/$2/$2.out ./
if (-e /tmp/mm5/$2/$2.align) /bin/cp /tmp/mm5/$2/$2.align ./
if (-e /tmp/mm5/$2/$2.tbl) /bin/cp /tmp/mm5/$2/$2.tbl ./
if (-e /tmp/mm5/$2/$2.cat) /bin/cp /tmp/mm5/$2/$2.cat ./
/bin/rm -fr /tmp/mm5/$2/*
/bin/rmdir --ignore-fail-on-non-empty /tmp/mm5/$2
/bin/rmdir --ignore-fail-on-non-empty /tmp/mm5
'_EOF_'
    chmod +x jkStuff/RMMouse

    mkdir -p RMRun
    rm -f RMRun/RMJobs
    foreach d ( ?{,?}/chr*_?{,?} )
	foreach f ( $d/chr*_?{,?}_?{,?}.fa )
	    set f = $f:t
	    echo /cluster/data/mm5/jkStuff/RMMouse \
		/cluster/data/mm5/$d $f \
		'{'check out line+ /cluster/data/mm5/$d/$f.out'}' \
		>> RMRun/RMJobs
	end
    end

    #- Do the run
    ssh kk
    cd /cluster/data/mm5/RMRun
    para create RMJobs
    para try, para check, para check, para push, para check,...

[kk:RMRun> para check
6885 jobs in batch
8 jobs (including everybody's) in Parasol queue.
Checking finished jobs.
ranOk: 6885
total jobs in batch: 6885
[kk:RMRun> para time
6885 jobs in batch
8 jobs (including everybody's) in Parasol queue.
Checking finished jobs
Completed: 6885 of 6885 jobs
CPU time in finished jobs:   40084305s  668071.74m 11134.53h  463.94d  1.271 y
IO & Wait Time:                122589s    2043.16m    34.05h    1.42d  0.004 y
Average job time:                5840s      97.33m     1.62h    0.07d
Longest job:                     9804s     163.40m     2.72h    0.11d
Submission to last job:         46771s     779.52m    12.99h    0.54d

# Done 11:57 AM 6/28/04

    #- Lift up the split-contig .out's to contig-level .out's
    ssh kksilo
    cd /cluster/data/mm5
    foreach d ( ?{,?}/chr*_?{,?} )
      cd $d
      set contig = $d:t
      liftUp $contig.fa.out $contig.lft warn ${contig}_*.fa.out > /dev/null
      cd ../..
    end

    #- Lift up the contig-level .out's to chr-level
    ssh kksilo
    cd /cluster/data/mm5
    ./jkStuff/liftOut5.csh
    #	This one error is OK
    #	Can not find Un/lift/ordered.lft .

    #- Load the .out files into the database with:
    ssh hgwdev
    cd /cluster/data/mm5
    # to redo:
    #    ./jkStuff/dropSplitTable.csh rmsk
    # make sure there's no chrUn -- rm Un/chrUn.fa.out
    hgLoadOut mm5 ?/*.fa.out ??/*.fa.out

# VERIFY REPEATMASKER RESULTS (DONE - 2004-06-28 Fan)

    # Run featureBits on mm5 and on a comparable genome build, and compare:
    ssh hgwdev
featureBits mm5 rmsk
#1137310280 bases of 2615483787 (43.484%) in intersection
#featureBits mm4 rmsk
1130883581 bases of 2627444668 (43.041%) in intersection
#featureBits mm3 rmsk
1080265553 bases of 2505900260 (43.109%) in intersection

#cd /cluster/data/mm5
#awk '{print $1}' chrom.sizes | sed -e "s/chr//" | grep -v random > chrom.lst

# SIMPLE REPEAT TRACK (DONE - 2004-06-29 Fan)
    # TRF can be run in parallel with RepeatMasker on the file server
    #	since it doesn't require masked input sequence.
    ssh kksilo
    mkdir /cluster/data/mm5/bed/simpleRepeat
    cd /cluster/data/mm5/bed/simpleRepeat
    mkdir trf
    rm -f jobs.csh
    echo '#\!/bin/csh -fe' > jobs.csh
    # create job list of 5MB chunks
    foreach f \
       (/cluster/data/mm5/?{,?}/chr?{,?}_[0-9]*/chr?{,?}_?{,?}.fa \
       /cluster/data/mm5/?{,?}/chr*_random_?{,?}/chr*_random_?{,?}.fa)
      set fout = $f:t:r.bed
      echo "/cluster/bin/i386/trfBig -trf=/cluster/bin/i386/trf $f /dev/null -bedAt=trf/$fout -tempDir=/tmp" \
        >> jobs.csh
    end
    chmod +x jobs.csh
    wc jobs.csh
    # 640    3836   90839 jobs.csh

    ./jobs.csh >&! jobs.log &
    # in bash:  ./jobs.csh > jobs.log 2>&1 &
    tail -f jobs.log
    # Done 3:07 PM 6/29/04, took about 6 hours.

    # When job is done lift output files
    liftUp simpleRepeat.bed /cluster/data/mm5/jkStuff/liftAll.lft warn trf/*.bed

    # Load into the database
    ssh hgwdev
    cd /cluster/data/mm5/bed/simpleRepeat
    hgLoadBed mm5 simpleRepeat simpleRepeat.bed \
      -sqlTable=$HOME/src/hg/lib/simpleRepeat.sql
    # Loaded 1150615 elements of size 16

    featureBits mm5 simpleRepeat
    # 81414259 bases of 2615483787 (3.113%) in intersection
    featureBits mm4 simpleRepeat
    # 82600648 bases of 2627444668 (3.144%) in intersection
    featureBits mm3 simpleRepeat
    # 75457193 bases of 2505900260 (3.011%) in intersection


# PROCESS SIMPLE REPEATS INTO MASK (DONE - 2004-06-29 - Fan)

    # After the simpleRepeats track has been built, make a filtered version
    # of the trf output: keep trf's with period <= 12:
    ssh kksilo
    cd /cluster/data/mm5/bed/simpleRepeat
    mkdir -p trfMask
    foreach f (trf/chr*.bed)
      awk '{if ($5 <= 12) print;}' $f > trfMask/$f:t
    end

    # Lift up filtered trf output to chrom coords
    cd /cluster/data/mm5
    mkdir -p bed/simpleRepeat/trfMaskChrom
    foreach c (?{,?})
      if (-e $c/lift/ordered.lst) then
	perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
	  $c/lift/ordered.lst > $c/lift/oTrf.lst
	liftUp bed/simpleRepeat/trfMaskChrom/chr$c.bed \
	  jkStuff/liftAll.lft warn `cat $c/lift/oTrf.lst`
      else
	echo "WARNING NO FILE:  $c/lift/ordered.lst"
      endif
      if (-e $c/lift/random.lst) then
        perl -wpe 's@(\S+)@bed/simpleRepeat/trfMask/$1.bed@' \
           $c/lift/random.lst > $c/lift/rTrf.lst
        liftUp bed/simpleRepeat/trfMaskChrom/chr${c}_random.bed \
          jkStuff/liftAll.lft warn `cat $c/lift/rTrf.lst`
      endif
    end
    # NOTE: ignore warning about non-existent Un/Lift/ordered.lift
    # since there is no chrUn

# MASK SEQUENCE WITH BOTH REPEATMASKER AND SIMPLE REPEAT/TRF
#				(Working on - 2004-06-29 Fan)
    ssh kksilo
    cd /cluster/data/mm5
    #- Soft-mask (lower-case) the contig and chr .fa's
    ./jkStuff/makeFaMasked.csh >&! maskFa.out &
    #	bash:	./jkStuff/makeFaMasked.csh > maskFa.out 2>&1 &
    tail -100f maskFa.out

    #- Make hard-masked .fa.masked files as well:
    ./jkStuff/makeHardMasked.csh

Edited ./jkStuff/makeNib.csh to comment out "if ..." and "endif" as below:

#!/bin/csh -fe

mkdir -p nib mixedNib maskedNib
foreach i (?{,?})
   cd $i
#   foreach j (chr$i{,_random}.fa)
   foreach j (*.fa)
#       if (-e "${j}")
        set r = $j:r
       /cluster/bin/i386/faToNib $j ../nib/$r.nib
       /cluster/bin/i386/faToNib -softMask $j ../mixedNib/$r.nib
       /cluster/bin/i386/faToNib -hardMask $j ../maskedNib/$r.nib
#       endif
       echo done $j
   end
   cd ..
end

    #- Rebuild the nib, mixedNib, maskedNib files:
    ./jkStuff/makeNib.csh
    # ignore complaints about missing chrUn

    # Redo symbolic links from /gbdb/mm5/nib to
    #   mixed (RM and TRF) soft-masked nib files
    ssh hgwdev
    rm -fr /gbdb/mm5/nib/*
    ln -s /cluster/data/mm5/mixedNib/chr*.nib /gbdb/mm5/nib

    # Copy data to /cluster/bluearc for cluster runs
    ssh kksilo

    # masked contigs
    rm -fr /cluster/bluearc/scratch/mus/mm5/trfFa
    mkdir -p /cluster/bluearc/scratch/mus/mm5/trfFa
    cp -p /cluster/data/mm5/?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa \
	/cluster/bluearc/scratch/mus/mm5/trfFa

    # masked chrom nibs
    cd /cluster/data/mm5
    rm -fr /cluster/bluearc/scratch/mus/mm5/softNib
    mkdir -p /cluster/bluearc/scratch/mus/mm5/softNib
    cp -p mixedNib/chr*.nib /cluster/bluearc/scratch/mus/mm5/softNib
    rm -fr /cluster/bluearc/scratch/mus/mm5/hardNib
    mkdir -p /cluster/bluearc/scratch/mus/mm5/hardNib
    cp -p maskedNib/chr*.nib /cluster/bluearc/scratch/mus/mm5/hardNib

    # fasta files
    rm -fr /cluster/bluearc/scratch/mus/mm5/fasta
    mkdir -p /cluster/bluearc/scratch/mus/mm5/fasta
    cp -p ?/*.fa ??/*.fa /cluster/bluearc/scratch/mus/mm5/fasta

    # RepeatMasker *.out files
    rm -rf /cluster/bluearc/scratch/mus/mm5/rmsk
    mkdir -p /cluster/bluearc/scratch/mus/mm5/rmsk
    cp -p ?{,?}/chr?{,?}{,_random}.fa.out /cluster/bluearc/scratch/mus/mm5/rmsk

    # lift file, for mrna processing
    cp -p jkStuff/liftAll.lft /cluster/bluearc/scratch/mus/mm5
#above was done 6/29/04 4:50PM

    # also copy to iservers
    ssh kkr1u00
    #cd ~/mm5
    cd /cluster/bluearc/scratch/mus/mm5

    mkdir /iscratch/i/mus/mm5
    cp -p liftAll.lft /iscratch/i/mus/mm5
    mkdir -p /iscratch/i/mus/mm5/softNib
    cp -p /cluster/bluearc/scratch/mus/mm5/softNib/chr*.nib /iscratch/i/mus/mm5/softNib

    mkdir -p /iscratch/i/mus/mm5/trfFa
    cd /cluster/store6/mm5
    cp ?{,?}/chr*_*/chr?{,?}{,_random}_?{,?}.fa /cluster/bluearc/scratch/mus/mm5/trfFa
    /cluster/bin/scripts/iSync

ssh kkr1u00
mkdir /iscratch/i/mus/mm5
cd /iscratch/i/mus
rsync -arlv /cluster/bluearc/scratch/mus/mm5 .

#wrote 8660800915 bytes  read 15380 bytes  17729409.00 bytes/sec
#total size is 10242205742  speedup is 1.18

cd /iserver/kkr1u00/i/mus/mm5
mv trfFa maskedContigs
cd /cluster/bluearc/scratch/mus/mm5
mv trfFa maskedContigs

# PREPARE CLUSTER FOR BLASTZ RUN (DONE - 2004-06-29 - Fan)

    ssh kksilo
    mkdir -p /cluster/bluearc/scratch/mus/mm5/rmsk.spec
    cd /cluster/bluearc/scratch/mus/mm5/rmsk.spec
    ln -s ../rmsk/*.out .

# NOTE: DON't leave indentations in the script below.
cat << '_EOF_' > runArian.sh
#!/bin/sh
for FN in *.out
do
echo ${FN}
/cluster/bluearc/RepeatMasker/DateRepsinRMoutput.pl \
${FN} -query mouse -comp human -comp rat
done
'_EOF_'

    chmod +x runArian.sh
    ./runArian.sh 

    cd /cluster/bluearc/scratch/mus/mm5
    mkdir linSpecRep.notInHuman
    mkdir linSpecRep.notInRat
    foreach f (rmsk.spec/*.out_hum_rat)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInHuman/$base.out.spec
    end

    foreach f (rmsk.spec/*.out_hum_rat)
        set base = $f:t:r:r
	echo $base.out.spec
	/cluster/bin/scripts/extractLinSpecReps 2 $f > \
		linSpecRep.notInRat/$base.out.spec
	end

    cp rmsk.spec /iscratch/i/mus/mm5 -Rp
    cp linSpecRep.notInRat /iscratch/i/mus/mm5 -Rp
    cp linSpecRep.notInHuman /iscratch/i/mus/mm5 -Rp

    /cluster/bin/scripts/iSync

    # Request rsync /cluster/bluearc/scratch/mus/mm5 to the KiloKluster

#  GC5BASE WIGGLE TRACK (DONE - 2004-06-24 - Hiram)
    #	This previously was a script that ran through each nib.
    #	Recently transformed into a mini cluster run.
    ssh kki
    mkdir /cluster/data/mm5/bed/gc5Base
    cd /cluster/data/mm5/bed/gc5Base

    mkdir wigData5 dataLimits5 wigData5_1K dataLimits5_1K

    cat << '_EOF_' > kkRun.sh
#!/bin/sh
NIB=$1

chr=${NIB/.nib/}
chrom=${chr#chr}

hgGcPercent -chr=${chr} -doGaps -file=stdout -win=5 mm5 \
        /cluster/data/mm5/mixedNib | \
    grep -w GC | \
    awk '{if (($3-$2) >= 5) {printf "%d\t%.1f\n", $2+1, $5/10.0} }' | \
    wigAsciiToBinary -dataSpan=5 -chrom=${chr} \
        -wibFile=wigData5/gc5Base_${chrom} \
            -name=${chrom} stdin 2> dataLimits5/${chr}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x kkRun.sh

    ls /cluster/data/mm5/mixedNib > nibList
    cat << '_EOF_' > gsub
#LOOP
./kkRun.sh $(path1)
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 nibList single gsub jobList
    para create jobList
    para try, check, ... etc
# Completed: 43 of 43 jobs
# CPU time in finished jobs:       4969s      82.81m     1.38h    0.06d  0.000 y
# IO & Wait Time:                   611s      10.19m     0.17h    0.01d  0.000 y
# Average job time:                 130s       2.16m     0.04h    0.00d
# Longest job:                      370s       6.17m     0.10h    0.00d
# Submission to last job:           598s       9.97m     0.17h    0.01d

    # load the .wig files back on hgwdev:
    ssh hgwdev
    cd /cluster/data/mm5/bed/gc5Base
    hgLoadWiggle -pathPrefix=/gbdb/mm5/wib/gc5Base mm5 gc5Base wigData5/*.wig
    # and symlink the .wib files into /gbdb
    mkdir /gbdb/mm5/wib/gc5Base
    ln -s `pwd`/wigData5/*.wib /gbdb/mm5/wib/gc5Base

    #	And then the zoomed data view
    ssh kki
    cd /cluster/data/mm5/bed/gc5Base
    mkdir wigData5_1K dataLimits5_1K

    cat << '_EOF_' > kkRunZoom.sh
#!/bin/sh
NIB=$1

chr=${NIB/.nib/}
chrom=${chr#chr}

hgGcPercent -chr=${chr} -doGaps -file=stdout -win=5 mm5 \
        /cluster/data/mm5/mixedNib | \
    grep -w GC | \
    awk '{if (($3-$2) >= 5) {printf "%d\t%.1f\n", $2+1, $5/10.0} }' | \
    wigZoom -dataSpan=1000 stdin | wigAsciiToBinary -dataSpan=1000 \
	-chrom=${chr} -wibFile=wigData5_1K/gc5Base_${chrom}_1K \
            -name=${chrom} stdin 2> dataLimits5_1K/${chr}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x kkRunZoom.sh

    cat << '_EOF_' > gsubZoom
#LOOP
./kkRunZoom.sh $(path1)
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 nibList single gsubZoom jobListZoom
    para create jobListZoom
    para try ... check ... etc ...
# Completed: 43 of 43 jobs
# CPU time in finished jobs:       4878s      81.29m     1.35h    0.06d  0.000 y
# IO & Wait Time:                   488s       8.14m     0.14h    0.01d  0.000 y
# Average job time:                 125s       2.08m     0.03h    0.00d
# Longest job:                      378s       6.30m     0.10h    0.00d
# Submission to last job:           665s      11.08m     0.18h    0.01d

    #	Then load these .wig files into the same database as above
    ssh hgwdev
    cd /cluster/data/mm5/bed/gc5Base
    hgLoadWiggle -pathPrefix=/gbdb/mm5/wib/gc5Base \
	-oldTable mm5 gc5Base wigData5_1K/*.wig
    # and symlink these .wib files into /gbdb
    ln -s `pwd`/wigData5_1K/*.wib /gbdb/mm5/wib/gc5Base

#  GC5BASE WIGGLE TRACK (DONE - 2004-07-01 - Hiram)
    #	This previously was a script that ran through each nib.
    #	Recently transformed into a mini cluster run.
    ssh kki
    mkdir /cluster/data/mm5/bed/gc5Base
    cd /cluster/data/mm5/bed/gc5Base

    mkdir wigData5 dataLimits5 wigData5_1K dataLimits5_1K

    cat << '_EOF_' > kkRun.sh
#!/bin/sh
NIB=$1

chr=${NIB/.nib/}
chrom=${chr#chr}

hgGcPercent -chr=${chr} -doGaps -file=stdout -win=5 mm5 \
        /cluster/data/mm5/mixedNib | \
    grep -w GC | \
    awk '{if (($3-$2) >= 5) {printf "%d\t%.1f\n", $2+1, $5/10.0} }' | \
    wigAsciiToBinary -dataSpan=5 -chrom=${chr} \
        -wibFile=wigData5/gc5Base_${chrom} \
            -name=${chrom} stdin 2> dataLimits5/${chr}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x kkRun.sh

    ls /cluster/data/mm5/mixedNib > nibList
    cat << '_EOF_' > gsub
#LOOP
./kkRun.sh $(path1)
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 nibList single gsub jobList
    para create jobList
    para try, check, ... etc
# Completed: 43 of 43 jobs
# CPU time in finished jobs:       4857s      80.94m     1.35h    0.06d  0.000 y
# IO & Wait Time:                   121s       2.02m     0.03h    0.00d  0.000 y
# Average job time:                 116s       1.93m     0.03h    0.00d
# Longest job:                      335s       5.58m     0.09h    0.00d
# Submission to last job:           516s       8.60m     0.14h    0.01d

    # load the .wig files back on hgwdev:
    ssh hgwdev
    cd /cluster/data/mm5/bed/gc5Base
    hgLoadWiggle -pathPrefix=/gbdb/mm5/wib/gc5Base mm5 gc5Base wigData5/*.wig
    # and symlink the .wib files into /gbdb
    mkdir /gbdb/mm5/wib
    mkdir /gbdb/mm5/wib/gc5Base
    ln -s `pwd`/wigData5/*.wib /gbdb/mm5/wib/gc5Base

    #	And then the zoomed data view
    ssh kki
    cd /cluster/data/mm5/bed/gc5Base
    mkdir wigData5_1K dataLimits5_1K

    cat << '_EOF_' > kkRunZoom.sh
#!/bin/sh
NIB=$1

chr=${NIB/.nib/}
chrom=${chr#chr}

hgGcPercent -chr=${chr} -doGaps -file=stdout -win=5 mm5 \
        /cluster/data/mm5/mixedNib | \
    grep -w GC | \
    awk '{if (($3-$2) >= 5) {printf "%d\t%.1f\n", $2+1, $5/10.0} }' | \
    wigZoom -dataSpan=1000 stdin | wigAsciiToBinary -dataSpan=1000 \
	-chrom=${chr} -wibFile=wigData5_1K/gc5Base_${chrom}_1K \
            -name=${chrom} stdin 2> dataLimits5_1K/${chr}
'_EOF_'
    # << this line makes emacs coloring happy
    chmod +x kkRunZoom.sh

    cat << '_EOF_' > gsubZoom
#LOOP
./kkRunZoom.sh $(path1)
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    gensub2 nibList single gsubZoom jobListZoom
    para create jobListZoom
    para try ... check ... etc ...
# Completed: 43 of 43 jobs
# CPU time in finished jobs:       4819s      80.31m     1.34h    0.06d  0.000 y
# IO & Wait Time:                    82s       1.37m     0.02h    0.00d  0.000 y
# Average job time:                 114s       1.90m     0.03h    0.00d
# Longest job:                      336s       5.60m     0.09h    0.00d
# Submission to last job:           500s       8.33m     0.14h    0.01d

    #	Then load these .wig files into the same database as above
    ssh hgwdev
    cd /cluster/data/mm5/bed/gc5Base
    hgLoadWiggle -pathPrefix=/gbdb/mm5/wib/gc5Base \
	-oldTable mm5 gc5Base wigData5_1K/*.wig
    # and symlink these .wib files into /gbdb
    ln -s `pwd`/wigData5_1K/*.wib /gbdb/mm5/wib/gc5Base

# BLASTZ HG17 (WORKING - 2004-07-06 - Hiram)
    ssh kk
    mkdir -p /cluster/data/mm5/bed/blastz.hg17.2004-07-06
    cd /cluster/data/mm5/bed
    ln -s  blastz.hg17.2004-07-06 blastz.hg17
    cd blastz.hg17

    cat << '_EOF_' > DEF
# mouse vs. human
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/home/angie/schwartzbin:/cluster/home/kent/bin/i386

ALIGN=blastz-run
BLASTZ=blastz
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET
# Mouse
SEQ1_DIR=/scratch/mus/mm5/softNib
# not used
SEQ1_RMSK=/scratch/mus/mm5/rmsk
# not used
SEQ1_FLAG=-rodent
SEQ1_SMSK=/scratch/mus/mm5/linSpecRep.notInHuman
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY
# Human
SEQ2_DIR=/iscratch/i/gs.18/build35/bothMaskedNibs
# RMSK not currently used
SEQ2_RMSK=
# FLAG not currently used
SEQ2_FLAG=
SEQ2_SMSK=/iscratch/i/gs.18/build35/linSpecRep.notInMouse
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=30000000
SEQ2_LAP=0

BASE=/cluster/data/mm5/bed/blastz.hg17

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    # prepare first cluster run
    ssh kk
    cd /cluster/data/mm5/bed/blastz.hg17
    #	OK to use this script here, it is generic, works anywhere
    /cluster/data/hg17/jkStuff/BlastZ_run0.sh
    cd run.0
    para try, check, push, check, ....
# Completed: 46717 of 46717 jobs
# CPU time in finished jobs:   16171136s  269518.93m  4491.98h  187.17d  0.513 y
# IO & Wait Time:                534501s    8908.35m   148.47h    6.19d  0.017 y
# Average job time:                 358s       5.96m     0.10h    0.00d
# Longest job:                     5263s      87.72m     1.46h    0.06d
# Submission to last job:         30066s     501.10m     8.35h    0.35d

    #	the file server to its knees.  Run this on the small cluster.
    ssh kki
    cd /cluster/data/mm5/bed/blastz.hg17
    /cluster/data/hg17/jkStuff/BlastZ_run1.sh
    cd run.1
    para try, check, push, etc ...
# Completed: 341 of 341 jobs
# CPU time in finished jobs:       2186s      36.43m     0.61h    0.03d  0.000 y
# IO & Wait Time:                  1804s      30.07m     0.50h    0.02d  0.000 y
# Average job time:                  12s       0.20m     0.00h    0.00d
# Longest job:                       82s       1.37m     0.02h    0.00d
# Submission to last job:          3895s      64.92m     1.08h    0.05d

    #	Third cluster run to convert lav's to axt's
    #	Does not work on kki since /scratch on the iservers is not the
    #	same as /scratch on the other clusters.
    ssh kk
    cd /cluster/data/mm5/bed/blastz.hg17
    /cluster/data/hg17/jkStuff/BlastZ_run2.sh
    cd run.2
    para try, check, push, etc ...
# Completed: 43 of 43 jobs
# CPU time in finished jobs:       2099s      34.98m     0.58h    0.02d  0.000 y
# IO & Wait Time:                  6862s     114.37m     1.91h    0.08d  0.000 y
# Average job time:                 208s       3.47m     0.06h    0.00d
# Longest job:                     1276s      21.27m     0.35h    0.01d
# Submission to last job:          1291s      21.52m     0.36h    0.01d

    # translate sorted axt files into psl
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.hg17
    mkdir p pslChrom
    set tbl = "blastzHg17"
    foreach f (axtChrom/chr*.axt)
      set c=$f:t:r
      echo "Processing chr $c"
      /cluster/bin/i386/axtToPsl $f S1.len S2.len pslChrom/${c}_${tbl}.psl
    end
    #	This takes more than an hour.  You can shorten this by changing
    #	that command to a simple echo, put the results into a file,
    #	split the file into four parts and run the four files as shell
    #	scripts on kksilo to have four processes running at the same
    #	time.  Load on kksilo gets up to about 20 which is reasonable.

    # Load database tables
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.hg17/pslChrom
    bash		#	for tcsh users
    for F in chr*_blastzHg17.psl
    do
	/cluster/bin/i386/hgLoadPsl mm5 ${F}
	echo "${F} done"
    done
    # this is a 40 minute job
    # exit bash if you are tcsh

    # featureBits on blastzMm3 or 4 will not work on hgwdev, runs out of
    # memory.  But if you reset your ~/.hg.conf to use the read-only
    #	user and contact the hgwdev host, then use the x86_64 featureBits
    # featureBits mm5 blastzHg17
    #	1057836001 bases of 2615483787 (40.445%) in intersection
    # featureBits mm4 blastzHg16
    #	1068995521 bases of 2627444668 (40.686%) in intersection

# CHAIN MM5 BLASTZ (DONE - 2004-07-02 - Hiram)

# The axtChain is best run on the small kluster, or the kk9 kluster
    ssh kki
    mkdir -p /cluster/data/mm5/bed/blastz.hg17/axtChain/run1
    cd /cluster/data/mm5/bed/blastz.hg17/axtChain/run1
    mkdir out chain

    ls -1S /cluster/data/mm5/bed/blastz.hg17/axtChrom/*.axt > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} out/$(root1).out
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

#  May need -minScore=5000 for all chroms if chr19 won't finish on kolossus

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain $1 /iscratch/i/mus/mm5/softNib \
	/iscratch/i/gs.18/build35/bothMaskedNibs $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain

    # 46 jobs
    gensub2 input.lst single gsub jobList
    para create jobList
    para try
    para push # ... etc ...
# Completed: 43 of 43 jobs
# CPU time in finished jobs:       5354s      89.23m     1.49h    0.06d  0.000 y
# IO & Wait Time:                 10543s     175.72m     2.93h    0.12d  0.000 y
# Average job time:                 370s       6.16m     0.10h    0.00d
# Longest job:                     1694s      28.23m     0.47h    0.02d
# Submission to last job:          1694s      28.23m     0.47h    0.02d

    # now on the file server, sort chains
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.hg17/axtChain
    time chainMergeSort run1/chain/*.chain > all.chain
    #	real    4m53.428s
    #	user    4m3.040s
    #	sys     0m29.440s

    time chainSplit chain all.chain
    #	real    4m34.674s
    #	user    3m38.370s
    #	sys     0m29.990s

    # optionally: rm run1/chain/*.chain

    # Load chains into database
    # next machine
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.hg17/axtChain/chain
    bash	#	for tcsh users
    for I in *.chain
    do
        c=${I/.chain/}
        hgLoadChain mm5 ${c}_chainHg17 $I
        echo done $c
    done
    # exit bash if you are tcsh
    #	This is a 50 minute job

    #	featureBits mm5 chainHg17
    #	2507720521 bases of 2615483787 (95.880%) in intersection
    #	featureBits mm4 chainHg16
    #	2558968088 bases of 2627444668 (97.394%) in intersection

# NET MM5 (WORKING - 2004-07-02 - Hiram)
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.hg17/axtChain
    mkdir preNet
    cd chain
    bash	#	for tcsh users
    for I in *.chain
    do
      echo preNetting $I
      /cluster/bin/i386/chainPreNet $I /cluster/data/mm5/chrom.sizes \
		/cluster/data/hg17/chrom.sizes ../preNet/$I
    done
    # exit bash if you are tcsh
    #	7 minute job

    cd ..
    mkdir n1
    cd preNet
    bash	#	for tcsh users
    for I in *.chain
    do
      n=${I/.chain/}.net
      echo primary netting $I $n
      /cluster/bin/i386/chainNet $I -minSpace=1 /cluster/data/mm5/chrom.sizes \
	/cluster/data/hg17/chrom.sizes ../n1/$n /dev/null
    done
    # exit bash if you are tcsh
    #	5 minute job

    cd ..
    cat n1/*.net | /cluster/bin/i386/netSyntenic stdin hNoClass.net
    #	memory usage 2546110464, utime 16327 s/100, stime 3546

    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.hg17/axtChain
    time netClass hNoClass.net mm5 hg17 human.net \
	-tNewR=/cluster/bluearc/scratch/mus/mm5/linSpecRep.notInHuman \
	-qNewR=/cluster/bluearc/scratch/hg/gs.18/build35/linSpecRep.notInMouse
    #	real    9m45.271s
    #	user    6m47.170s
    #	sys     1m20.440s

    # If things look good do
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.hg17/axtChain
    rm -r n1 hNoClass.net
    # Make a 'syntenic' subset of these with
    time netFilter -syn human.net > humanSyn.net
    #	real    12m3.701s
    #	user    8m44.180s
    #	sys     1m1.610s

    # Load the nets into database
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.hg17/axtChain
    netFilter -minGap=10 human.net |  hgLoadNet mm5 netHg17 stdin
    netFilter -minGap=10 humanSyn.net | hgLoadNet mm5 syntenyNetHg17 stdin

    # check results
    # featureBits mm5 netHg17
    #	2504056038 bases of 2615483787 (95.740%) in intersection
    # featureBits mm4 netHg16
    #	2553137690 bases of 2627444668 (97.172%) in intersection

    # featureBits mm5 syntenyNetHg17
    #	2460442823 bases of 2615483787 (94.072%) in intersection
    # featureBits mm4 syntenyNetHg16
    #	2495783103 bases of 2627444668 (94.989%) in intersection

    # Add entries for net and chain to mouse/hg17 trackDb

    # make net
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.hg17/axtChain
    mkdir humanNet
    time netSplit human.net humanNet
    #	real    4m46.190s
    #	user    3m27.740s
    #	sys     0m38.900s

    #	extract axt's from net, and convert to maf's
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.hg17/axtChain
    mkdir ../axtNet ../mafNet
cat > makeMaf.csh << '_EOF_'
#!/bin/csh -ef
    foreach f (humanNet/chr*.net)
        set c = $f:t:r
        echo "netToAxt: $c.net -> $c.axt"
        rm -f ../axtNet/$c.axt
        netToAxt humanNet/$c.net chain/$c.chain \
	    /cluster/data/mm5/nib /cluster/data/hg17/nib stdout | \
	    axtSort stdin ../axtNet/$c.axt
        axtToMaf ../axtNet/$c.axt \
            /cluster/data/mm5/chrom.sizes /cluster/data/hg17/chrom.sizes \
            ../mafNet/$c.maf -tPrefix=mm5. -qPrefix=hg17.
	echo "Complete: $c.net -> axtNet/$c.axt -> mafNet/$c.maf"
    end
'_EOF_'
# << for emacs
    csh makeMaf.csh >&! makeMaf.log &
    tail -100f makeMaf.log
    #	real    39m53.316s
    #	user    20m2.530s
    #	sys     4m40.120s


    ssh hgwdev
    mkdir /cluster/data/mm5/bed/blastz.hg17/axtBest
    cd /cluster/data/mm5/bed/blastz.hg17/axtBest
    ln -s ../axtNet/chr*.axt .

    # copy net axt's to download area
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.hg17/axtNet
    mkdir -p /usr/local/apache/htdocs/goldenPath/mm5/vsHg17/axtNet
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/mm5/vsHg17/axtNet
    cd /usr/local/apache/htdocs/goldenPath/mm5/vsHg17/axtNet
    gzip *.axt
XXX - running 2004-07-13 14;18
    # add README.txt file to dir (use previous assembly's copy as template)
    #	32 minute gzip

    #  Convert those axt files to psl
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.hg17
    mkdir pslBest
    foreach a (axtBest/chr*.axt)
	set c=$a:t:r
	echo -n "processing $c.axt -> ${c}_blastzBesthg17.psl ..."
    /cluster/bin/i386/axtToPsl axtBest/${c}.axt \
	S1.len S2.len pslBest/${c}_blastzBestHg17.psl
	echo "Done"
    end

    # Load tables
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.hg17/pslBest
    for I in chr*BestHg17.psl
    do
	/cluster/bin/i386/hgLoadPsl mm5 ${I}
	echo "done ${I}"
    done

     # check results
    # featureBits mm5 blastzBestHg17
    #	1020692679 bases of 2615483787 (39.025%) in intersection
    # featureBits mm4 blastzBestHg16
    #	1030510540 bases of 2627444668 (39.221%) in intersection

    # Make /gbdb links and add them to the axtInfo table:
     mkdir -p /gbdb/mm5/axtBest/Hg17
     cd /gbdb/mm5/axtBest/Hg17
     ln -s /cluster/data/mm5/bed/blastz.hg17/axtNet/chr*.axt .
     cd /cluster/data/mm5/bed/blastz.hg17/axtNet
     rm -f axtInfoInserts.sql
     foreach f (/gbdb/mm5/axtBest/Hg17/chr*.axt)
       set chr=$f:t:r
       echo "INSERT INTO axtInfo (species, alignment, chrom, fileName) \
                VALUES ('hg17','Blastz Best in Genome','$chr','$f');" \
         >>! axtInfoInserts.sql
     end
    hgsql mm5 < ~/kent/src/hg/lib/axtInfo.sql
    #	table axtInfo may already exist, ignore create error.
    hgsql mm5 < axtInfoInserts.sql

# MAKING HUMAN SYNTENY (DONE - 2004-07-13 - Hiram)

ssh hgwdev
mkdir /cluster/data/mm5/bed/syntenyHg17
cd /cluster/data/mm5/bed/syntenyHg17

# Copy all the needed scripts from /cluster/data/hg16/bed/syntenyRn3
cp -p /cluster/data/hg17/bed/syntenyRn3/*.pl .

./syntenicBest.pl -db=mm5 -table=blastzBestHg17 > synBest.out 2>&1
./smooth.pl > smooth.out 2>&1
./joinsmallgaps.pl > joingaps.out 2>&1
./fillgap.pl -db=mm5 -table=blastzBestHg17 > fillgap.out 2>&1
./synteny2bed.pl > syn2bed.out 2>&1

    #	The five commands above
    #	real    168m43.627s
    #	user    0m18.680s
    #	sys     0m4.990s

#	Used to load this in syntenyHg17, but that type is misleading to
#	the table browser and fails the checkTableCoords check.
#	Better to use this ensRatMusHom type:
#	Need a new name here for the Hg17 to not conflict with the
#	others
sed -e 's/ensPhusionBlast/ensRatMusHg17/g' \
      $HOME/kent/src/hg/lib/ensPhusionBlast.sql \
      > ensRatMusHg17.sql
hgLoadBed mm5 ensRatMusHg17 ucsc100k.bed -sqlTable=ensRatMusHg17.sql

    # featureBits mm5 ensRatMusHg17
    #	2366463967 bases of 2615483787 (90.479%) in intersection
    # featureBits mm4 syntenyHg16
    #	2299774191 bases of 2627444668 (87.529%) in intersection

# MAKING MOUSE AXTTIGHT FROM AXTBEST (DONE - 2004-07-13 - Hiram)
    # After creating axtBest alignments above, use subsetAxt to get axtTight:
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.hg17/axtNet
    mkdir -p ../axtTight
    bash	#	for tcsh users
    for I in *.axt
    do
      echo "axtNet/$I -> ../axtTight/$I"
      subsetAxt  $I ../axtTight/$I \
	~kent/src/hg/mouseStuff/subsetAxt/coding.mat 3400
    done
    # exit bash if you are tcsh
    #	An 8 minute job

    # translate to psl
    cd ../axtTight
    mkdir ../pslTight
    bash	#	for tcsh users
    for I in *.axt
    do
      C=${I/.axt/}
      axtToPsl $I ../S1.len ../S2.len ../pslTight/${C}_blastzTightHg17.psl
      echo "Done: $I -> ${C}_blastzTightHg17.psl"
    done
    # exit bash if you are tcsh

    # Load tables into database
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.hg17/pslTight
    for I in chr*TightHg17.psl
    do
	/cluster/bin/i386/hgLoadPsl mm5 ${I}
	echo "done ${I}"
    done

    #	Compare results with previous assembly:
    #	featureBits mm5 blastzTightHg17
    #	168148800 bases of 2615483787 (6.429%) in intersection
    #	featureBits mm4 blastzTightHg16
    #	170163839 bases of 2627444668 (6.476%) in intersection

    # copy  axt's to download area
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.hg17/axtTight
    mkdir -p /usr/local/apache/htdocs/goldenPath/mm5/vsHg17/axtTight
    cp -p *.axt /usr/local/apache/htdocs/goldenPath/mm5/vsHg17/axtTight
    cd /usr/local/apache/htdocs/goldenPath/mm5/vsHg17/axtTight
    gzip *.axt
    # add README.txt file to dir (use previous assembly's copy as template)
    #	4 minute gzip

#### BUILD Ensembl cross-reference table, ensemblXref3 (DONE - 2004-07-13 - Fan)

# PLEASE NOTE THAT THE ENSEMBLXREF3 TABLE IS BUILT USING ENSMART DATA OF MOUSE BUILD 32.
# THIS TABLE IS NEEDED TO SUPPORT SUPERFAMILY TRACK OF THE PROTEOME BROWSER.
# WHEN ENSEMBL FINISHES THEIR MOUSE BUILD 33 RELEASE, WE NEED TO REBUILD THIS
# TABLE.
    # Get the ensembl gene/protein cross-reference data from
    # http://www.ensembl.org/Multi/martview?species=Mus_musculus
    # Follow this sequence through the pages:
    # Page 1) Make sure that the Mus musculus choice is selected. Hit next.
    # Page 2) Uncheck the "Limit to" box in the region choice. Then hit next.
    # Page 3) Choose the "Feature" box, select Ensembl gene, transcript, and peptid IDs,
	      SPTrEMBL ID, SWISSPROT ID, and SWISSPROT AC 
    # Page 4) Choose "Text, tab separated".  choose gzip compression.  hit export.
    # Save as ensXref

    sed ensXref.tsv -e 's/\./\t/g' > ensemblXref3.tab

    hgsql mm5 -e "drop table ensemblXref3"
    hgsql mm5 < ~/src/hg/lib/ensemblXref3.sql

    hgsql mm5 -e 'load data local infile "ensemblXref3.tab" into table ensemblXref3 ignore 1 lines'

# CPGISLANDS (DONE - 2004-07-13 - Fan)
    ssh hgwdev
    mkdir -p /cluster/data/mm5/bed/cpgIsland
    cd /cluster/data/mm5/bed/cpgIsland

    # Build software from Asif Chinwalla (achinwal@watson.wustl.edu)
    cvs co hg3rdParty/cpgIslands
    cd hg3rdParty/cpgIslands
    make
    #	gcc readseq.c cpg_lh.c -o cpglh.exe
    mv cpglh.exe /cluster/data/mm5/bed/cpgIsland/
    
    # cpglh.exe requires hard-masked (N) .fa's.  
    # There may be warnings about "bad character" for IUPAC ambiguous 
    # characters like R, S, etc.  Ignore the warnings.  
    ssh kksilo
    cd /cluster/data/mm5/bed/cpgIsland
    foreach f (../../*/chr*.fa.masked)
      set fout=$f:t:r:r.cpg
      echo running cpglh on $f to $fout
      ./cpglh.exe $f > $fout
    end
    #	the warnings:
    # Bad char 0x52 = 'R' at line 117472, base 5873535, sequence chr14
    # Bad char 0x53 = 'S' at line 120651, base 6032462, sequence chr14
    # Bad char 0x53 = 'S' at line 120652, base 6032546, sequence chr14
    #	real    21m47.823s
    #	user    18m30.810s
    #	sys     1m13.420s

    # Transform cpglh output to bed +
    cat << '_EOF_' > filter.awk
{
$2 = $2 - 1;
width = $3 - $2;
printf("%s\t%d\t%s\t%s %s\t%s\t%s\t%0.0f\t%0.1f\t%s\t%s\n",
       $1, $2, $3, $5,$6, width,
       $6, width*$7*0.01, 100.0*2*$6/width, $7, $9);
}
'_EOF_'
    # << this line makes emacs coloring happy
    awk -f filter.awk chr*.cpg > cpgIsland.bed

    ssh hgwdev
    cd /cluster/data/mm5/bed/cpgIsland
    hgLoadBed mm5 cpgIslandExt -tab -noBin \
      -sqlTable=$HOME/kent/src/hg/lib/cpgIslandExt.sql cpgIsland.bed
    
    # Reading cpgIsland.bed
    # Loaded 16238 elements of size 10
    # Sorted
    # Saving bed.tab
    # Loading mm5

# MAKE DOWNLOADABLE SEQUENCE FILES (DONE 2004-07-14 Fan)
    ssh kksilo
    cd /cluster/data/mm5

    # Build the .zip files
    cp /cluster/data/rn3/jkStuff/zipAll.sh jkStuff
    # edit this zipAll.sh to produce output to /cluster/data/mm5/bigZips
    jkStuff/zipAll.sh > zipAll.log
    #	bash:	./jkStuff/zipAll.sh > zipAll.log 2>&1 &
    tail -f zipAll.log

    mkdir zip
    mv *.zip zip
    cd zip
    # Look at zipAll.log to make sure all file lists look reasonable.
    # Check zip file integrity:
    foreach f (*.zip)
      unzip -t $f > $f.test
      tail -1 $f.test
    end

    wc -l *.zip.test
    # 46 chromAgp.zip.test
    # 45 chromFa.zip.test
    # 45 chromFaMasked.zip.test
    # 45 chromOut.zip.test
    # 45 chromTrf.zip.test
    # 641 contigAgp.zip.test
    # 641 contigFa.zip.test
    # 641 contigFaMasked.zip.test
    # 641 contigOut.zip.test
    # 641 contigTrf.zip.test
    #3431 total

    ssh hgwdev
    cd /cluster/data/mm5/jkStuff
    # create generic copy program
    cat << '_EOF_' > cpToWeb.sh
#!/bin/sh
if [ $# -ne 1 ]; then
	echo "usage: cpToWeb.sh <goldenPath download directory>"
	echo -e "\texample: cpToWeb.sh mm5"
	exit 255
fi
GP=/usr/local/apache/htdocs/goldenPath/$1
mkdir -p ${GP}
mkdir -p ${GP}/chromosomes
for f in ../?/*.fa ../??/*.fa
do
    BN=`basename ${f}`
    zip -j ${GP}/chromosomes/${BN}.zip ${f}
    echo "zipped: ${BN}"
done
mkdir -p ${GP}/bigZips
for Z in *.zip
do
	cp -p ${Z} ${GP}/bigZips
	echo "copied: ${Z}"
done
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod +x cpToWeb.sh
    cd /cluster/data/mm5/zip
    ../jkStuff/cpToWeb.sh mm5
    cd /usr/local/apache/htdocs/goldenPath/mm5
    # Take a look at bigZips/* and chromosomes/*, update their README.txt's

    # Make the upstream sequence files.
    # NOTE: must be redone due to bad gap track
    cd bigZips
    featureBits mm5 refGene:upstream:1000 -fa=upstream1000.fa
    zip upstream1000.zip upstream1000.fa
    rm upstream1000.fa
    featureBits mm5 refGene:upstream:2000 -fa=upstream2000.fa
    zip upstream2000.zip upstream2000.fa
    rm upstream2000.fa
    featureBits mm5 refGene:upstream:5000 -fa=upstream5000.fa
    zip upstream5000.zip upstream5000.fa
    rm upstream5000.fa
    # mrna zips -- auto dump process takes care of this


# MAKE LINEAGE-SPECIFIC REPEATS FOR CHICKEN (DONE 7/15/04 angie)
    # In an email 2/13/04, Arian said we could treat all human repeats as 
    # lineage-specific for human-chicken blastz.  Do the same for mouse.  
    # Scripts expect *.out.spec filenames, so set that up:
    ssh kkr1u00
    cd /cluster/data/mm5
    mkdir /iscratch/i/mus/mm5/linSpecRep.notInChicken
    foreach f (/iscratch/i/mus/mm5/rmsk/chr*.fa.out)
      cp -p $f /iscratch/i/mus/mm5/linSpecRep.notInChicken/$f:t:r:r.out.spec
    end
    iSync
    # Use these the next time we run human-chicken blastz.


# BLASTZ CHICKEN (GALGAL2) (DONE 7/19/04 angie)
    ssh kk
    mkdir /cluster/data/mm5/bed/blastz.galGal2.2004-07-15
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15
    # Use human-chicken params: set L=10000 (higher threshold on blastz's 
    # outer loop) and abridge repeats.
    cat << '_EOF_' > DEF
# mouse vs. chicken
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz

# Specific settings for chicken (per Webb email to Brian Raney)
BLASTZ_H=2000
BLASTZ_Y=3400
BLASTZ_L=10000
BLASTZ_K=2200
BLASTZ_Q=/cluster/data/blastz/HoxD55.q
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Mouse
SEQ1_DIR=/scratch/mus/mm5/softNib
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/mus/mm5/linSpecRep.notInChicken
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Chicken
SEQ2_DIR=/iscratch/i/galGal2/nib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=/iscratch/i/galGal2/linSpecRep
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/mm5/bed/blastz.galGal2.2004-07-15

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    # first cluster run: raw blastz alignments
    ssh kk
    bash # if a csh/tcsh user
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15
    source DEF
    mkdir $RAW run.0
    /cluster/home/angie/hummus/make-joblist $DEF > $BASE/run.0/j
    sh ./xdir.sh
    cd run.0
    sed -e 's@^blastz-run@/cluster/bin/penn/blastz-run@' j > jobList
    para create jobList
    para try, check, push, check, ....
#Completed: 51491 of 51491 jobs
#Average job time:                 357s       5.95m     0.10h    0.00d
#Longest job:                     1015s      16.92m     0.28h    0.01d
#Submission to last job:         89841s    1497.35m    24.96h    1.04d

    # second cluster run: lift raw alignments -> lav dir
    ssh kki
    bash # if a csh/tcsh user
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15
    source DEF
    mkdir run.1 lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > $BASE/run.1/jobList
    cd run.1
    wc -l jobList
    para create jobList
    para try, check, push, etc ...
#Completed: 341 of 341 jobs
#Average job time:                  11s       0.18m     0.00h    0.00d
#Longest job:                       55s       0.92m     0.02h    0.00d
#Submission to last job:           245s       4.08m     0.07h    0.00d

    # third run: lav -> axt
    # NOTE: use axtRescore here because we used a non-default BLASTZ_Q matrix 
    # and abridged repeats (Penn State's restore_rpts program rescores with 
    # default matrix, oops).
    ssh kki
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15
    mkdir axtChrom pslChrom run.2
    cd run.2
    cat << '_EOF_' > do.csh
#!/bin/csh -ef
cd $1
set chr = $1:t
set path = (/cluster/bin/x86_64 $path)
cat `ls -1 *.lav | sort -g` \
| lavToAxt stdin \
    /iscratch/i/mus/mm5/softNib /iscratch/i/galGal2/nib stdout \
| axtRescore -scoreScheme=/cluster/data/blastz/HoxD55.q stdin stdout \
| axtSort stdin ../../axtChrom/$chr.axt 
axtToPsl ../../axtChrom/$chr.axt ../../S1.len ../../S2.len \
  ../../pslChrom/$chr.psl
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    foreach d (../lav/chr*)
      echo "do.csh $d" >> jobList
    end
    para create jobList
    para try, check, push, check
#Completed: 43 of 43 jobs
#Average job time:                  38s       0.63m     0.01h    0.00d
#Longest job:                      160s       2.67m     0.04h    0.00d
#Submission to last job:           233s       3.88m     0.06h    0.00d


# CHAIN CHICKEN BLASTZ (DONE 7/19/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chain
    ls -1S /cluster/data/mm5/bed/blastz.galGal2.2004-07-15/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in exists $(path1)} {check out line+ chain/$(root1).chain} {check out line+ out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain -scoreScheme=/cluster/data/blastz/HoxD55.q \
         -linearGap=/cluster/data/blastz/chickenHumanTuned.gap \
         -minScore=5000 $1 \
    /iscratch/i/mus/mm5/softNib \
    /iscratch/i/galGal2/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 43 of 43 jobs
#Average job time:                  60s       1.00m     0.02h    0.00d
#Longest job:                      355s       5.92m     0.10h    0.00d
#Submission to last job:           355s       5.92m     0.10h    0.00d

    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=5000 /tmp/score.$f:t:r
      echo ""
    end

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        echo loading $c
        hgLoadChain mm5 ${c}_chainGalGal2 $i
    end
    featureBits mm5 chainGalGal2Link
#78951466 bases of 2615483787 (3.019%) in intersection
    featureBits hg17 chainGalGal2Link
#103882699 bases of 2866216770 (3.624%) in intersection


# NET CHICKEN BLASTZ (DONE 7/19/04 angie)
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15/axtChain
    netClass -noAr noClass.net mm5 galGal2 chicken.net

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15/axtChain
    rm noClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn chicken.net > chickenSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15/axtChain
    netFilter -minGap=10 chicken.net |  hgLoadNet mm5 netGalGal2 stdin
    netFilter -minGap=10 chickenSyn.net | hgLoadNet mm5 syntenyNetGalGal2 stdin
    # Add entries for chainGalGal2, netGalGal2, syntenyNetGalGal2 to 
    # mouse/mm5 trackDb


# GENERATE GALGAL2 MAF FOR MULTIZ FROM NET (DONE 7/19/04 angie)
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15/axtChain
    netSplit chicken.net net
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15
    mkdir axtNet
    foreach f (axtChain/net/*)
      set chr = $f:t:r
      netToAxt $f axtChain/chain/$chr.chain /cluster/data/mm5/mixedNib \
        /cluster/data/galGal2/nib stdout \
      | axtSort stdin axtNet/$chr.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.mg.maf
      axtToMaf $f \
            /cluster/data/mm5/chrom.sizes /cluster/data/galGal2/chrom.sizes \
            $maf -tPrefix=mm5. -qPrefix=galGal2.
    end


# MAKE VSGALGAL2 DOWNLOADABLES (DONE 7/19/04 angie)
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15
    gzip axtNet/*.axt
    cd /cluster/data/mm5/bed/blastz.galGal2.2004-07-15/axtChain
    ln all.chain chicken.chain
    zip /cluster/data/mm5/zip/chicken.chain.zip chicken.chain
    rm chicken.chain
    zip /cluster/data/mm5/zip/chicken.net.zip chicken.net
    zip /cluster/data/mm5/zip/chickenSyn.net.zip chickenSyn.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/mm5/vsGalGal2
    cd /usr/local/apache/htdocs/goldenPath/mm5/vsGalGal2
    mv /cluster/data/mm5/zip/chicken*.zip .
    cp -pR /cluster/data/mm5/bed/blastz.galGal2.2004-07-15/axtNet .
    md5sum *.zip axtNet/* > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# EXTRACT LINEAGE-SPECIFIC REPEATS FOR DOG (DONE 7/15/04 angie)
    ssh kkr1u00
    cd /cluster/bluearc/scratch/mus/mm5/rmsk
    # Run Arian's DateRepsinRMoutput.pl to add extra columns telling 
    # whether repeats in -query are also expected in -comp species.  
    # Even though we already have the mouse-human linSpecReps,
    # extractLinSpecReps requires two columns of DateRepsinRMoutput.pl
    # additions.  So add human, then ignore it.  
    # Dog in extra column 1, Human in extra column 2
    foreach outfl ( *.out )
        echo "$outfl"
        /cluster/bluearc/RepeatMasker/DateRepsinRMoutput.pl \
          ${outfl} -query mouse -comp dog -comp human
    end
    # Now extract dog (extra column 1), ignore human.
    cd /iscratch/i/mus/mm5
    mkdir linSpecRep.notInDog
    foreach f (/cluster/bluearc/scratch/mus/mm5/rmsk/*.out_dog_hum)
        set base = $f:t:r:r
        echo $base.out.spec
        /cluster/bin/scripts/extractLinSpecReps 1 $f > \
                        linSpecRep.notInDog/$base.out.spec
    end
    # Clean up.
    rm /cluster/bluearc/scratch/mus/mm5/rmsk/*.out_dog_hum
    iSync


# BLASTZ DOG (CANFAM1) (DONE 7/16/04 angie)
    ssh kk
    mkdir /cluster/data/mm5/bed/blastz.canFam1.2004-07-15
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15
    # Use default (Human-Mouse) settings for starters.
    cat << '_EOF_' > DEF
# mouse vs. dog
export PATH=/usr/bin:/bin:/usr/local/bin:/cluster/bin/penn:/cluster/bin/i386:/cluster/home/angie/schwartzbin

ALIGN=blastz-run
BLASTZ=blastz

# Default
BLASTZ_H=2000
BLASTZ_ABRIDGE_REPEATS=1

# TARGET: Mouse
SEQ1_DIR=/scratch/mus/mm5/softNib
SEQ1_RMSK=
SEQ1_FLAG=
SEQ1_SMSK=/iscratch/i/mus/mm5/linSpecRep.notInDog
SEQ1_IN_CONTIGS=0
SEQ1_CHUNK=10000000
SEQ1_LAP=10000

# QUERY: Dog
SEQ2_DIR=/scratch/hg/canFam1/nib
SEQ2_RMSK=
SEQ2_FLAG=
SEQ2_SMSK=/scratch/hg/canFam1/linSpecRep.notInMouse
SEQ2_IN_CONTIGS=0
SEQ2_CHUNK=10000000
SEQ2_LAP=0

BASE=/cluster/data/mm5/bed/blastz.canFam1.2004-07-15

DEF=$BASE/DEF
RAW=$BASE/raw
CDBDIR=$BASE
SEQ1_LEN=$BASE/S1.len
SEQ2_LEN=$BASE/S2.len
'_EOF_'
    # << this line keeps emacs coloring happy

    # first cluster run: raw blastz alignments
    ssh kk
    bash # if a csh/tcsh user
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15
    source DEF
    mkdir $RAW run.0
    /cluster/home/angie/hummus/make-joblist $DEF > $BASE/run.0/j
    sh ./xdir.sh
    cd run.0
    sed -e 's@^blastz-run@/cluster/bin/penn/blastz-run@' j > jobList
    para create jobList
    para try, check, push, check, ....
    # cluster was mobbed...
#Completed: 93775 of 93775 jobs
#Average job time:                 187s       3.11m     0.05h    0.00d
#Longest job:                     3907s      65.12m     1.09h    0.05d
#Submission to last job:         76763s    1279.38m    21.32h    0.89d

    # second cluster run: lift raw alignments -> lav dir
    ssh kki
    bash # if a csh/tcsh user
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15
    source DEF
    mkdir run.1 lav
    /cluster/bin/scripts/blastz-make-out2lav $DEF $BASE > $BASE/run.1/jobList
    cd run.1
    wc -l jobList
    para create jobList
    para try, check, push, etc ...
#Completed: 341 of 341 jobs
#Average job time:                  98s       1.63m     0.03h    0.00d
#Longest job:                      281s       4.68m     0.08h    0.00d
#Submission to last job:          2102s      35.03m     0.58h    0.02d

    # third run: lav -> axt
    # (if non-default BLASTZ_Q is used in the future, put axtRescore in 
    # the pipe after lavToAxt)
    ssh kki
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15
    mkdir axtChrom pslChrom run.2
    cd run.2
    cat << '_EOF_' > do.csh
#!/bin/csh -ef
cd $1
set chr = $1:t
cat `ls -1 *.lav | sort -g` \
| $HOME/bin/x86_64/lavToAxt stdin \
    /iscratch/i/mus/mm5/softNib /iscratch/i/canFam1/nib stdout \
| $HOME/bin/x86_64/axtSort stdin ../../axtChrom/$chr.axt 
$HOME/bin/x86_64/axtToPsl ../../axtChrom/$chr.axt ../../S1.len ../../S2.len \
  ../../pslChrom/$chr.psl
'_EOF_'
    # << this line keeps emacs coloring happy
    chmod a+x do.csh
    cp /dev/null jobList
    foreach d (../lav/chr*)
      echo "do.csh $d" >> jobList
    end
    para create jobList
    para try, check, push, check
#Completed: 43 of 43 jobs
#Average job time:                 671s      11.18m     0.19h    0.01d
#Longest job:                     2398s      39.97m     0.67h    0.03d
#Submission to last job:          2417s      40.28m     0.67h    0.03d


# CHAIN DOG BLASTZ (DONE 7/16/04 angie)
    # Run axtChain on little cluster
    ssh kki
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15
    mkdir -p axtChain/run1
    cd axtChain/run1
    mkdir out chainchimpSuperQuals
    ls -1S /cluster/data/mm5/bed/blastz.canFam1.2004-07-15/axtChrom/*.axt \
      > input.lst
    cat << '_EOF_' > gsub
#LOOP
doChain {check in line+ $(path1)} {check out line+ chain/$(root1).chain} {check out exists out/$(root1).out}
#ENDLOOP
'_EOF_'
    # << this line makes emacs coloring happy

    cat << '_EOF_' > doChain
#!/bin/csh
axtChain $1 \
    /iscratch/i/mus/mm5/softNib \
    /iscratch/i/canFam1/nib $2 > $3
'_EOF_'
    # << this line makes emacs coloring happy
    chmod a+x doChain
    gensub2 input.lst single gsub jobList
    para create jobList
    para try, check, push, check...
#Completed: 43 of 43 jobs
#Average job time:                 537s       8.96m     0.15h    0.01d
#Longest job:                     2071s      34.52m     0.58h    0.02d
#Submission to last job:          2071s      34.52m     0.58h    0.02d
    # now on the cluster server, sort chains
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15/axtChain
    chainMergeSort run1/chain/*.chain > all.chain
    chainSplit chain all.chain
    rm run1/chain/*.chain

    # take a look at score distr's
    foreach f (chain/*.chain)
      grep chain $f | awk '{print $2;}' | sort -nr > /tmp/score.$f:t:r
      echo $f:t:r
      textHistogram -binSize=5000 /tmp/score.$f:t:r
      echo ""
    end

    # Lots of chaff with scores in the 3000's.  Many very-high-scoring 
    # chains.  So filter the chain down somewhat...
    mv all.chain all.chain.unfiltered
    chainFilter -minScore=5000 all.chain.unfiltered > all.chain
    rm chain/*
    chainSplit chain all.chain
    gzip all.chain.unfiltered

    # Load chains into database
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15/axtChain/chain
    foreach i (*.chain)
        set c = $i:r
        hgLoadChain mm5 ${c}_chainCanFam1 $i
    end
    # mouse-dog gets significantly less coverage than human-dog:
    featureBits mm5 -chrom=chr1 chainCanFam1Link
#63386139 bases of 185739816 (34.126%) in intersection
    featureBits hg17 -chrom=chr1 chainCanFam1Link
#123999291 bases of 222827847 (55.648%) in intersection
    # mouse-dog isn't a whole lot less than mouse-human though:
    featureBits mm5 -chrom=chr1 chainHg17Link
#75492250 bases of 185739816 (40.644%) in intersection


# NET DOG BLASTZ (DONE 7/16/04 angie)
    ssh kolossus
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15/axtChain
    chainPreNet all.chain ../S1.len ../S2.len stdout \
    | chainNet stdin -minSpace=1 ../S1.len ../S2.len stdout /dev/null \
    | netSyntenic stdin noClass.net

    # Add classification info using db tables:
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15/axtChain
    netClass -noAr noClass.net mm5 canFam1 dog.net

    # Make a 'syntenic' subset:
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15/axtChain
    rm noClass.net
    # Make a 'syntenic' subset of these with
    netFilter -syn dog.net > dogSyn.net

    # Load the nets into database 
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15/axtChain
    netFilter -minGap=10 dog.net |  hgLoadNet mm5 netCanFam1 stdin
    netFilter -minGap=10 dogSyn.net | hgLoadNet mm5 syntenyNetCanFam1 stdin
    # Add entries for chainCanFam1, netCanFam1 to mouse/mm5 trackDb


# MAKE VSCANFAM1 DOWNLOADABLES (DONE 7/19/04 angie)
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15
    gzip axtNet/chr*.axt
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15/axtChain
    ln all.chain dog.chain
    zip /cluster/data/mm5/zip/dog.chain.zip dog.chain
    rm dog.chain
    zip /cluster/data/mm5/zip/dog.net.zip dog.net
    zip /cluster/data/mm5/zip/dogSyn.net.zip dogSyn.net

    ssh hgwdev
    mkdir /usr/local/apache/htdocs/goldenPath/mm5/vsCanFam1
    cd /usr/local/apache/htdocs/goldenPath/mm5/vsCanFam1
    mv /cluster/data/mm5/zip/dog*.zip .
    cp -pR /cluster/data/mm5/bed/blastz.canFam1.2004-07-15/axtNet .
    md5sum *.zip axtNet/* > md5sum.txt
    # Copy over & edit README.txt w/pointers to chain, net formats.


# GENERATE CANFAM1 MAF FOR MULTIZ FROM NET (DONE 7/19/04 angie)
    ssh kksilo
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15/axtChain
    netSplit dog.net net
    cd /cluster/data/mm5/bed/blastz.canFam1.2004-07-15
    mkdir axtNet
    foreach f (axtChain/net/*)
      set chr = $f:t:r
      netToAxt $f axtChain/chain/$chr.chain /cluster/data/mm5/nib \
        /cluster/data/canFam1/nib stdout \
      | axtSort stdin axtNet/$chr.axt
    end
    mkdir mafNet
    foreach f (axtNet/chr*.axt)
      set maf = mafNet/$f:t:r.mc.maf
      axtToMaf $f \
            /cluster/data/mm5/chrom.sizes /cluster/data/canFam1/chrom.sizes \
            $maf -tPrefix=mm5. -qPrefix=canFam1.
    end


### MAKE THE affyU74 TRACK - needed for the Gene Sorter 
#                              (DONE - 2004-07-16 - Fan)
# MAKE THE affyU74 TRACK using Affy consensus sequences instead of 
# target sequences. Recalculate alignments and load data
----------------------------------
# Load up semi-local disk with target sequences for Affy mouse U74 chips.
ssh kkr1u00
mkdir -p /iscratch/i/affy
#	This /projects filesystem is not available on kkr1u00
#	but it is on kk
ssh kk
cp /projects/compbio/data/microarray/affyGnfMouse/sequences/U74*consensus.fa /iscratch/i/affy

ssh kkr1u00
iSync

# Run cluster job to do alignments
ssh kk
mkdir /cluster/data/mm5/bed/affyU74.2004-07-16
cd /cluster/data/mm5/bed/affyU74.2004-07-16
mkdir run
cd run
mkdir psl
echo /scratch/mus/mm5/maskedContigs/*.fa | wordLine stdin > genome.lst
ls -1 /iscratch/i/affy/U74*consensus.fa > affy.lst
cat << '_EOF_' > gsub
#LOOP
/cluster/bin/i386/blat -fine -mask=lower -minIdentity=95 -ooc=/scratch/hg/h/11.ooc  {check in line+ $(path1)} {check in line+ $(path2)} {check out line+ psl/$(root1)_$(root2).psl}
#ENDLOOP
'_EOF_'
# << this line makes emacs coloring happy

gensub2 genome.lst affy.lst gsub jobList
para create jobList
para try
# do usual para check/para push etc. until the job is done. 

# Completed: 1917 of 1917 jobs
# CPU time in finished jobs:      14240s     237.34m     3.96h    0.16d  0.000 y
# IO & Wait Time:                  7946s     132.43m     2.21h    0.09d  0.000 y
# Average job time:                  12s       0.19m     0.00h    0.00d
# Longest job:                       40s       0.67m     0.01h    0.00d
# Submission to last job:           307s       5.12m     0.09h    0.00d

# Do sort, best in genome filter, and convert to chromosome coordinates
# to create affyU74.psl.
ssh kksilo
cd /cluster/data/mm5/bed/affyU74.2004-07-16/run
pslSort dirs raw.psl tmp psl

# change filter parameters for these sequences. only use alignments that
# cover 30% of sequence and have at least minAli = 0.95.
# minAli = 0.97 too high. low minCover as a lot of n's in these sequences
pslReps -minCover=0.3 -sizeMatters -minAli=0.95 -nearTop=0.005 raw.psl contig.psl /dev/null

# Processed 44630 alignments
liftUp ../all_affyU74.psl ../../../jkStuff/liftAll.lft warn contig.psl

# Sort by chromosome and load into database.
ssh hgwdev
cd /cluster/data/mm5/bed/affyU74.2004-07-16
pslSortAcc nohead chrom temp all_affyU74.psl
cat chrom/*.psl > affyU74.psl
# shorten qName to "xxxx_at" instead of "U74Xv2:xxxx_at;"
# and reload data into table
hgLoadPsl mm5 affyU74.psl -tNameIx
rm -fr chrom temp run

##   MAKE THE affyGnfU74 TRACKs (DONE - 2004-07-18 - Fan)
# Make bed files and load consensus sequences for Affy U74 chip set.
----------------------------------
#This needs to be done after affyU74 is already made.
ssh hgwdev
mkdir -p /cluster/data/mm5/bed/affyGnf.2004-07-16
cd /cluster/data/mm5/bed/affyGnf.2004-07-16
#	may need to build this command in src/hg/affyGnf
affyPslAndAtlasToBed ../affyU74.2004-07-16/affyU74.psl \
	/projects/compbio/data/microarray/affyGnfMouse/data/data_public_U74 \
	affyGnfU74A.bed affyGnfU74A.exp -newType -chip=U74Av2
affyPslAndAtlasToBed ../affyU74.2004-07-16/affyU74.psl \
	/projects/compbio/data/microarray/affyGnfMouse/data/U74B_b.txt \
	affyGnfU74B.bed affyGnfU74B.exp -newType -chip=U74Bv2
affyPslAndAtlasToBed ../affyU74.2004-07-16/affyU74.psl \
	/projects/compbio/data/microarray/affyGnfMouse/data/U74C_b.txt \
	affyGnfU74C.bed affyGnfU74C.exp -newType -chip=U74Cv2

# edit 3 .bed files to shorten qName to "xxxx_at" instead of "U74Xv2:xxxx_at;"

# and reload data into table
hgLoadBed mm5 affyGnfU74A affyGnfU74A.bed
hgLoadBed mm5 affyGnfU74B affyGnfU74B.bed
hgLoadBed mm5 affyGnfU74C affyGnfU74C.bed

# Add in sequence data for U74 tracks.
# Copy consensus sequence to /gbdb if it isn't already
# [THE SYM LINKS WERE ALREADY DONE.]
    mkdir -p /gbdb/hgFixed/affyProbes
    cd /gbdb/hgFixed/affyProbes
    ln -s /projects/compbiodata/microarray/affyGnfMouse/sequences/U74Av2_consensus.fa .
    ln -s /projects/compbiodata/microarray/affyGnfMouse/sequences/U74Bv2_consensus.fa .
    ln -s /projects/compbiodata/microarray/affyGnfMouse/sequences/U74Cv2_consensus.fa .
    
    # used perl -pi.bak -e 's/;/ /' <file> to remove ";" after probe name
    # ASSUMED THIS IS ALREADY DONE LAST TIME FOR MM4.
    # reload sequences with prefix removed so acc matches name used in
    # other dependent tables
                                                    
    hgLoadSeq -abbr=U74Av2: mm5 /gbdb/hgFixed/affyProbes/U74Av2_consensus.fa
    hgLoadSeq -abbr=U74Bv2: mm5 /gbdb/hgFixed/affyProbes/U74Bv2_consensus.fa
    hgLoadSeq -abbr=U74Cv2: mm5 /gbdb/hgFixed/affyProbes/U74Cv2_consensus.fa

### GNF ATLAS 2  [DONE Fan 7/18/2004]
    # Align probes from GNF1M chip.
    ssh kk
    cd /cluster/data/mm5/bed
    mkdir -p geneAtlas2/run/psl
    cd geneAtlas2/run
    mkdir -p /cluster/bluearc/geneAtlas2
    cp /projects/compbio/data/microarray/geneAtlas2/mouse/gnf1m.fa /cluster/bluearc/geneAtlas2
    ls -1 /scratch/mus/mm5/maskedContigs/ > genome.lst
    ls -1 /cluster/bluearc/geneAtlas2/gnf1m.fa > mrna.lst
    echo '#LOOP\nblat -fine -ooc=/scratch/hg/h/mouse11.ooc  /scratch/mus/mm5/maskedContigs/$(path1) $(path2) {check out line+ psl/$(root1)_$(root2).psl}\n#ENDLOOP' > gsub
    gensub2 genome.lst mrna.lst gsub spec
    para create spec
    para try
    para check
    para push
    para time
# Completed: 639 of 639 jobs
# CPU time in finished jobs:      58174s     969.57m    16.16h    0.67d  0.002 y
# IO & Wait Time:                  4833s      80.55m     1.34h    0.06d  0.000 y
# Average job time:                  99s       1.64m     0.03h    0.00d
# Longest job:                      189s       3.15m     0.05h    0.00d
# Submission to last job:          1749s      29.15m     0.49h    0.02d
    # Do sort, best in genome filter, and convert to chromosome coordinates
    # to create gnf1h.psl.
    pslSort dirs raw.psl tmp psl
    pslReps -minCover=0.3 -minAli=0.95 -nearTop=0.005 raw.psl contig.psl /dev/null
    liftUp ../affyGnf1m.psl ../../../jkStuff/liftAll.lft warn contig.psl
    rm -r contig.psl raw.psl psl

    # Load probes and alignments from GNF1H into database.
    ssh hgwdev
    cd /cluster/data/mm5/bed/geneAtlas2
    ln -s /projects/compbio/data/microarray/geneAtlas2/mouse/gnf1m.fa /gbdb/hgFixed/affyProbes
    hgLoadPsl mm5 affyGnf1m.psl
    hgLoadSeq mm5 /gbdb/hgFixed/affyProbes/gnf1m.fa

    # Load up track
    hgMapMicroarray gnfAtlas2.bed hgFixed.gnfMouseAtlas2MedianRatio \
    	affyGnf1m.psl
    # Note that the unmapped 5000 records are from all-N sequences.
    hgLoadBed mm5 gnfAtlas2 gnfAtlas2.bed

# MOUSE AFFYMETRIX MOE430 TRACK (DONE, 2004-07-19, Fan)
    mkdir -p /projects/compbio/data/microarray/affyMouse
    # Download MOE430A and MOE430B consensus sequences from Affymetrix web site
    # http://www.affymetrix.com/support/technical/byproduct.affx?product=moe430
    unzip MOE430*_consensus.zip

    # check for duplicate probes: there are none, all have unique names
    # check for duplicate probes: 100 from 136745_at to 1367551_a_at
    # remove "consensus:" and ";" from FASTA headers to shorten probeset
    # names for database

    sed -e 's/consensus://' MOE430A_consensus | sed -e 's/;/ /' > MOE430_all.fa
    sed -e 's/consensus://' MOE430B_consensus | sed -e 's/;/ /' >> MOE430_all.fa
 
    cp /projects/compbio/data/microarray/affyMouse/MOE430_all.fa \
       /cluster/bluearc/affy/

    # THE ABOVE WAS ALREADY DONE BY RACHEL 4/16/04.

    # Set up cluster job to align MOE430 consensus sequences to mm5
    ssh kkr1u00
    cd /cluster/data/mm5/bed
    mkdir -p affyMOE430
    cd affyMOE430
    mkdir -p /iscratch/i/affy
    cp /cluster/bluearc/affy/MOE430_all.fa /iscratch/i/affy
    iSync

    ssh kk
    cd /cluster/data/mm5/bed/affyMOE430
    ls -1 /iscratch/i/affy/MOE430_all.fa > affy.lst
    ls -1 /scratch/mus/mm5/maskedContigs/ > allctg.lst

    echo '#LOOP\n/cluster/bin/i386/blat -fine -mask=lower -minIdentity=95 -
ooc=/scratch/hg/h/mouse11.ooc  /scratch/mus/mm5/maskedContigs/$(path1) $(path2) 
{check out line+ psl/$(root1)_$(root2).psl}\n#ENDLOOP' > template.sub

    gensub2 allctg.lst affy.lst template.sub para.spec
    mkdir psl
    para create para.spec
    # Actually do the job with usual para try/check/push/time etc.
# para time
# Completed: 639 of 639 jobs
# CPU time in finished jobs:      24369s     406.14m     6.77h    0.28d  0.001 y
# IO & Wait Time:                  2263s      37.72m     0.63h    0.03d  0.000 y
# Average job time:                  42s       0.69m     0.01h    0.00d
# Longest job:                       63s       1.05m     0.02h    0.00d
# Submission to last job:           671s      11.18m     0.19h    0.01d


    # Do sort, best in genome filter, and convert to chromosome coordinates
    # to create affyRAE230.psl
    pslSort dirs raw.psl tmp psl

    # only use alignments that cover 30% of sequence and have at least
    # 95% identity in aligned region. 
    # low minCover as a lot of n's in these sequences
    pslReps -minCover=0.3 -sizeMatters -minAli=0.95 -nearTop=0.005 raw.psl 
contig.psl /dev/null
    liftUp affyMOE430.psl ../../jkStuff/liftAll.lft warn contig.psl

    # Load alignments and sequences into database
    ssh hgwdev
    cd /cluster/data/mm5/bed/affyMOE430
    # shorten names in psl file
    sed -e 's/MOE430//' affyMOE430.psl > affyMOE430.psl.bak
    mv affyMOE430.psl.bak affyMOE430.psl

    # load track into database

    hgLoadPsl mm5 affyMOE430.psl
    # 1 warning on loading: Blat error so that 1449824_at has a 
    # negative entry (-195) in the qBaseInsert field. 
    # Loading into the database forces this to 0.
 
    # Add consensus sequences for MOE430
    # Copy sequences to gbdb is they are not there already
    mkdir -p /gbdb/hgFixed/affyProbes
    ln -s /projects/compbio/data/microarray/affyMouse/MOE430_all.fa \ 
       /gbdb/hgFixed/affyProbes

    hgLoadSeq -abbr=MOE430 mm5 /gbdb/hgFixed/affyProbes/MOE430_all.fa
    
    # Clean up
    rm batch.bak contig.psl raw.psl 
    
    # BELOW TWO THINGS WERE DONE BY RACHEL ALREDAY FOR MM4
    # add entry to trackDb.ra in ~kent/src/hg/makeDb/trackDb/mouse/
    # add affyMOE430.html file and then do make alpha to add to trackDb table


######## MAKING GENE SORTER TABLES #######  (STARTED - 2004-07-15 - Hiram)
# These are instructions for building the
# Gene Sorter.  Don't start these until
# there is a knownGene track. and the affy tracks

# Cluster together various alt-splicing isoforms.
#	Creates the knownIsoforms and knownCanonical tables
ssh hgwdev
cd /tmp
hgClusterGenes mm5 knownGene knownIsoforms knownCanonical
#	You may need to build this binary in src/hg/near/hgClusterGenes
#	Got 24603 clusters, from 41208 genes in 43 chromosomes
#	featureBits mm5 knownCanonical
#	853516995 bases of 2615483787 (32.633%) in intersection
#	featureBits mm4 knownCanonical
#	840021165 bases of 2627444668 (31.971%) in intersection
#	featureBits mm3 knownCanonical
#	825943052 bases of 2505900260 (32.960%) in intersection
#	! ! ! Can not do featureBits on knownIsoforms

# Extract peptides from knownGenes into fasta file
# and create a blast database out of them.
ssh hgwdev
mkdir -p  /cluster/data/mm5/bed/geneSorter/blastp
cd /cluster/data/mm5/bed/geneSorter/blastp
pepPredToFa mm5 knownGenePep known.faa
#	You may need to build this binary in src/hg/near/pepPredToFa
/cluster/bluearc/blast229/formatdb -i known.faa -t known -n known

# Copy over database to bluearc scratch
mkdir /cluster/bluearc/scratch/mus/mm5/blastp
cp -p /cluster/data/mm5/bed/geneSorter/blastp/known.* \
	/cluster/bluearc/scratch/mus/mm5/blastp

# Split up fasta file into bite sized chunks for cluster
cd /cluster/data/mm5/bed/geneSorter/blastp
mkdir split
faSplit sequence known.faa 8000 split/kg

# Make parasol run directory 
ssh kk
mkdir /cluster/data/mm5/bed/geneSorter/blastp/self
cd /cluster/data/mm5/bed/geneSorter/blastp/self
mkdir run
cd run
mkdir out

# Make blast script
cat  << '_EOF_' > blastSome
#!/bin/sh
BLASTMAT=/cluster/bluearc/blast229/data /cluster/bluearc/blast229/blastall \
	-p blastp -d /cluster/bluearc/scratch/mus/mm5/blastp/known \
	-i $1 -o $2 -e 0.01 -m 8 -b 1000
'_EOF_'
    # << keep emacs happy
chmod a+x blastSome

# Make gensub2 file
cat  << '_EOF_' > gsub
#LOOP
blastSome {check in line+ $(path1)} {check out line out/$(root1).tab}
#ENDLOOP
'_EOF_'
    # << keep emacs happy

# Create parasol batch
#	'ls ../../split/*.fa' is too much, hence the echo
echo ../../split/*.fa | wordLine stdin > split.lst
gensub2 split.lst single gsub jobList
para create jobList
para try
para check
para push ... etc ...
# Completed: 7739 of 7739 jobs
# CPU time in finished jobs:     120685s    2011.42m    33.52h    1.40d  0.004 y
# IO & Wait Time:                 22722s     378.69m     6.31h    0.26d  0.001 y
# Average job time:                  19s       0.31m     0.01h    0.00d
# Longest job:                      147s       2.45m     0.04h    0.00d
# Submission to last job:           705s      11.75m     0.20h    0.01d

# Load into database.  This takes about an hour.
ssh hgwdev
cd /cluster/data/mm5/bed/geneSorter/blastp/self/run/out
hgLoadBlastTab mm5 knownBlastTab *.tab
# Scanning through 7739 files
    #	Loading database with 8017562 rows
    #	real    17m9.104s
    #	user    3m8.980s
    #	sys     0m28.800s

# Create known gene mapping table and expression distance tables
# for GNF Atlas 2.  (The hgExpDistance takes an hour.)
# DONE (04-07-18 Fan)

hgMapToGene mm5 affyGnf1m knownGene knownToGnf1m
hgExpDistance mm5 hgFixed.gnfMouseAtlas2MedianRatio \
	hgFixed.gnfMouseAtlas2MedianExps gnfAtlas2Distance \
	-lookup=knownToGnf1m


# Create table that maps between known genes and RefSeq
hgMapToGene mm5 refGene knownGene knownToRefSeq
#	may need to build this command in src/hg/near/hgMapToGene

# Create a table that maps between known genes and 
# the nice affy expression data.
hgMapToGene mm5 affyU74  knownGene knownToU74
hgMapToGene mm5 affyMOE430 knownGene knownToMOE430
hgMapToGene mm5 affyMOE430 -prefix=A: knownGene knownToMOE430A

# Format and load Rinn et al sex expression data
mkdir /cluster/data/mm5/bed/rinnSex
cd !$
hgMapMicroarray rinnSex.bed hgFixed.mouseRinnSexMedianRatio \
    ../affyMOE430/affyMOE430.psl
hgLoadBed mm5 rinnSex rinnSex.bed

# Format and load the GNF data
mkdir /cluster/data/mm5/bed/affyGnf95
cd /cluster/data/mm5/bed/affyGnf95
affyPslAndAtlasToBed -newType ../affyU95.psl \
	/projects/compbio/data/microarray/affyGnfHuman/data_public_U95 \
	affyGnfU95.tab affyGnfU95Exps.tab -shortOut

#	this .sql load was in preceeding instructions, but this .sql file
#	appears to not exist and it doesn't seem to be needed anyway.
#	Everything below this seems to create tables OK.
#  hgsql mm5 < ~/kent/src/hg/affyGnf/affyGnfU95.sql

# Create table that gives distance in expression space between 
# GNF genes.  These commands take about 15 minutes each
#	The affyGnfU74?Exps arguments appear to be unused in 
hgExpDistance
hgExpDistance mm5 affyGnfU74A affyGnfU74AExps affyGnfU74ADistance \
	-lookup=knownToU74
# Got 13593 unique elements in affyGnfU74A
hgExpDistance mm5 affyGnfU74B affyGnfU74BExps affyGnfU74BDistance \
	-lookup=knownToU74
# Got 8512 unique elements in affyGnfU74B
hgExpDistance mm5 affyGnfU74C affyGnfU74CExps affyGnfU74CDistance \
	-lookup=knownToU74
# Got 2318 unique elements in affyGnfU74C


# C.ELEGANS BLASTP FOR GENE SORTER (DONE 7/20/04 Fan)
    # Make C. elegans ortholog column using blastp on wormpep.
    # First make C. elegans protein database and copy it to iscratch/i
    # if it doesn't exist already:
    ssh eieio
    mkdir /cluster/data/ce2/bed/blastp
    cd /cluster/data/ce2/bed/blastp
    # Point a web browser at ftp://ftp.sanger.ac.uk/pub/databases/wormpep/
    # to find out the latest version.  Then use that in place of 128 below.
    wget -O wormPep128.faa \
      ftp://ftp.sanger.ac.uk/pub/databases/wormpep/wormpep128/wormpep128
    formatdb -i wormPep128.faa -t wormPep128 -n wormPep128
    ssh kkr1u00
    if (-e /iscratch/i/ce2/blastp) then
      rm -r /iscratch/i/ce2/blastp
    endif
    mkdir -p /iscratch/i/ce2/blastp
    cp /cluster/data/ce2/bed/blastp/wormPep128.p?? /iscratch/i/ce2/blastp
    iSync

    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/mm5/bed/blastp/ce2/run/out
    cd /cluster/data/mm5/bed/blastp/ce2/run
    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/ce2/blastp/wormPep128 -i \$1 
-o \$2 -e 0.01 -m 8 -b 1
end
    chmod a+x blastSome
    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end
    # Create parasol batch
    ls 1S /cluster/store6/mm5/bed/geneSorter/blastp/split >split.lst
    #ls -1S ../../split/*.fa > split.lst
    #EDIT split.lst to add "../../../geneSorter/blastp/split/" in front of "kg"
    gensub2 split.lst single gsub spec
    para create spec
    para try, check, push, check, ...
# Completed: 7739 of 7739 jobs
# CPU time in finished jobs:      54871s     914.51m    15.24h    0.64d  0.002 y
# IO & Wait Time:                 26157s     435.95m     7.27h    0.30d  0.001 y
# Average job time:                  10s       0.17m     0.00h    0.00d
# Longest job:                       41s       0.68m     0.01h    0.00d
# Submission to last job:           210s       3.50m     0.06h    0.00d

    # Load into database.  
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastp/ce2/run/out
    hgLoadBlastTab mm5 ceBlastTab -maxPer=1 *.tab

# HUMAN BLASTP FOR GENE SORTER (DONE 7/20/04 Fan)
    # Make human ortholog column using blastp on human known genes.
    # First make human protein database and copy it to iscratch/i
    # if it doesn't exist already:
    mkdir /cluster/data/hg17/bed/blastp
    cd /cluster/data/hg17/bed/blastp
    pepPredToFa hg17 knownGenePep known.faa
    formatdb -i known.faa -t known -n known
    ssh kkr1u00
    if (-e /iscratch/i/hg17/blastp) then
      rm -r /iscratch/i/hg17/blastp
    endif
    mkdir -p /iscratch/i/hg17/blastp
    cp /cluster/data/hg17/bed/blastp/known.p?? /iscratch/i/hg17/blastp
    iSync
    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/mm5/bed/blastp/hg17/run/out
    cd /cluster/data/mm5/bed/blastp/hg17/run
    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/hg17/blastp/known -i \$1 -o 
\$2 -e 0.001 -m 8 -b 1
end
    chmod a+x blastSome
    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end
    # Create parasol batch
    ls 1S /cluster/store6/mm5/bed/geneSorter/blastp/split >split.lst
    #EDIT split.lst to add "../../../geneSorter/blastp/split/" in front of "kg"
    gensub2 split.lst single gsub spec
    para create spec
    para try, check, push, check, ...

# Completed: 7739 of 7739 jobs
# CPU time in finished jobs:     125830s    2097.17m    34.95h    1.46d  0.004 y
# IO & Wait Time:                 22740s     379.00m     6.32h    0.26d  0.001 y
# Average job time:                  19s       0.32m     0.01h    0.00d
# Longest job:                      137s       2.28m     0.04h    0.00d
# Submission to last job:           301s       5.02m     0.08h    0.00d

    # Load into database.  
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastp/hg17/run/out
    hgLoadBlastTab mm5 hgBlastTab -maxPer=1 *.tab


# ZEBRAFISH BLASTP FOR GENE SORTER (DONE 7/20/04 Fan)
    # Make Danio rerio (zebrafish) ortholog column using blastp on Ensembl.
    # First make protein database and copy it to iscratch/i
    # if it doesn't exist already:
    ssh kkstore
    mkdir /cluster/data/danRer1/bed/blastp
    cd /cluster/data/danRer1/bed/blastp
    wget 
ftp://ftp.ensembl.org/pub/current_zebrafish/data/fasta/pep/Danio_rerio.ZFISH3.ma
y.pep.fa.gz 
    zcat Dan*.pep.fa.gz > ensembl.faa
    formatdb -i ensembl.faa -t ensembl -n ensembl
    ssh kkr1u00
    if (-e /iscratch/i/danRer1/blastp) then
      rm -r /iscratch/i/danRer1/blastp
    endif
    mkdir -p /iscratch/i/danRer1/blastp
    cp /cluster/data/danRer1/bed/blastp/ensembl.p?? /iscratch/i/danRer1/blastp
    iSync
    # THE ABOVE IS ALREADY DONE BY ANGIE

    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/mm5/bed/blastp/danRer1/run/out
    cd /cluster/data/mm5/bed/blastp/danRer1/run
    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/danRer1/blastp/ensembl -i 
\$1 -o \$2 -e 0.005 -m 8 -b 1
end
    chmod a+x blastSome
    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end
    # Create parasol batch
    ls 1S /cluster/store6/mm5/bed/geneSorter/blastp/split >split.lst
    #EDIT split.lst to add "../../../geneSorter/blastp/split/" in front of "kg"
    gensub2 split.lst single gsub spec
    para create spec
    para try, check, push, check, ...
# Completed: 7739 of 7739 jobs
# CPU time in finished jobs:      96773s    1612.89m    26.88h    1.12d  0.003 y
# IO & Wait Time:                 29356s     489.26m     8.15h    0.34d  0.001 y
# Average job time:                  16s       0.27m     0.00h    0.00d
# Longest job:                       73s       1.22m     0.02h    0.00d
# Submission to last job:           282s       4.70m     0.08h    0.00d

    # Load into database.  
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastp/danRer1/run/out
    hgLoadBlastTab mm5 drBlastTab -maxPer=1 *.tab


# YEAST BLASTP FOR GENE SORTER (DONE 7/20/04 Fan)
    # Make Saccharomyces cerevisiae (yeast) ortholog column using blastp on 
    # RefSeq.  First make protein database and copy it to iscratch/i
    # if it doesn't exist already:
    mkdir /cluster/data/sacCer1/bed/blastp
    cd /cluster/data/sacCer1/bed/blastp
    wget ftp://genome-
ftp.stanford.edu/pub/yeast/data_download/sequence/genomic_sequence/orf_protein/o
rf_trans.fasta.gz
    zcat orf_trans.fasta.gz > sgdPep.faa
    formatdb -i sgdPep.faa -t sgdPep -n sgdPep
    #ABOVE WAS ALREDY DONE BY JIM

    ssh kkr1u00
    # Note: sacCer1 is a name conflict with SARS coronavirus... oh well, 
    # fortunately we won't be looking for homologs there.  :)
    if (-e /iscratch/i/sacCer1/blastp) then
      rm -r /iscratch/i/sacCer1/blastp
    endif
    mkdir -p /iscratch/i/sacCer1/blastp
    cp /cluster/data/sacCer1/bed/blastp/sgdPep.p?? /iscratch/i/sacCer1/blastp
    iSync

    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/mm5/bed/blastp/sacCer1/run/out
    cd /cluster/data/mm5/bed/blastp/sacCer1/run
    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/sacCer1/blastp/sgdPep -i \$1 
-o \$2 -e 0.01 -m 8 -b 1
end
    chmod a+x blastSome
    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end
    # Create parasol batch
    ls 1S /cluster/store6/mm5/bed/geneSorter/blastp/split >split.lst
    #EDIT split.lst to add "../../../geneSorter/blastp/split/" in front of "kg"
    gensub2 split.lst single gsub spec
    para create spec
    para try, check, push, check, ...

# Completed: 7739 of 7739 jobs
# CPU time in finished jobs:      16348s     272.46m     4.54h    0.19d  0.001 y
# IO & Wait Time:                 23063s     384.39m     6.41h    0.27d  0.001 y
# Average job time:                   5s       0.08m     0.00h    0.00d
# Longest job:                       14s       0.23m     0.00h    0.00d
# Submission to last job:           203s       3.38m     0.06h    0.00d

    # Load into database.  
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastp/sacCer1/run/out
    hgLoadBlastTab mm5 scBlastTab -maxPer=1 *.tab

# DM1 BLASTP FOR GENE SORTER (DONE 7/20/04 Fan)
    # Make Drosophila melanagaster ortholog column using blastp on FlyBase.
    # First make protein database and copy it to iscratch/i
    # if it doesn't exist already:
    # This is already done, see makeMm3.doc for procedure
    # the directory: /cluster/bluearc/dm1/blastp should have data

    ssh kkr1u00
    if (-e /iscratch/i/dm1/blastp) then
      rm -r /iscratch/i/dm1/blastp
    endif
    mkdir -p /iscratch/i/dm1/blastp
    cp /cluster/data/dm1/bed/blastp/bdgp.p?? /iscratch/i/dm1/blastp
    iSync
    # THE ABOVE IS ALREADY DONE BY ANGIE

    # Make parasol run directory 
    ssh kk
    mkdir -p /cluster/data/mm5/bed/blastp/dm1/run/out
    cd /cluster/data/mm5/bed/blastp/dm1/run
    # Make blast script
    cat > blastSome <<end
#!/bin/csh
setenv BLASTMAT /iscratch/i/blast/data
/iscratch/i/blast/blastall -p blastp -d /iscratch/i/dm1/blastp/bdgp -i \$1 -o 
\$2 -e 0.001 -m 8 -b 1
end
    chmod a+x blastSome
    # Make gensub2 file
    cat > gsub <<end
#LOOP
blastSome {check in line+ \$(path1)} {check out line out/\$(root1).tab}
#ENDLOOP
end
    # Create parasol batch
    ls 1S /cluster/store6/mm5/bed/geneSorter/blastp/split >split.lst
    #EDIT split.lst to add "../../../geneSorter/blastp/split/" in front of "kg"
    gensub2 split.lst single gsub spec
    para create spec
    para try, check, push, check, ...
# Completed: 7739 of 7739 jobs
# CPU time in finished jobs:      64033s    1067.22m    17.79h    0.74d  0.002 y
# IO & Wait Time:                 20868s     347.79m     5.80h    0.24d  0.001 y
# Average job time:                  11s       0.18m     0.00h    0.00d
# Longest job:                       45s       0.75m     0.01h    0.00d
# Submission to last job:           351s       5.85m     0.10h    0.00d
    # Load into database.  
    ssh hgwdev
    cd /cluster/data/mm5/bed/blastp/dm1/run/out
    hgLoadBlastTab mm5 dmBlastTab -maxPer=1 *.tab

# Create table that maps between known genes and LocusLink (DONE 7/20/04 Fan)
hgsql --skip-column-names -e "select mrnaAcc,locusLinkId from refLink" mm5 \
        > refToLl.txt
hgMapToGene mm5 refGene knownGene knownToLocusLink -lookup=refToLl.txt
#       row count is 30303

# ENABLE GENE SORTER FOR mm5 IN HGCENTRALTEST (DONE 7/20/04 Fan)
    echo "update dbDb set hgNearOk = 1 where name = 'mm5';" \
      | hgsql -h genome-testdb hgcentraltest


# END OF GENE SORTER STUFF
#############################################################################

