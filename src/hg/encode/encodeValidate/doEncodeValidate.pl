#!/usr/bin/env perl

# encodeValidate.pl - validate an ENCODE data submission generated by the
#                       automated submission pipeline
# Verifies that all files and metadata are present and of correct formats
# Creates a load file (load.ra) and track configuration (trackDb.ra) for the datasets
# Returns 0 if validation succeeds.

# DO NOT EDIT the /cluster/bin/scripts copy of this file -- 
# edit the CVS'ed source at:
# $Header: /projects/compbio/cvsroot/kent/src/hg/encode/encodeValidate/doEncodeValidate.pl,v 1.24 2008/06/13 01:16:52 larrym Exp $

use warnings;
use strict;

use lib "/cluster/bin/scripts";
use HgAutomate;
use File::stat;
use Getopt::Long;
use English;
use Carp qw(cluck);

use vars qw/
    $opt_configDir
    $opt_outDir
    $opt_verbose
    /;

sub usage {
    print STDERR <<END;
usage: encodeValidate.pl submission-type project-submission-dir
options:
    -verbose num        Set verbose level to num (default 1).            -
    -configDir dir      Path of configuration directory, containing
                        metadata .ra files (default: submission-dir/../config)
    -outDir dir         Path of output directory, for validation files
                        (default: submission-dir/out)
END
exit 1;
}

sub readFile
{
# Return lines from given file, with EOL chomp'ed off.
# Handles either Unix or Mac EOL characters.
# Reads whole file into memory, so should NOT be used for huge files.
    my ($file) = @_;
    my $oldEOL = $/;
    open(FILE, $file) or die "ERROR: Can't open file \'$file\'\n";
    my @lines = <FILE>;
    if(@lines == 1 && $lines[0] =~ /\r/) {
        # rewind and re-read as a Mac file - obviously, this isn't the most efficient way to do this.
        seek(FILE, 0, 0);
        $/ = "\r";
        @lines = <FILE>;
    }
    for (@lines) {
        chomp;
    }
    close(FILE);
    $/ = $oldEOL;
    return \@lines;
}

sub splitKeyVal
{
# split a line into key/value, using the FIRST tab in the line; we also trim key/value strings
    my ($str) = @_;
    my $key = undef;
    my $val = undef;
    if($str =~ /([^\t]+)\t(.+)/) {
        $key = $1;
        $val = $2;
        $key =~ s/^\s+//;
        $key =~ s/\s+$//;
        $val =~ s/^\s+//;
        $val =~ s/\s+$//;
    }
    return ($key, $val);
}

# Global constants
our $fieldConfigFile = "fields.ra";
our $vocabConfigFile = "cv.ra";
our $labsConfigFile = "labs.ra";

our $loadFile = "load.ra";
our $trackFile = "trackDb.ra";

# Global variables
our $submitPath;        # full path of data submission directory
our $configPath;        # full path of configuration directory
our $outPath;           # full path of output directory
our $pifFile;           # project information filename (most recent found in 
                                # submission dir)
our %pif;               # project information
our %tracks;            # track information
our %terms;             # controlled vocabulary

############################################################################
# Validators -- extend when adding new metadata fields

# dispatch table
our %validators = (
    File_Name => \&validateFileName,
    Part => \&validatePart,
    Dataset_Name => \&validateDatasetName,
    Assembly_REF => \&validateAssemblyREF,
    Data_Type_REF => \&validateDataTypeREF,
    Raw_Data_Acc_REF => \&validateRawDataAccREF,
    Data_Version => \&validateDataVersion,
    Cell_Line_REF => \&validateCellLineREF,
    Gene_Type_REF => \&validateGeneTypeREF,
    Antibody_REF => \&validateAntibodyREF,
    );

# standard validators (required or optional for all projects)
sub validateFileName {
    # Validate array of filenames, ordered by part
    # Check files exist and are of correct data format
    my ($files, $track) = @_;
    my @files = @{$files};
    &HgAutomate::verbose(3, "     Track: $track    Files: " . join (' ', @files) . "\n");
    for (my $i=0; $i < @files; $i++) {
        my $file = $files[$i];
        my $part = $i + 1;
        defined($file) || die "ERROR: Dataset missing part \'$part\'\n";
        -e $file || die "ERROR: File \'$file\' does not exist\n";
        -s $file || die "ERROR: File \'$file\' is empty\n";
        -r $file || die "ERROR: File \'$file\' is not readable \n";
        &checkDataFormat($tracks{$track}->{'type'}, $file);
    }
}

sub validatePart {
    my ($val) = @_;
    $val >= 0 && $val < 100 || die "ERROR: Part \'$val\' is invalid (must be 0-100)\n";
}

sub validateDatasetName {
    my ($val) = @_;
}

sub validateAssemblyREF {
    my ($val) = @_;
    $val =~ /hg1[78]/ || die "ERROR: Assembly REF \'$val\' is invalid (must be 'hg17' or 'hg18\')\n";
}

sub validateDataTypeREF {
    my ($val) = @_;
}

sub validateRawDataAccREF {
# No validation
}

sub validateDataVersion {
# No validation
}

# project-specific validators
sub validateCellLineREF {
    my ($val) = @_;
    defined($terms{'Cell Line'}{$val}) || die "ERROR: Cell line \'$val\' is not known \n";
}

sub validateGeneTypeREF {
    my ($val) = @_;
    defined($terms{'Gene Type'}{$val}) || die "ERROR: Gene type \'$val\' is not known \n";
}

sub validateAntibodyREF {
    my ($val) = @_;
    defined($terms{'Antibody'}{$val}) || die "ERROR: Antibody \'$val\' is not known \n";
}

############################################################################
# Format checkers - extend when adding new data format

# dispatch table
our %formatCheckers = (
    wig => \&validateWig,
    bed => \&validateBed,
    genePred => \&validateGene,
    mappedReads => \&validateMappedReads,
    );

sub validateWig {
    my ($file) = @_;
    my $outFile = "validateWig.out";
    my $filePath = "$submitPath/$file";
    my $err = system (
        "cd $outPath; head -10 $filePath | wigEncode stdin /dev/null /dev/null >$outFile 2>&1");
    if ($err) {
        print STDERR  "ERROR: File \'$file\' failed wiggle validation\n";
        open(ERR, "$outPath/$outFile") || die "ERROR: Can't open wiggle validation file \'$outPath/$outFile\': $!\n";
        my @err = <ERR>;
        die "@err\n";
    } else {
        &HgAutomate::verbose(2, "File \'$file\' passed wiggle validation\n");
    }
}

sub validateBed {
# Validate each line of a bed 5 or greater file.
    my ($file, $type) = @_;
    my $filePath = "$submitPath/$file";
    my $line = 0;
    open(FILE, $filePath) or die "Couldn't open file: $filePath; error: $!\n";
    while(<FILE>) {
        chomp;
        my @fields = split /\t/;
        $line++;
        my $prefix = "Failed bed validation, line $line:";
        if(/^(track|browser)/) {
            ;
        } elsif(@fields < 5) {
            die "$prefix not enough fields; " . scalar(@fields) . " present; at least 5 are required";
        } elsif ($fields[0] !~ /^chr(\d+|M|X|Y)$/) {
            die "$prefix field 1 value ($fields[0]) is invalid; not a valid chrom name";
        } elsif ($fields[1] !~ /^\d+$/) {
            die "$prefix field 2 value ($fields[1]) is invalid; value must be a positive number";
        } elsif ($fields[2] !~ /^\d+$/) {
            die "$prefix field 3 value ($fields[2]) is invalid; value must be a positive number";
        } elsif ($fields[2] < $fields[1]) {
            die "$prefix field 3 value ($fields[2]) is less than field 2 value ($fields[1])";
        } elsif ($fields[4] !~ /^\d+$/ && $fields[4] !~ /^\d+\.\d+$/) {
            die "$prefix field 5 value ($fields[4]) is invalid; value must be a positive number";
        } elsif ($fields[4] < 0 || $fields[4] > 1000) {
            die "$prefix field 5 value ($fields[4]) is invalid; score must be 0-1000";
        } else {
            ;
        }
    }
    close(FILE);
    HgAutomate::verbose(2, "File \'$file\' passed bed validation\n");
}

sub validateGene {
    my ($file, $type) = @_;
    my $outFile = "validateGene.out";
    my $filePath = "$submitPath/$file";
    my $err = system (
        "cd $outPath; egrep -v '^track|browser' $filePath | ldHgGene -out=genePred.tab -genePredExt hg18 testTable stdin >$outFile 2>&1");
    if ($err) {
        print STDERR  "ERROR: File \'$file\' failed GFF validation\n";
        open(ERR, "$outPath/$outFile") || die "ERROR: Can't open GFF validation file \'$outPath/$outFile\': $!\n";
        my @err = <ERR>;
        die "@err\n";
    } else {
        &HgAutomate::verbose(2, "File \'$file\' passed GFF validation\n");
    }
}

sub validateMappedReads {
    my ($file, $type) = @_;
    my $filePath = "$submitPath/$file";
    my $line = 0;
    open(FILE, $filePath) or die "Couldn't open file: $filePath; error: $!\n";
    while(<FILE>) {
        $line++;
        if(!(/chr(\d+|M|X|Y)\t\d+\t\d+\t[ATCG]+\t\d+\t[+-]\t.*/)) {
            die "Line number $line is invalid\nline: $_";
        }
    }
    close(FILE);
    HgAutomate::verbose(2, "File \'$file\' passed mappedReads validation\n");
}


############################################################################
# Misc subroutines

sub validateField {
    # validate value for type of field
    my ($type, $val, $arg) = @_;
    $type =~ s/ /_/g;
    &HgAutomate::verbose(4, "Validating $type: " . (defined($val) ? $val : "") . "\n");
    $validators{$type}->($val, $arg);
}

sub checkDataFormat {
    # validate file type
    my ($format, $file) = @_;
    &HgAutomate::verbose(3, "Checking data format for $file: $format\n");
    my $type = "";
    if ($format =~ m/(bed) (\d+)/) {
        $format = $1;
        $type = $2;
    }
    $formatCheckers{$format} || 
        die "ERROR: Data format \'$format\' in PIF file \'$pifFile\' is unknown\n";
    $formatCheckers{$format}->($file, $type);
}

sub loadControlledVocab {
    %terms = ();
    my %termRa = &readRaFile("$configPath/$vocabConfigFile", "term");
    foreach my $term (keys %termRa) {
        my $type = $termRa{$term}->{'type'};
        $terms{$type}->{$term} = $termRa{$term};
    }
}

sub newestFile {
  # Get the most recently modified file from a list
    my @files = @_;
    my $newestTime = 0;
    my $newestFile = "";
    my $file = "";
    foreach $file (@files) {
        my $fileTime = (stat($file))->mtime;
        if ($fileTime > $newestTime) {
            $newestTime = $fileTime;
            $newestFile = $file;
        }
    }
    return $newestFile;
}

sub getPif {
    # Read info from Project Information File.  Verify required fields
    # are present and that the project is marked active.
    my %pif = ();
    $pifFile = &newestFile(glob "*.PIF");
    &HgAutomate::verbose(2, "Using newest PIF file \'$pifFile\'\n");

    %tracks = ();  # this is a global
    my $track;

    my $lines = readFile($pifFile);
    while (@{$lines}) {
        my $line = shift @{$lines};
        # strip leading and trailing spaces
        $line =~ s/^ +//;
        $line =~ s/ +$//;
        # ignore comments and blank lines
        next if $line =~ /^#/;
        next if $line =~ /^$/;

        my ($key, $val) = splitKeyVal($line);
        if(!defined($key)) {
            next;
        }
        if ($key ne "track") {
            &HgAutomate::verbose(3, "PIF field: $key = $val\n");
            $pif{$key} = $val;
        } else {
            my %track = ();
            $track = $val;
            $tracks{$track} = \%track;
            &HgAutomate::verbose(5, "  Found track: \'$track\'\n");
            while ($line = shift @{$lines}) {
                $line =~ s/^ +//;
                $line =~ s/ +$//;
                next if $line =~ /^#/;
                next if $line =~ /^$/;
                if ($line =~ /^track/) {
                    unshift @{$lines}, $line;
                    last;
                }
                my ($key, $val) = splitKeyVal($line);
                $track{$key} = $val;
                &HgAutomate::verbose(5, "    Property: $key = $val\n");
            }
        }
    }

    # Validate fields
    defined($pif{'project'}) || die "ERROR: Project not defined\n"; 
    $pif{'active'} =~ "yes" || 
        die "ERROR: Project \'$pif{'project'}\' not yet active\n";
    defined(%tracks) ||
        die "ERROR: Tracks not defined for project \'$pif{'project'}\'in $pifFile \n";

    foreach my $track (keys %tracks) {
        &HgAutomate::verbose(4, "  Track: $track\n");
        my %track = %{$tracks{$track}};
        foreach my $key (keys %track) {
            &HgAutomate::verbose(4, "    Setting: $key   Value: $track{$key}\n");
        }
    }

    if (defined($pif{'variables'})) {
        my @variables = split (/\s+/, $pif{'variables'});
        my %variables;
        my $i = 0;
        foreach my $variable (@variables) {
            # replace underscore with space
            $variable =~ s/_/ /g;
            $variables[$i++] = $variable;
            $variables{$variable} = 1;
        }
        $pif{'variableHash'} = \%variables;
        $pif{'variableArray'} = \@variables;
    }
    return %pif;
}

sub readRaFile {
    # Read records from a .ra file into a hash of hashes and return it.
    my ($file, $type) = @_;
    open(RA, $file) || 
        die "ERROR: Can't open RA file \'$file\'\n";
    my @lines = <RA>;
    my %ra = ();
    my $raKey = undef;
    foreach my $line (@lines) {
        $line =~ s/^\s+//;
        $line =~ s/\s+$//;
        if ($line =~ /^$/) {
            $raKey = undef;
            next;
        }
        next if $line =~ /^#/;
        chomp $line;
        if ($line =~ m/^$type\s+(.*)/) {
            $raKey = $1;
        } else {
            defined($raKey) || die "ERROR: Missing $type before $line\n";
            my ($key, $val) = split('\s+', $line, 2);
            $ra{$raKey}->{$key} = $val;
        }
    }
    close(RA);
    return %ra;
}

############################################################################
# Main

my $line;
my $i;
my @ddfHeader;	# list of field headers on the first line of DDF file
my %ddfHeader = ();
my %datasets = ();
my $wd = `pwd`; chomp $wd;

my $ok = GetOptions("configDir=s",
                    "outDir=s",
                    "verbose=i",
                    );
&usage() if (!$ok);
&usage() if (scalar(@ARGV) < 2);

# Get command-line args
my $submitType = $ARGV[0];	# currently not used
my $submitDir = $ARGV[1];

# Get general options
$opt_verbose = 1 if (!defined $opt_verbose);

# Determine submission, configuration, and output directory paths
&HgAutomate::verbose(2, "Validating submission in directory \'$submitDir\'\n");
if ($submitDir =~ /^\/.*/) {
    $submitPath = $submitDir;
} else {
    $submitPath = "$wd/$submitDir";
}
&HgAutomate::verbose(4, "Submission directory path: \'$submitPath\'\n");

if (defined $opt_configDir) {
    if ($opt_configDir =~ /^\//) {
        $configPath = $opt_configDir;
    } else {
        $configPath = "$wd/$opt_configDir";
    }
} else {
    $configPath = "$submitDir/../config"
}
&HgAutomate::verbose(4, "Config directory path: \'$configPath\'\n");

if (defined $opt_outDir) {
    if ($opt_outDir =~ /^\//) {
        $outPath = $opt_outDir;
    } else {
        $outPath = "$wd/$opt_outDir";
    }
} else {
    $outPath = "$submitDir/out"
}
&HgAutomate::verbose(4, "Output directory path: \'$outPath\'\n");

# Change dir to submission directory 
chdir $submitPath ||
    die ("SYS ERR; Can't change to submission directory \'$submitPath\': $OS_ERROR\n");
&HgAutomate::verbose(3, "Creating output in directory \'$outPath\'\n");
mkdir $outPath || 
    die ("SYS ERR: Can't create out directory \'$outPath\': $OS_ERROR\n");

# Locate project information (PIF) file and verify that project is
#  ready for submission
%pif = &getPif();

# Gather fields defined for DDF file. File is in 
# ra format:  field <name>, required <true|false>
my %fields = &readRaFile("$configPath/$fieldConfigFile", "field");

my %labs;
if(-e "$configPath/$labsConfigFile") {
    # tolerate missing labs.ra in dev trees.
    %labs = &readRaFile("$configPath/$labsConfigFile", "lab");
}

# Add required fields for this -- the variables in the PIF file
if (defined($pif{'variables'})) {
    foreach my $variable (keys %{$pif{'variableHash'}}) {
        $fields{$variable}->{'required'} = 'yes';
    }
}

# Open dataset descriptor file (DDF)
my $ddfFile = &newestFile(glob "*.DDF");
&HgAutomate::verbose(2, "Using newest DDF file \'$ddfFile\'\n");
my $lines = readFile($ddfFile);

# Get header containing column names
while(@{$lines}) {
    my $line = shift(@{$lines});
    # remove leading and trailing spaces and newline
    $line =~ s/^ +//;
    $line =~ s/ +$//;
    # ignore empty lines and comments
    next if $line =~ /^$/;
    next if $line =~ /^#/;
    @ddfHeader = split(/\t/, $line);
    for ($i=0; $i < @ddfHeader; $i++) {
        $ddfHeader{$ddfHeader[$i]} = $i;
    }
    last;
}

# Validate DDF header -- assure field is recognized
foreach my $field (@ddfHeader) {
    defined($fields{$field}) || die "ERROR: Header \'$field\' is unknown\n"; 
    delete($fields{$field});
}

# Check that all required fields are present in DDF header -- any
# not yet deleted that are marked required but have not been found in header
foreach my $field (keys %fields) {
    $fields{$field}->{'required'} eq "yes" && 
        die "ERROR: DDF header is missing required field \'$field\'\n"; 
}

# Process lines in DDF file.  Create dataset hash with one entry per dataset.
# The entry contains an array of fields that are the same as the DDF fields,
# except when multiple files comprise one data set (multiple Parts).
# In this case, all files are included in the File Name field, 
my $dataset;
while (@{$lines}) {
    my $line = shift(@{$lines});
    $line =~ s/^ +//;
    $line =~ s/ +$//;
    next if $line =~ /^#/;
    next if $line =~ /^$/;
    my @fields = split('\t', $line);
    my $fileField = $ddfHeader{'File Name'};
    my $filename = $fields[$fileField];
    my $partField = $ddfHeader{'Part'};
    my $part = 1;
    if (defined($partField)) {
        validateField('Part', $fields[$partField]);
        $part =  $fields[$partField];
    }
    $dataset = $fields[$ddfHeader{'Dataset Name'}];
    my $offset = $part - 1;
    if (defined($datasets{$dataset})) {
        # add file to dataset, checking all fields with non-empty values 
        # are identical (except 'Part', which must differ)
        for ($i=0; $i < @fields; $i++) {
            next if ($i == $fileField || $i == $partField);
            $fields[$i] =~ $datasets{$dataset}->[$i] ||
                die "ERROR: Dataset \'$dataset\' has differing \'$ddfHeader[$i]\' values\n";
        }
        !defined($datasets{$dataset}->[$fileField]->[$offset]) ||
            die "ERROR: Dataset \'$dataset\' part \'$part\' has multiple files\n";
        $datasets{$dataset}->[$fileField]->[$offset] = $filename;
    } else {
        # add dataset
        my @filenames;
        $filenames[$offset] = $filename;
        $fields[$fileField] = \@filenames;
        $datasets{$dataset} = \@fields;
    }
}

# Validate files and metadata fields in all datasets using controlled
# vocabulary.  Create .ra file for loader .
&loadControlledVocab;
open(LOADER_RA, ">$outPath/$loadFile") || die "SYS ERROR: Can't write \'$outPath/$loadFile\' file; error: $!\n";
open(TRACK_RA, ">$outPath/$trackFile") || die "SYS ERROR: Can't write \'$outPath/$trackFile\' file; error: $!\n";
foreach $dataset (keys %datasets) {
    my $datasetRef = $datasets{$dataset};
    my $dataType = $datasetRef->[$ddfHeader{'Data Type REF'}];
    my $tableType = $tracks{$dataType}->{'tableType'};
    &HgAutomate::verbose(2, "  Dataset: $dataset\tTrack: $dataType\n");
    for ($i=0; $i < @ddfHeader; $i++) {
        &validateField($ddfHeader[$i], $datasetRef->[$i], $dataType);
    }

    # Construct table name from track name and variables
    my $trackName = "wgEncode" . $dataType;
    my $tableName = $trackName;
    if(!defined($pif{shortLabelPrefix})) {
        $pif{shortLabelPrefix} = "";
    }
    if(!defined($pif{longLabelPrefix})) {
        $pif{longLabelPrefix} = "";
    }
    if(!defined($tracks{$dataType}->{longLabelSuffix})) {
        $tracks{$dataType}->{longLabelSuffix} = "";
    }
    if(!defined($tracks{$dataType}->{shortLabelSuffix})) {
        $tracks{$dataType}->{shortLabelSuffix} = "";
    }
    my $shortLabel = $pif{shortLabelPrefix};
    if($tracks{$dataType}->{shortLabelSuffix}) {
        $shortLabel = $shortLabel ? "$shortLabel $tracks{$dataType}->{shortLabelSuffix}" : $tracks{$dataType}->{shortLabelSuffix};
    }
    my $longLabel = "ENCODE $pif{longLabelPrefix} $tracks{$dataType}->{longLabelSuffix}";
    if (defined($pif{variables})) {
        my @variables = @{$pif{variableArray}};
        my %hash = map { $_ => $datasetRef->[$ddfHeader{$_}] } @variables;
        for my $var (@variables) {
            $tableName = $tableName . $datasetRef->[$ddfHeader{$var}];
        }
        my $shortSuffix;
        my $longSuffix;
        if($hash{"Antibody REF"} && $hash{"Cell Line REF"}) {
            $shortSuffix = "$hash{'Antibody REF'}/$hash{'Cell Line REF'}";
            $longSuffix = "$hash{'Antibody REF'} in $hash{'Cell Line REF'} cells";
        } elsif ($hash{"Cell Line REF"}) {
            $shortSuffix = "$hash{'Cell Line REF'}";
            $longSuffix = "in $hash{'Cell Line REF'} cells";
        }
        if($shortSuffix) {
            $shortLabel = $shortLabel ? "$shortLabel ($shortSuffix)" : $shortSuffix;
        }
        if($longSuffix) {
            $longLabel .= " ($longSuffix)";
        }
    }
    # mysql doesn't allow hyphens in table names.
    $tableName =~ s/-/_/g;
    print LOADER_RA "tablename $tableName\n";
    print LOADER_RA "track $trackName\n";
    print LOADER_RA "type $tracks{$dataType}->{type}\n";
    print LOADER_RA "tableType $tableType\n" if defined($tableType);
    print LOADER_RA "assembly $datasetRef->[$ddfHeader{'Assembly REF'}]\n";
    print LOADER_RA "files @{$datasetRef->[$ddfHeader{'File Name'}]}\n";
    print LOADER_RA "\n";

    # XXXX This is a work in progress; assign as subtracks?
    print TRACK_RA "track\t$tableName\n";
    print TRACK_RA "subTrack\t$trackName\n";
    print TRACK_RA "shortLabel\t$shortLabel\n";
    print TRACK_RA "longLabel\t$longLabel\n";
    my ($sec,$min,$hour,$mday,$mon,$year,$wday,$yday,$isdst) = localtime(time());
    print TRACK_RA sprintf("dateSubmitted\t%d-%02d-%d %d:%d:%d\n", 1900 + $year, $mon + 1, $mday, $hour, $min, $sec);
    print TRACK_RA "\n";

}
close(LOADER_RA);
close(TRACK_RA);

# Send "data is ready" email to email contact assigned to $pif{lab}

if($labs{$pif{lab}} && $labs{$pif{lab}}->{wranglerEmail}) {
    my $email = $labs{$pif{lab}}->{wranglerEmail};
    `echo "dir: $submitPath" | /bin/mail -s "ENCODE data from $pif{lab} lab is ready" $email`;
}

exit 0;
